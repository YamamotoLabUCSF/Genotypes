{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Genotypes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "https://github.com/YamamotoLabUCSF/Genotypes  \n",
    "v1.0/Committed 8-02-2019;\n",
    "v1.1/Committed 1-02-2021\n",
    "\n",
    "<img src=\"Genotypes_img/NGS_overview.png\" align=\"left\" width=\"540\">\n",
    "\n",
    "### Background: \n",
    "Genetic variation is foundational in biology. Identification of alleles, allele frequencies, and rare variants in populations is central to many biological questions. Massively parallel DNA sequencing has made it increasingly feasible to collect DNA sequence information at specific genomic positions (loci) for 100s-1000s of individual cells or organisms (*samples*) within a population.  \n",
    "\n",
    "**This script automates sample-specific genotype inference at target loci**, expediting (1) analysis of genetic variation in a sample population, and (2) identification of individual (potentially rare) samples bearing specific alleles and genotypic properties.\n",
    " \n",
    "**Figure**. *Briefly, sample-specific target loci can be PCR-amplified in arrayed format, with sample identity defined by short DNA indices appended as 'barcodes'. After pooling and sequencing by synthesis (SBS), reads are assigned to source samples (demultiplexed) and stored in sample-specific fastq files. **Using fastq files as input, this script identifies probable alleles in each sample, and based on their frequencies, extrapolates genotype at the locus in question.** The script reports overall allele frequencies across the sampled population, and enables identification of specific sample(s) that harbor potentially rare genetic variants.*\n",
    "\n",
    "### Potential uses:\n",
    "This script was developed to enable rapid identification of mutant clones following Cas9-editing (CRISPR-Cas9 mutagenesis) and clonal isolation. This script should be useful for additional applications needing rapid inferral of sample-specific genotypes at specific loci recovered by PCR (*e.g.*, from individual organisms or from clonally isolated cell populations), as well as applications that involve summation of population genetic diversity. \n",
    "\n",
    "### Synopsis:\n",
    "**This script returns allele definitions (and inferred genotypes) for samples from a demultiplexed NGS fastq dataset** \n",
    ">(see 'Output notes' for file output\n",
    "details).  \n",
    "\n",
    "**Users are asked for paths to specific directories (*e.g.*, output and input directories, BLASTN reference sequence database), a locally installed BLASTN (NCBI) executable, and (optional) DNA sub-sequences to map onto alignments**  \n",
    ">(see 'Input notes' for details).\n",
    "    \n",
    "Python3, BLASTN & BLASTDBCMD (NCBI) are required for operation.  \n",
    "BLASTN & BLASTDBCMD can be downloaded and locally installed at <https://www.ncbi.nlm.nih.gov/guide/howto/run-blast-local/>.  \n",
    "\n",
    "A sequence reference database is required for BLASTN alignment operations, and can be obtained in one of two ways:\n",
    "- create custom database from a fasta file containing reference sequence(s) using MAKEBLASTDB (NCBI)  \n",
    "(details at <https://www.ncbi.nlm.nih.gov/books/NBK279688/>)\n",
    "- download pre-formatted NCBI BLAST database (details at <https://www.ncbi.nlm.nih.gov/books/NBK537770/>)\n",
    "    \n",
    "For usage details, please refer to README file at GitHub and to the following manuscript:  \n",
    ">*Ehmsen, Knuesel, Martinez, Asahina, Aridomi, Yamamoto (2021)*\n",
    "    \n",
    "Please cite usage as:  \n",
    ">Genotypes.py  \n",
    ">*Ehmsen, Knuesel, Martinez, Asahina, Aridomi, Yamamoto (2021)*\n",
    " \n",
    "--------\n",
    "\n",
    "<img src=\"Genotypes_img/Genotypes_thumbnail_sketch.png\" align=\"right\" width=\"650\">\n",
    "\n",
    "### Operation notes:\n",
    "*What does this script do?*\n",
    " 1. **classify & count reads:** counts unique read types per well (*i.e.*, sample); fastq file name provides the sample name  \n",
    " \n",
    " \n",
    " 2. **identify top 10 reads** per well (in terms of read abundance); calculates representation among reads within the well at four levels:\n",
    " \n",
    "   (a) raw frequency (% read type in question, relative to total reads)  \n",
    "   (b) percentile (% of other read types that fall below the frequency of the read type in question)  \n",
    "   (c) adjusted frequency @ 1% (% read type in question, relative to reads that occur at >1% frequency)  \n",
    "   (d) adjusted frequency @ 10% (% read type in question, relative to reads that occur at >10% frequency)  \n",
    "   \n",
    "   --> These are returned as hypothesized \"Ranked Alleles\" in further analysis\n",
    "   \n",
    "   \n",
    " 3. **align to reference database:** aligns top 10 reads to reference genome using BLASTN  \n",
    " *(National Center for Biotechnology Information;\n",
    "    Altschul S.F. et al. (1990) \"Basic local alignment search tool\")*    \n",
    "    \n",
    "    \n",
    " 4. **return alignments as alleles & inferred genotypes;**  \n",
    "    For Ranked Alleles with >1 high-scoring pair (hsp) (potentially indicative of indel >~60 bp/  \n",
    "    alignments split by BLASTN), Genotypes.py attempts allele reconstruction by retrieving the sequence spanned  \n",
    "    by the hsp's (if end-to-end span across hsp's <1 kb) using BLASTDBCMD  \n",
    "    \n",
    " **(optional) map sub-sequence(s) onto alleles:**  \n",
    "    -  for mutants, the alignment shows location of Cas9 cut(s) and indel(s) relative to wt,\n",
    "       if Cas9 guide sequence(s) supplied by user  \n",
    "    -  also indicates location of test sub-sequence(s) and whether sub-sequence is altered (ablated),\n",
    "       if test sub-sequence(s) supplied by user  \n",
    "       \n",
    "       \n",
    " 5. **provide overall population statistics:**  \n",
    " \n",
    "   (a) total sample # for which genotypes were extrapolated  \n",
    "   (b) distribution of genotypes among samples (homozygous, heterozygous, etc.)  \n",
    "   (c) estimated wild-type *vs.* mutant allele frequencies  \n",
    "   (d) summary of samples and deprecated reads that either had 'no hit' in reference database provided to BLASTN,\n",
    "       or multiple hits (>1), or overlapping high-scoring pairs (hsp's) that confounded allele reconstruction  \n",
    "       \n",
    "--------\n",
    "### Input notes:\n",
    "You will be prompted for the following user-specific information (up to 8 items):\n",
    "\n",
    "   **Required** (5 strings specifying directory or executable locations, 1 string specifying sequence database file prefix): \n",
    "      <ul>\n",
    "      <li>where should output files go?</li>\n",
    "          *path to* **output directory** *for output files*\n",
    "      <li>where are input files found?</li>\n",
    "          *path to single directory containing* **demultiplexed fastq files**                                         \n",
    "      <li>where is BLASTN executable found?</li>\n",
    "          *path to* **BLASTN** *installation*\n",
    "      <li>where is the reference sequence database used for alignment?</li>\n",
    "          *path to directory containing six files that compose the* **reference sequence database** *used\n",
    "    for BLASTN alignments (.nhr, .nin, .nog, .nsd, .nsi, .nsg)*\n",
    "      <li>what prefix is common to the six files that compose the reference sequence database?</li>\n",
    "          *prefix common to database files .nhr, .nin, .nog, .nsd, .nsi, .nsg*\n",
    "      <li>where is BLASTDBCMD executable found?</li>\n",
    "          *path to* **BLASTDBCMD** *installation*\n",
    "      </ul>\n",
    "                                                                                                           \n",
    "   **Optional** (up to 2 lines of comma-separated strings specifying DNA sub-sequence(s):    \n",
    " **DNA sub-sequence(s)** to be mapped onto sequence alignments\n",
    "      <ul>\n",
    "      <li>**guide RNA sequence** (in 5'-3' DNA representation, excluding PAM sequence)</li>\n",
    "      <li>**test sequence** (5'-3' sub-sequence motif(s) of interest, to query whether lost or gained in allele(s))</li>\n",
    "      </ul>\n",
    "      \n",
    "--------\n",
    "### Output notes:\n",
    "This script produces 8 output files in the user-specified output directory.  \n",
    "These include:  \n",
    "\t 1. fasta.fa  \n",
    "        (collection of fasta entries representing top 10 most abundant sequences assigned to a single sample ID)\n",
    "        \n",
    "\t 2. blastn_alignments.txt  \n",
    "        (output of blastn operation on fasta.fa)\n",
    "     \n",
    "     3. allele_definitions.txt\n",
    "        (output of script operation on blastn_alignments.txt, samples returned in order of processing)  \n",
    "        \n",
    "     4. allele_evidence.pdf  \n",
    "        (output of script operation on blastn_alignments.txt, plots of calculated read/allele frequencies)  \n",
    "        \n",
    "     5. genotypes.txt  \n",
    "        (output of script operation on blastn_alignments.txt, samples returned in ranked order based on  \n",
    "        genotype inferral)  \n",
    "        \n",
    "     6. allele_definitions.csv  \n",
    "        (tabular representation of allele data for all samples)  \n",
    "         \n",
    "\t 7. population_summary.txt  \n",
    "        (output of script operation on genotypes.txt)  \n",
    "        \n",
    "     8. script_metrics.txt  \n",
    "        (summary/analysis of script operation metrics [metadata])  \n",
    "\n",
    "           Directory structure under an output directory specified as 'Genotypes', for example,  \n",
    "           would contain the following files after Genotypes.py operations:  \n",
    "\n",
    "           /Genotypes  \n",
    "                          `-----allele_definitions.csv  \n",
    "                          `-----allele_definitions.txt  \n",
    "                          `-----allele_evidence.pdf  \n",
    "                          `-----blastn_alignments.txt  \n",
    "                          `-----fasta.fa  \n",
    "                          `-----genotypes.txt  \n",
    "                          `-----population_summary.txt  \n",
    "                          `-----script_metrics.txt\n",
    "--------\n",
    "### Visual summary of key script operations:\n",
    "In short, sequencing data in a sample-specific **fastq file** (*e.g.,* below), are converted to user-interpretable  genotype inferences (**key output files**, below), for 100s to 1000s of samples.  \n",
    "<img src=\"Genotypes_img/fastq_example.png\" align=\"left\" width=\"700\">\n",
    "<br clear=\"all\" />\n",
    "#### Key output files:  \n",
    "##### allele_definitions.txt \n",
    "Samples are reported with sequence alignments to document alleles, along with inferred genotypes. \n",
    "<img src=\"Genotypes_img/genotype_example.png\" align=\"left\" width=\"800\">\n",
    "<br clear=\"all\" />\n",
    "##### allele_evidence.pdf\n",
    "Samples are reported with frequency plots as evidence.\n",
    "<img src=\"Genotypes_img/frequency_plots_example.png\" align=\"left\" width=\"700\">  \n",
    "<br clear=\"all\" />\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "**Welcome.**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### I. Setup  \n",
    "Import libraries, modules  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Check for availability of Python dependencies in path\n",
    "missing_dependencies_list = []\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('psutil')\n",
    "    \n",
    "try:\n",
    "    import numpy\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('numpy')\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('scipy')\n",
    "    \n",
    "try:\n",
    "    import matplotlib.pyplot\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('matplotlib.pyplot')\n",
    "    \n",
    "try:\n",
    "    import fpdf\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('fpdf')\n",
    "    \n",
    "try:\n",
    "    import PyPDF2\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('PyPDF2')\n",
    "\n",
    "try:\n",
    "    import pandas\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('pandas')\n",
    "    \n",
    "if len(missing_dependencies_list) > 0:\n",
    "    print('ModuleNotFoundError\\n')\n",
    "    print('Please note, the following required Python module(s) are not found in your Python system path:')\n",
    "    for i in missing_dependencies_list:\n",
    "        print('   '+i)\n",
    "    print('\\nPlease exit the script and install these Python dependencies in your system path.')\n",
    "    print(\"\"\"\\nGuidelines for installation of Python dependencies can be found in the README file for Genotypes.py ('System Setup')\"\"\")\n",
    "    print(\"\"\"    (Creation of a Python virtual environment is recommended)\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Operating system interfaces\n",
    "import os\n",
    "\n",
    "# import subprocess management\n",
    "import subprocess\n",
    "\n",
    "# Time access and conversions, Basic data and time types\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# System-specific parameters and functions\n",
    "import sys\n",
    "\n",
    "# Process and system utilities\n",
    "import psutil\n",
    "from psutil import virtual_memory\n",
    "\n",
    "# Gzip to read GNU zipped files\n",
    "import gzip\n",
    "\n",
    "# Low-level networking interface\n",
    "import socket\n",
    "\n",
    "# System version information\n",
    "import platform\n",
    "\n",
    "# Unix-style pathname pattern expansion\n",
    "import glob\n",
    "\n",
    "# Object-oriented filesystem paths\n",
    "from pathlib import Path\n",
    "\n",
    "# NumPy (numeric operations)\n",
    "import numpy\n",
    "\n",
    "# SciPy (for percentile) \n",
    "from scipy import stats\n",
    "\n",
    "# Container datatypes (for Counter operation)\n",
    "from collections import Counter\n",
    "\n",
    "# Decimal fixed point and floating point arithmetic\n",
    "from decimal import Decimal\n",
    "\n",
    "# Internationalization services (for use of thousands separator in numbers where appropriate)\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "\n",
    "# Regular expression operations\n",
    "import re\n",
    "\n",
    "# Python plotting\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Python PDF tools\n",
    "from fpdf import FPDF\n",
    "from PyPDF2 import PdfFileMerger, PdfFileReader\n",
    "\n",
    "# Python panel data frames\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Log start time\n",
    "initialTime = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Define functions     \n",
    "*User inputs can be entered either in rapid succession ('List' format), or in response to individually coached prompts. 'Prompts' defines a series of 6 coached entries that provide a user with instructive detail regarding the nature of required input.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define 'prompts' function for coached user input\n",
    "def prompts():\n",
    "    \"\"\"Coached prompts to collect user input\"\"\"\n",
    "    # Make variables assigned in prompts() function globally available\n",
    "    global output_directory\n",
    "    global fastq_directory\n",
    "    global blastn_path\n",
    "    global db_path\n",
    "    global db_prefix\n",
    "    global blastdbcmd_path\n",
    "    global guideRNA_seq\n",
    "    global extant_seq\n",
    "    global test_seq\n",
    "    # 1-Specify output directory.\n",
    "    print(r\"\"\"\n",
    "---------------------------------------------\n",
    "Location of OUTPUT DIRECTORY for output files\n",
    "---------------------------------------------\n",
    "    \n",
    "The script generates 8 separate files, all in the directory you indicate here.  It is important that this directory\n",
    "either not exist prior to running the script, or if it does exist, it must be *empty* of any files with the names\n",
    "to be created below.  These files are:\n",
    "    \n",
    "    1. fasta.fa\n",
    "\n",
    "    2. blastn_alignments.txt\n",
    "        (output of blastn operation on fasta.fa)\n",
    "\n",
    "    3. allele_definitions.txt\n",
    "        (output of script operation on blastn_alignments.txt, samples returned in order of processing)\n",
    "                  \n",
    "    4. allele_evidence.pdf \n",
    "        (optional; output of script operation on blastn_alignments.txt, plot of calculated read/allele frequencies)\n",
    "\n",
    "    5. genotypes.txt\n",
    "        (output of script operation on blastn_alignments.txt, samples returned in order of genotype inferences)\n",
    "\n",
    "    6. population_summary.txt\n",
    "        (output of script operation on genotypes.txt)\n",
    "                  \n",
    "    7. allele_definitions.csv\n",
    "        (allele metrics (frequency representations) and definitions for each sample, in spreadsheet format)\n",
    "                  \n",
    "    8. script_metrics.txt \n",
    "        (summary/analysis of script operation metrics)\n",
    "            \n",
    "        Notes: \n",
    "        * These files do not exist before the script is run. The files are made by the script.\n",
    "        * The primary data outputs for genotypes are found in:\n",
    "            allele_definitions.txt, allele_evidence.pdf, genotypes.txt & population_summary.txt\n",
    "        \n",
    "        \n",
    "At this prompt, indicate an absolute path to a ** directory ** that will be created by the script as the location\n",
    "for output files.  This directory should not exist yet -- it will be created as an output of this script, and will\n",
    "be populated with the file outputs of this specific instance of the script operation.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators, regardless of operating system (Mac or Windows).\n",
    "\n",
    "Example: if you'd like to create a directory ('Genotypes') in an existing directory ('Illumina'), accessed\n",
    "with absolute path of '/Users/myname/Illumina/Genotypes' (Mac) or 'C:\\Users\\myname\\Illumina\\Genotypes'\n",
    "(Windows), enter '/Users/myname/Illumina/Genotypes' at the command line prompt. Replace 'myname' with the\n",
    "appropriate intervening directory identifiers. Do *not* flank your entry with quotation marks (') at the command\n",
    "line.\n",
    "    \n",
    "Alternatively, simply enter a desired directory name (e.g., 'Genotypes') and run this script from\n",
    "within a directory where you'd like to create this new directory.\"\"\"+'\\n')\n",
    "    output_directory = input(r\"\"\"    -----> Output directory name and path:  \"\"\")\n",
    "    # 2-Specify the fastq files to be used for input, by indicating directory location of the file list.\n",
    "    print(r\"\"\"\n",
    "------------------------------------------------------------------------------\n",
    "Location of INPUT FILES (single directory containing demutiplexed fastq files)\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "You will now be asked to enter the path to the directory containing the fastq files\n",
    "to be processed as Genotypes.py input.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "\n",
    "Example: if your fastq input files are named file1.fastq, file2.fastq, etc. and are found in a directory\n",
    "named 'Sequences' with absolute path of '/Users/myname/Sequences' (Mac) or 'C:\\Users\\myname\\Sequences' (PC),\n",
    "enter '/Users/myname/Sequences' at the command line prompt.\n",
    "\n",
    "When you're done entering the fastq file location, press 'Enter' again to proceed in the script.\"\"\"+'\\n')\n",
    "    fastq_directory = input(r\"\"\"    -----> Directory name and path:  \"\"\")\n",
    "    # 3-Collect path to blastn executable.\n",
    "    print(\"\"\"\n",
    "-----------------------------\n",
    "Location of BLASTN EXECUTABLE\n",
    "-----------------------------\n",
    "\n",
    "This script uses BLASTN (NCBI) to align reads from your fastq files to a reference sequence database\n",
    "(such as a genome database or sequence database).\n",
    "Please indicate the absolute path to the BLASTN executable.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "    \n",
    "Example: if your BLASTN executable is found at absolute path /Users/myname/blastn, type '/Users/myname/blastn'\n",
    "and press Enter.\"\"\"+'\\n')\n",
    "    blastn_path = input(r\"\"\"    -----> Path to BLASTN executable:  \"\"\")\n",
    "    # 4-Collect location of blastn database directory.\n",
    "    print(\"\"\"\n",
    "-----------------------------------------------\n",
    "Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
    "-----------------------------------------------\n",
    "\n",
    "Because this script uses BLASTN (NCBI) to align reads from your fastq files a reference sequence database,\n",
    "an alignment reference database is needed. This reference database consists of a single directory containing\n",
    "six files (.nhr, .nin, .nog, .nsd, .nsi, .nsg) (generated by the program MAKEBLASTDB (NCBI) from a file\n",
    "containing sequences in fasta format, or downloaded from NCBI as an existing database).\n",
    "    \n",
    "Please indicate the absolute path to the directory you are using as your reference sequence database.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "    \n",
    "Example: if your reference sequence database is found at absolute path /Users/myname/database, type\n",
    "'/Users/myname/database' and press Enter.\"\"\"+'\\n')\n",
    "    db_path = input(r\"\"\"    -----> Path to BLASTN alignment reference sequence database:  \"\"\")\n",
    "    # 5-Collect prefix of blastn database files.\n",
    "    print(\"\"\"\n",
    "------------------------------------------------\n",
    "PREFIX common to BLASTN ALIGNMENT DATABASE FILES\n",
    "------------------------------------------------\n",
    "\n",
    "A BLASTN reference sequence database consists of six files in a single directory, with each of the six\n",
    "files sharing a common prefix (usually determined by the name of the fasta file provided to MAKEBLASTDB\n",
    "during database generation).\n",
    "    \n",
    "Please indicate the common prefix for files of the reference sequence database.\"\"\"+'\\n')\n",
    "    db_prefix = input(r\"\"\"    -----> Prefix for alignment reference sequence database files:  \"\"\")\n",
    "    # 6-Collect path to BLASTDBCMD executable.\n",
    "    print(\"\"\"\n",
    "---------------------------------\n",
    "Location of BLASTDBCMD EXECUTABLE\n",
    "---------------------------------\n",
    "\n",
    "This script uses BLASTDBCMD (NCBI) to retrieve DNA sequence spans between coordinates in a reference sequence database* (such as a genome database or sequence database) (*in cases where BLASTN has split an alignment into >1 local high-scoring pair (hsp)).\n",
    "    \n",
    "Please indicate the absolute path to the BLASTDBCMD executable.\n",
    "    \n",
    "Example: if your BLASTDBCMD executable is found at absolute path /Users/myname/blastdbcmd,\n",
    "type '/Users/myname/blastdbcmd' and press Enter.\"\"\"+'\\n')\n",
    "    blastdbcmd_path = input(r\"\"\"    -----> Path to BLASTDBCMD executable:  \"\"\")  \n",
    "    # 7-Specify whether to include sequence(s) of interest to query in alignment outputs.\n",
    "    print(\"\"\"      \n",
    "-----------------------------------------------------------------\n",
    "Optional: Nucleotide sequence(s) to identify in output alignments\n",
    "-----------------------------------------------------------------\n",
    "    \n",
    "Some applications of 'allele definition' and 'genotype inferral' may call for identification of the presence\n",
    "or absence of a specific anticipated sub-sequence (few nucleotides), and/or for the mapping of the location of\n",
    "a sub-sequence if present in the sequence alignment.\n",
    "    \n",
    "Genotypes.py allows for the optional testing of sub-sequences.\n",
    "    \n",
    "If you would like to specify subsequences, type 'Yes' and press Enter.\n",
    "Otherwise, if you do not wish to specify subsequences, type 'No' and press Enter.\"\"\"+'\\n')\n",
    "    test_seq = input(\"\"\"    -----> 'Yes' or 'No' to sub-sequence specification:  \"\"\")\n",
    "    if test_seq == 'Yes':\n",
    "        print(\"\"\"  \n",
    "--------------------------------------------------------------------------------------------------\n",
    "Nucleotide sequence(s): guide RNA annealing sites and/or test for presence/absence of sub-sequence\n",
    "--------------------------------------------------------------------------------------------------\"\"\")\n",
    "        # 7a-Collect guide RNA sequence details.\n",
    "        print(\"\"\"\n",
    "............................................................\n",
    "***** guide RNA details: specify guide RNA sequence(s) *****\n",
    "    \n",
    "To specify guide RNA sequence(s), enter text for each directly at the command line,\n",
    "separated by a comma ('x,y').\n",
    "    \n",
    "Please specify guide RNA sequence(s) [excluding PAM]:\n",
    "    \n",
    "When text entries are entered, press ‘enter’ again to proceed in the script.\n",
    "To skip text entries for these fields, simply press ‘enter’ until the next prompt appears.\n",
    "\n",
    "Examples:\n",
    "    If your single guide RNA sequence is 'ATCCAGTTCTCCAGTCTCCC', enter: 'ATCCAGTTCTCCAGTCTCCC'.\n",
    "    If you have two guide RNA sequences and they are 'ATCCAGTTCTCCAGTCTCCC' and 'GCGAGCTCGTGTCTGTGACG',\n",
    "    enter: 'ATCCAGTTCTCCAGTCTCCC, GCGAGCTCGTGTCTGTGACG'.\"\"\"+'\\n')\n",
    "        guideRNA_seq_temp = input(r\"\"\"    -----> guide RNA sequence(s):  \"\"\")\n",
    "        guideRNA_seq = [i.strip() for i in guideRNA_seq_temp.split(',')]\n",
    "        # 7b-Collect sub-sequence details (extant in allele or not?).\n",
    "        print(\"\"\"\n",
    "......................................................................................\n",
    "***** query DNA sequence(s): specify sequence(s) to test for presence or absence *****\n",
    "    \n",
    "To specify query DNA sequence(s), enter text for each directly at the command line,\n",
    "separated by a comma ('x,y').\n",
    "    \n",
    "Please specify short DNA sequence to test for presence vs. ablation.\n",
    "    \n",
    "When text entries are entered, press ‘enter’ again to proceed in the script.\n",
    "To skip text entries for these fields, simply press ‘enter’ until the next prompt appears.\n",
    "\n",
    "Examples:\n",
    "    If your single query sequence is 'TACTCAATATCGATC', enter: 'TACTCAATATCGATC'.\n",
    "    If you have two query sequences and they are 'TACTCAATATCGATC' and 'CGGGAGCCCGAG', enter:\n",
    "    'TACTCAATATCGATC, CGGGAGCCCGAG'.\"\"\"+'\\n')\n",
    "        extant_seq_temp = input(r\"\"\"    -----> query DNA sequence(s):  \"\"\")\n",
    "        extant_seq = [i.strip() for i in extant_seq_temp.split(',')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*'merge' and 'merge1' define functions that merge R1 & R2 (reverse complement), or append if they do not overlap; nt_dict is called upon to reverse complement R2* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'merge' function to merge R1 & R2 reads\n",
    "def merge(s1, s2):\n",
    "    i = 0\n",
    "    while not s2.startswith(s1[i:]):\n",
    "        i += 1\n",
    "    if i < len(s2):\n",
    "        return s1[:i] + s2\n",
    "    else:\n",
    "        return 'no overlap'\n",
    "    \n",
    "# Define 'merge1' function to append two strings that do not overlap\n",
    "def merge1(s1, s2):\n",
    "    i = 0\n",
    "    while not s2.startswith(s1[i:]):\n",
    "        i += 1\n",
    "    return s1[:i] + s2\n",
    "\n",
    "# Define nt complement dictionary, for use in generating DNA sequence complements   \n",
    "nt_dict = {'A':'T', 'T':'A', 'G':'C', 'C':'G', 'N':'N', '-':'-'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*'allele_output' defines a function that is called upon when populating the 'genotypes.txt' output file; the function reports alleles for samples that belong to a specified genotype class (e.g., homozygous deletion)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define 'allele_output' function to report defined alleles for samples based on genotype class designation\n",
    "def allele_output(genotype_class):\n",
    "    \"\"\"\n",
    "    This function outputs allele definitions for samples belonging to a specified class of inferred genotypes\n",
    "    \"\"\"\n",
    "    for i in genotype_class:\n",
    "        file.write(i+'\\n'+(18+len(imputedgenotypes_dict.get(i)[0]))*'*'+'\\n'+'INFERRED GENOTYPE: '+imputedgenotypes_dict.get(i)[0]+'\\n'+(18+len(imputedgenotypes_dict.get(i)[0]))*'*'+'\\n\\n')\n",
    "        read_checklist = []\n",
    "        read_abundance_checklist = []\n",
    "        for n in range(1, len(imputedgenotypes_dict.get(i))):\n",
    "            if imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[1] == 'R1+R2':\n",
    "                if 'R1+R2' not in read_checklist:\n",
    "                    read_checklist.append('R1+R2')\n",
    "                    file.write('\\n'+3*' '+'*'+17*'~'+'*\\n'+3*' '+'| READ 1 + READ 2 |\\n'+3*' '+'*'+17*'~'+'*\\n\\n')\n",
    "                else:\n",
    "                    pass\n",
    "                if float(imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[4].split(':')[1]) < 10:\n",
    "                    if 'R1dregs' not in read_abundance_checklist:\n",
    "                        read_abundance_checklist.append('R1dregs')\n",
    "                        file.write(3*' '+'*'+56*'~'+'*\\n'+3*' '+'|  >>>>> remaining alleles occur at frequency <10% <<<<< |\\n'+3*' '+'*'+56*'~'+'*\\n\\n')\n",
    "                    else:\n",
    "                        pass\n",
    "            if imputedgenotypes_dict.get(i)[n][1].get('allele_type') == 'wild-type':\n",
    "                file.write(3*' '+'Allele: '+imputedgenotypes_dict.get(i)[n][0].get('allele_name')+' | '+imputedgenotypes_dict.get(i)[n][1].get('allele_type')+'\\n    Locus: '+imputedgenotypes_dict.get(i)[n][0].get('chr+build')+', '+imputedgenotypes_dict.get(i)[n][0].get('locusID')+' '+imputedgenotypes_dict.get(i)[n][0].get('coordinates')+'\\n')\n",
    "            else:\n",
    "                file.write(3*' '+'Allele: '+imputedgenotypes_dict.get(i)[n][0].get('allele_name')+' | '+imputedgenotypes_dict.get(i)[n][1].get('allele_type')+', '+imputedgenotypes_dict.get(i)[n][1].get('allele_specs')+'\\n    Locus: '+imputedgenotypes_dict.get(i)[n][0].get('chr+build')+', '+imputedgenotypes_dict.get(i)[n][0].get('locusID')+' '+imputedgenotypes_dict.get(i)[n][0].get('coordinates')+'\\n')           \n",
    "            for guide in imputedgenotypes_dict.get(i)[n][2]:\n",
    "                if imputedgenotypes_dict.get(i)[n][2].get(guide) != 'None':\n",
    "                    if guide in guideRNA_seq:\n",
    "                        file.write('\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))-2)*' '+\"5'-\"+guide+\"-3' (guide sequence)\"+'\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))+len(guide)-3)*' '+'v')\n",
    "                    elif guide in guideRNA_seq_rev:\n",
    "                        file.write('\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))-2)*' '+\"3'-\"+guide+\"-5' (guide sequence)\"+'\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))+4)*' '+'v')\n",
    "            file.write(imputedgenotypes_dict.get(i)[n][0].get('alignment'))\n",
    "            for seq in imputedgenotypes_dict.get(i)[n][3]:\n",
    "                if imputedgenotypes_dict.get(i)[n][3].get(seq) != 'None':\n",
    "                    file.write('\\n')\n",
    "                    if seq in extant_seq:\n",
    "                        file.write((1+int(imputedgenotypes_dict.get(i)[n][3].get(seq)))*' '+len(seq)*'^'+'\\n'+(int(imputedgenotypes_dict.get(i)[n][3].get(seq))-2)*' '+\"5'-\"+seq+\"-3' (sequence of interest)\\n\")\n",
    "                    elif seq in extant_seq_rev:\n",
    "                        file.write((1+int(imputedgenotypes_dict.get(i)[n][3].get(seq)))*' '+len(seq)*'^'+'\\n'+(int(imputedgenotypes_dict.get(i)[n][3].get(seq))-2)*' '+\"3'-\"+seq+\"-5' (sequence of interest)\\n\")\n",
    "                elif imputedgenotypes_dict.get(i)[n][3].get(seq) == 'None':\n",
    "                    file.write('\\n')\n",
    "            file.write('\\n')\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define 'frequency_plots' function to plot sample allele frequency metrics for visualization in pdf file\n",
    "def frequency_plots():\n",
    "    \"\"\"\n",
    "    This function plots sample allele frequency metrics for visualization in a pdf file\n",
    "    \"\"\"\n",
    "    # Make variable assigned in frequency_plots() function globally available\n",
    "    global frequencyplotsDuration\n",
    "    # Start the clock on plot time duration\n",
    "    startTime_frequencyplots = datetime.now()\n",
    "    # Assign allele_evidence.pdf file to output path\n",
    "    allele_evidence_output = Path(str(output_path)+'/'+processdate+'_allele_evidence.pdf')\n",
    "    # Initiate PDF file to record allele frequency plots for each sample\n",
    "    pdf = FPDF(format='letter')\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=20, style='B')\n",
    "    pdf.ln(20)\n",
    "    pdf.write(5, 'Frequency plots to support inferred genotypes')\n",
    "    pdf.output(allele_evidence_output)\n",
    "    # Generate allele frequency plots for each sample, based on the following principles and frequency metrics:\n",
    "    # for each sample, up to 10 candidate alleles are 'ranked' based on relative read frequency in the initial fastq file\n",
    "    # four frequency plots are generated, (1) raw read frequency relative to all other reads, (2) frequency relative to the\n",
    "    # top 10 most abundant reads, (3) frequency relative to reads that occur at >1% raw abundance; (4) frequency relative to\n",
    "    # reads that occur at >10% raw abundance\n",
    "    for samplename in imputedgenotypes_dict:\n",
    "        plot_name = output_directory / (samplename+'_plot.png')\n",
    "        pdf_output = output_directory / (samplename+'_.pdf')\n",
    "        R1R2_allele_list = []\n",
    "        R1R2_allele_names = []\n",
    "        R1R2_allele_frequency = []\n",
    "        R1R2_allele_type = []\n",
    "        R1R2_allele_specs = []\n",
    "        for x in range(1, len(imputedgenotypes_dict[samplename])):\n",
    "            if imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[1] == 'R1+R2':\n",
    "                R1R2_allele_list.append(imputedgenotypes_dict[samplename][x][0].get('allele_name'))\n",
    "                R1R2_allele_type.append(imputedgenotypes_dict[samplename][x][1].get('allele_type'))\n",
    "                R1R2_allele_specs.append(imputedgenotypes_dict[samplename][x][1].get('allele_specs'))\n",
    "        for i in range(1, len(R1R2_allele_list)+1):\n",
    "            R1R2_allele_names.append(i)\n",
    "        for i in R1R2_allele_list:\n",
    "            R1R2_allele_frequency.append(float(i.split(' ')[4].split(':')[1]))\n",
    "# \n",
    "        x1 = R1R2_allele_names\n",
    "#\n",
    "        N = len(R1R2_allele_names)\n",
    "        width = 0.4\n",
    "        spacing1 = [float(i) for i in range(1,N+1)]\n",
    "#\n",
    "        y1a = R1R2_allele_frequency\n",
    "        while len(y1a) < N:\n",
    "            y1a.append(float(0))\n",
    "        label_list_a = [value for value in zip(x1,y1a,spacing1,R1R2_allele_type,R1R2_allele_specs)]\n",
    "#\n",
    "        R1R2_allele_frequency_top10 = []\n",
    "        for i in R1R2_allele_list:\n",
    "            freq1 = i.split(' ')[6].split(':')[1]\n",
    "            R1R2_allele_frequency_top10.append(float(freq1) if freq1 != 'None' else 0)\n",
    "        y1b = R1R2_allele_frequency_top10\n",
    "        while len(y1b) < N:\n",
    "            y1b.append(float(0))\n",
    "        label_list_b = [value for value in zip(x1,y1b,spacing1,R1R2_allele_type,R1R2_allele_specs)]\n",
    "    \n",
    "#\n",
    "        R1R2_allele_frequency_1 = []\n",
    "        for i in R1R2_allele_list:\n",
    "            freq1 = i.split(' ')[7].split(':')[1]\n",
    "            R1R2_allele_frequency_1.append(float(freq1) if freq1 != 'None' else 0)\n",
    "        y1c = R1R2_allele_frequency_1\n",
    "        while len(y1c) < N:\n",
    "            y1c.append(float(0))\n",
    "        label_list_c = [value for value in zip(x1,y1c,spacing1,R1R2_allele_type,R1R2_allele_specs)]\n",
    "#\n",
    "        R1R2_allele_frequency_10 = []\n",
    "        for i in R1R2_allele_list:\n",
    "            freq1 = i.split(' ')[8].split(':')[1]\n",
    "            R1R2_allele_frequency_10.append(float(freq1) if freq1 != 'None' else 0)\n",
    "        y1d = R1R2_allele_frequency_10\n",
    "        while len(y1d) < N:\n",
    "            y1d.append(float(0))\n",
    "        label_list_d = [value for value in zip(x1,y1d,spacing1,R1R2_allele_type,R1R2_allele_specs)]\n",
    "#\n",
    "# Plots\n",
    "        fig = plt.figure(figsize=(11,7), dpi=250)\n",
    "# Subplot 1\n",
    "        ax1 = fig.add_subplot(141)\n",
    "        ax1.grid(color='#808080', linestyle='--', linewidth=0.2, axis='x', zorder=0)\n",
    "        rects1 = ax1.barh(spacing1, y1a, width, color='#87CEFA', alpha=1, edgecolor='black', linewidth=0.5, align='center', zorder=2, label='  R1\\n+R2')\n",
    "        ax1.set_ylabel('Allele Rank', fontsize=10, fontname='Arial', alpha=0.8)\n",
    "        ax1.set_xlabel('Frequency', fontsize=10, fontname='Arial', alpha=0.8)\n",
    "        ax1.set_title('Allele frequencies\\n(% total reads)', fontsize=8.5, fontweight='bold', fontname='Arial')\n",
    "        plt.xlim([0,110])\n",
    "        plt.ylim([0.5, N+0.5])\n",
    "        plt.gca().invert_yaxis()\n",
    "        ax1 = plt.gca()\n",
    "        ax1.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax1.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "        ax1.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.legend(loc = 'lower right', frameon=True, fontsize=7)\n",
    "        ax1.spines['bottom'].set_color('grey')\n",
    "        ax1.spines['top'].set_color('grey')\n",
    "        ax1.spines['left'].set_color('grey')\n",
    "        ax1.tick_params(which='both', color='grey', labelcolor='grey')\n",
    "        for i in label_list_a:\n",
    "            if i[1] != 0:\n",
    "                if i[1] > 20:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax1.text(i[1]/10, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', weight = 'bold', fontsize=7)\n",
    "                        ax1.text(i[1]/10, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax1.text(i[1]/10, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', weight = 'bold', fontsize=7)\n",
    "                else:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax1.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', fontsize=7)\n",
    "                        ax1.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax1.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', fontsize=7)\n",
    "#\n",
    "# Subplot 2\n",
    "        ax2 = fig.add_subplot(142)\n",
    "        ax2.grid(color='#808080', linestyle='--', linewidth=0.2, axis='x', zorder=0)\n",
    "        rects1 = ax2.barh(spacing1, y1b, width, color='#87CEFA', alpha=1, edgecolor='black', linewidth=0.5, align='center', zorder=2, label='  R1\\n+R2')\n",
    "        ax2.set_ylabel('Allele Rank', fontsize=10, fontname='Arial', alpha=0.8)\n",
    "        ax2.set_xlabel('Frequency', fontsize=10, fontname='Arial', alpha=0.8)\n",
    "        ax2.set_title('Allele frequencies\\n(% top 10 most abundant reads)', fontsize=8.5, fontweight='bold', fontname='Arial')\n",
    "        plt.xlim([0,110])\n",
    "        plt.ylim([0.5, N+0.5])\n",
    "        plt.gca().invert_yaxis()\n",
    "        ax2 = plt.gca()\n",
    "        ax2.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "        ax2.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.legend(loc = 'lower right', frameon=True, fontsize=7)\n",
    "        ax2.spines['bottom'].set_color('grey')\n",
    "        ax2.spines['top'].set_color('grey')\n",
    "        ax2.spines['left'].set_color('grey')\n",
    "        ax2.tick_params(which='both', color='grey', labelcolor='grey')\n",
    "        for i in label_list_b:\n",
    "            if i[1] != 0:\n",
    "                if i[1] > 20:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax2.text(i[1]/10, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', weight = 'bold', fontsize=7)\n",
    "                        ax2.text(i[1]/10, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax2.text(i[1]/10, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', weight = 'bold', fontsize=7)\n",
    "                else:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax2.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', fontsize=7)\n",
    "                        ax2.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax2.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', fontsize=7)\n",
    "#\n",
    "# Subplot 3       \n",
    "        ax3 = fig.add_subplot(143)\n",
    "        ax3.grid(color='#808080', linestyle='--', linewidth=0.2, axis='x', zorder=0)\n",
    "        rects1 = ax3.barh(spacing1, y1c, width, color='#87CEFA', alpha=1, edgecolor='black', linewidth=0.5, align='center', zorder=2, label='  R1\\n+R2')\n",
    "        ax3.set_ylabel('Allele Rank', fontsize=10, fontname='Arial', alpha=0.8)\n",
    "        ax3.set_xlabel('Frequency', fontsize=10, fontname='Arial', alpha=0.8)\n",
    "        ax3.set_title('Allele frequencies\\n(% reads adjusted for frequency >1%)', fontsize=8.5, fontweight='bold', fontname='Arial')\n",
    "        plt.xlim([0,110])\n",
    "        plt.ylim([0.5, N+0.5])\n",
    "        plt.gca().invert_yaxis()\n",
    "        ax3 = plt.gca()\n",
    "        ax3.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax3.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "        ax3.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax3.spines['right'].set_visible(False)\n",
    "        ax3.legend(loc = 'lower right', frameon=True, fontsize=7)\n",
    "        ax3.spines['bottom'].set_color('grey')\n",
    "        ax3.spines['top'].set_color('grey')\n",
    "        ax3.spines['left'].set_color('grey')\n",
    "        ax3.tick_params(which='both', color='grey', labelcolor='grey')\n",
    "        for i in label_list_c:\n",
    "            if i[1] != 0:\n",
    "                if i[1] > 20:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax3.text(i[1]/10, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', weight = 'bold', fontsize=7)\n",
    "                        ax3.text(i[1]/10, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax3.text(i[1]/10, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', weight = 'bold', fontsize=7)\n",
    "                else:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax3.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', fontsize=7)\n",
    "                        ax3.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax3.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', fontsize=7)\n",
    "#\n",
    "# Subplot 4\n",
    "        ax4 = fig.add_subplot(144)\n",
    "        ax4.grid(color='#808080', linestyle='--', linewidth=0.2, axis='x', zorder=0)\n",
    "        rects1 = ax4.barh(spacing1, y1d, width, color='#87CEFA', alpha=1, edgecolor='black', linewidth=0.5, align='center', zorder=2, label='  R1\\n+R2')\n",
    "        ax4.set_ylabel('Allele Rank', fontsize=10, fontname='Arial', alpha=0.8)\n",
    "        ax4.set_xlabel('Frequency', fontsize=10, fontname='Arial', alpha=0.8)\n",
    "        ax4.set_title('Allele frequencies\\n(% reads adjusted for frequency >10%)', fontsize=8.5, fontweight='bold', fontname='Arial')\n",
    "        plt.xlim([0,110])\n",
    "        plt.ylim([0.5, N+0.5])\n",
    "        plt.gca().invert_yaxis()\n",
    "        ax4 = plt.gca()\n",
    "        ax4.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax4.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "        ax4.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax4.spines['right'].set_visible(False)\n",
    "        ax4.legend(loc = 'lower right', frameon=True, fontsize=7)\n",
    "        ax4.spines['bottom'].set_color('grey')\n",
    "        ax4.spines['top'].set_color('grey')\n",
    "        ax4.spines['left'].set_color('grey')\n",
    "        ax4.tick_params(which='both', color='grey', labelcolor='grey')\n",
    "        for i in label_list_d:\n",
    "            if i[1] != 0:\n",
    "                if i[1] > 20:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax4.text(i[1]/10, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', weight = 'bold', fontsize=7)\n",
    "                        ax4.text(i[1]/10, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax4.text(i[1]/10, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', weight = 'bold', fontsize=7)\n",
    "                else:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax4.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', fontsize=7)\n",
    "                        ax4.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax4.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', fontsize=7)\n",
    "        plt.tight_layout()\n",
    "#\n",
    "        plt.savefig(plot_name, format='png', dpi=250)\n",
    "        plt.close(fig)\n",
    "#   \n",
    "        pdf = FPDF('L', 'mm', (400, 250))\n",
    "        pdf.add_page()\n",
    "        pdf.set_font(\"Arial\", size=8, style='BU')\n",
    "        pdf.write(5, samplename)\n",
    "        pdf.ln(3)\n",
    "        pdf.set_font(\"Arial\", size=7)\n",
    "        pdf.write(5, 'inferred genotype: '+imputedgenotypes_dict[samplename][0].split('|')[1]+','+imputedgenotypes_dict[samplename][0].split('|')[2])\n",
    "        pdf.ln(5)\n",
    "        allele_count_R1R2 = 1\n",
    "        read1read2_check = []\n",
    "        for x in range(1, len(imputedgenotypes_dict[samplename])):\n",
    "            if imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[1] == 'R1+R2':\n",
    "                if imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[8].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[8].split(':')[1]) > 20:\n",
    "                    if len(read1read2_check) == 0:\n",
    "                        read1read2_check.append('R1+R2')\n",
    "                        pdf.set_font(\"Arial\", size=7, style='U')\n",
    "                        pdf.write(5, 'R1+R2, sequences with >20% representation among reads:')\n",
    "                        pdf.ln(3)\n",
    "                    else:\n",
    "                        pass\n",
    "                    pdf.set_font(\"Courier\", size=6)\n",
    "                    if len(imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[1]) > 200:\n",
    "                        string = imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[1]\n",
    "                        string2 = imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[2]\n",
    "                        string3 = imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[3]\n",
    "                        chunks = range(12, len(string), 100)\n",
    "                        for index, chunk in enumerate(chunks):\n",
    "                            if index == 0:\n",
    "                                pdf.write(5, string[chunk-12:chunk+100])\n",
    "                                pdf.ln(3)\n",
    "                                pdf.write(5, string2[chunk-12:chunk+100])\n",
    "                                pdf.ln(3)\n",
    "                                pdf.write(5, string3[chunk-12:chunk+100])\n",
    "                            elif 0 < index < (len(chunks)-1):\n",
    "                                pdf.write(5, '\\n'+4*' '+'query'+'  '+string[chunk:chunk+100])\n",
    "                                pdf.ln(3)\n",
    "                                pdf.write(5, 11*' '+string2[chunk:chunk+100])\n",
    "                                pdf.ln(3)\n",
    "                                pdf.write(5, 'reference'+'  '+string3[chunk:chunk+100])\n",
    "                            else:\n",
    "                                pdf.write(5, '\\n'+4*' '+'query'+'  '+string[chunk:])\n",
    "                                pdf.ln(3)\n",
    "                                pdf.write(5, 11*' '+string2[chunk:])\n",
    "                                pdf.ln(3)\n",
    "                                pdf.write(5, 'reference'+'  '+string3[chunk:])\n",
    "                        allele_count_R1R2 = allele_count_R1R2+1\n",
    "                        pdf.ln(4)\n",
    "                    else:\n",
    "                        pdf.write(5, imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[1])\n",
    "                        pdf.ln(3)\n",
    "                        pdf.write(5, imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[2])\n",
    "                        pdf.ln(3)\n",
    "                        pdf.write(5, imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[3])\n",
    "                        allele_count_R1R2 = allele_count_R1R2+1\n",
    "                        pdf.ln(4)\n",
    "        pdf.ln(5)\n",
    "        pdf.image(str(plot_name), x = None, y = None, w = 195, h = 0, type = '', link = '')\n",
    "        pdf.output(str(pdf_output))\n",
    "#    \n",
    "        merger = PdfFileMerger()\n",
    "#   \n",
    "        filenames =[str(allele_evidence_output), str(pdf_output)]\n",
    "#\n",
    "        for filename in filenames:\n",
    "            merger.append(PdfFileReader(filename, 'rb'))\n",
    "#   \n",
    "        merger.write(str(allele_evidence_output))\n",
    "    # Remove sample png file and pdf file as intermediaries\n",
    "        try:\n",
    "            os.remove(plot_name)\n",
    "        except OSError:\n",
    "            pass\n",
    "#    \n",
    "        try:\n",
    "            os.remove(pdf_output)\n",
    "        except OSError:\n",
    "            pass  \n",
    "# Log frequency plotting time duration\n",
    "    frequencyplotsDuration = str(datetime.now()- startTime_frequencyplots).split(':')[0]+' hr|'+str(datetime.now() - startTime_frequencyplots).split(':')[1]+' min|'+str(datetime.now() - startTime_frequencyplots).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_frequencyplots).split(':')[2].split('.')[1]+' microsec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*'convert_bytes' and 'path_size' define functions that are used when populating 'script_metrics.txt' with script directory and file size metadata; 'convert_bytes' reframes a path size (in bytes) to a higher-order of magnitude, if appropriate (e.g., KB, MB, GB, TB); 'path_size' defines a function that returns file or directory size (in bytes, KB, MB, GB, or TB)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define 'convert_bytes' function to be used in data collection for script_metrics.txt\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    This function converts bytes to convenient order of magnitude prefixes\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "        \n",
    "# Define 'path_size' function to be used in data collection for script_metrics.txt\n",
    "def path_size(given_path):\n",
    "    \"\"\"\n",
    "    This function returns file or directory size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(given_path):\n",
    "        file_info = os.stat(given_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "    elif os.path.isdir(given_path):\n",
    "        dir_info = os.stat(given_path)\n",
    "        return convert_bytes(dir_info.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### II. Define user-specified variables\n",
    "\n",
    "A user defines input variables by entering individual lines of text at the Jupyter interface.  \n",
    "\n",
    "Up to 7 variables will now be defined as inputs (see **'User inputs'** above). \n",
    "\n",
    "First, specify whether user input is provided at individually coached prompts (**'Prompt'**) or in rapid succession that bypasses detailed prompts (**'List'**).\n",
    "\n",
    "In either format, a user will also be asked whether **optional DNA sub-sequence(s)** will be provided, to map onto sequence alignments. Specifically, the script classifies these optional sub-sequences as either **guide RNA sequences** (5'->3' in DNA form, excluding PAM) or **test sequences** (5'->3', to query for presence/absence in aligned sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "User-specified input: choice of coached prompts vs. single-list entry\n",
      "---------------------------------------------------------------------\n",
      "    \n",
      "Values for the user-specified input indicated above can be entered at individually coached command-line prompts\n",
      "(default), or as a single list of variables provided in a single command-line entry without coached prompts.\n",
      "    \n",
      "To proceed with input at individual command-line PROMPTS, type 'Prompt' and press Enter;\n",
      "To proceed with input provided as a single LIST in one command-line entry, type 'List' and press Enter:  List\n",
      "\n",
      "\n",
      "You specified LIST format to specify input values.\n",
      "..............................................................................................................\n",
      "Some applications of 'allele definition' and 'genotype inferral' may call for identification of the presence\n",
      "or absence of a specific anticipated sub-sequence (few nucleotides), and/or for the mapping of the location of\n",
      "a sub-sequence if present in the sequence alignment.\n",
      "    \n",
      "Genotypes.py allows for the optional testing of sub-sequences.\n",
      "    \n",
      "If you would like to specify subsequences, type 'Yes' and press Enter.\n",
      "Otherwise, if you do not wish to specify subsequences, type 'No' and press Enter.\n",
      "\n",
      "    -----> 'Yes' or 'No' to sub-sequence specification:  Yes\n",
      "    \n",
      "    Will you specify guide RNA sequence(s) to map onto output alignments?\n",
      "    -----> 'Yes' or 'No' to guide RNA specification:  Yes\n",
      "    \n",
      "    Will you specify query DNA sequence(s) (sequence(s) to test for presence or absence) to map onto output\n",
      "    alignments?\n",
      "    -----> 'Yes' or 'No' to query sub-sequence specification:  Yes\n",
      "\n",
      "----------------------------------\n",
      "User-specified input (list format)\n",
      "----------------------------------\n",
      "Please paste input values directly at the interpreter prompt, specifying the following 8 values:\n",
      "\n",
      "    1-Location of OUTPUT DIRECTORY for output files\n",
      "    2-Location of INPUT FILES (directory containing fastq files)\n",
      "    3-Location of BLASTN EXECUTABLE\n",
      "    4-Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
      "    5-Prefix common to BLASTN sequence database files\n",
      "    6-Location of BLASTDBCMD EXECUTABLE\n",
      "    7-Optional guide RNA sequence(s) to identify in output alignments\n",
      "    8-Optional sub-sequence(s) to identify in output alignments\n",
      "\n",
      "** Input the values in the specified order in a single line of text\n",
      "** Separate each value by a single semicolon (';')\n",
      "    \n",
      "For example:\n",
      "\n",
      "/Users/myname/GenotypesOutput; /Users/myname/fastq_files; /Users/myname/bin/blastn; /Users/myname/blastn_database;\n",
      "GRCh38; /Users/myname/bin/blastdbcmd; GTGCCAGCCACATTCAGAAC; AGAACAGGGTGTTCTG\n",
      "\n",
      "Press 'Enter' twice to complete.\n",
      "\n",
      "    \n",
      "/Users/kirkehmsen/Documents/GenotypesOutputGit2; /Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/fastq_files_subset; /Users/kirkehmsen/anaconda3/bin/blastn; /Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/blastn_database; GRCh38; /Users/kirkehmsen/anaconda3/bin/blastdbcmd; GTGCCAGCCACATTCAGAAC; AGAACAGGGTGTTCTG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Specify 'Prompt' or 'List' format for entry of user-defined variables \n",
    "user_input = input(r\"\"\"\n",
    "---------------------------------------------------------------------\n",
    "User-specified input: choice of coached prompts vs. single-list entry\n",
    "---------------------------------------------------------------------\n",
    "    \n",
    "Values for the user-specified input indicated above can be entered at individually coached command-line prompts\n",
    "(default), or as a single list of variables provided in a single command-line entry without coached prompts.\n",
    "    \n",
    "To proceed with input at individual command-line PROMPTS, type 'Prompt' and press Enter;\n",
    "To proceed with input provided as a single LIST in one command-line entry, type 'List' and press Enter:  \"\"\")\n",
    "\n",
    "if user_input == 'Prompt':\n",
    "    prompts()\n",
    "elif user_input == 'List':\n",
    "    print(\"\"\"\n",
    "\n",
    "You specified LIST format to specify input values.\n",
    "..............................................................................................................\n",
    "Some applications of 'allele definition' and 'genotype inferral' may call for identification of the presence\n",
    "or absence of a specific anticipated sub-sequence (few nucleotides), and/or for the mapping of the location of\n",
    "a sub-sequence if present in the sequence alignment.\n",
    "    \n",
    "Genotypes.py allows for the optional testing of sub-sequences.\n",
    "    \n",
    "If you would like to specify subsequences, type 'Yes' and press Enter.\n",
    "Otherwise, if you do not wish to specify subsequences, type 'No' and press Enter.\"\"\"+'\\n')\n",
    "    test_seq = input(r\"\"\"    -----> 'Yes' or 'No' to sub-sequence specification:  \"\"\")\n",
    "    if test_seq == 'Yes':\n",
    "        print(r\"\"\"    \n",
    "    Will you specify guide RNA sequence(s) to map onto output alignments?\"\"\")\n",
    "        user_input2 = input(r\"\"\"    -----> 'Yes' or 'No' to guide RNA specification:  \"\"\")\n",
    "        print(r\"\"\"    \n",
    "    Will you specify query DNA sequence(s) (sequence(s) to test for presence or absence) to map onto output\n",
    "    alignments?\"\"\")\n",
    "        user_input3 = input(r\"\"\"    -----> 'Yes' or 'No' to query sub-sequence specification:  \"\"\")\n",
    "        if user_input2 == 'Yes' and user_input3 == 'Yes':\n",
    "            print(r\"\"\"\n",
    "----------------------------------\n",
    "User-specified input (list format)\n",
    "----------------------------------\n",
    "Please paste input values directly at the interpreter prompt, specifying the following 8 values:\n",
    "\n",
    "    1-Location of OUTPUT DIRECTORY for output files\n",
    "    2-Location of INPUT FILES (directory containing fastq files)\n",
    "    3-Location of BLASTN EXECUTABLE\n",
    "    4-Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
    "    5-Prefix common to BLASTN sequence database files\n",
    "    6-Location of BLASTDBCMD EXECUTABLE\n",
    "    7-Optional guide RNA sequence(s) to identify in output alignments\n",
    "    8-Optional sub-sequence(s) to identify in output alignments\n",
    "\n",
    "** Input the values in the specified order in a single line of text\n",
    "** Separate each value by a single semicolon (';')\n",
    "    \n",
    "For example:\n",
    "\n",
    "/Users/myname/GenotypesOutput; /Users/myname/fastq_files; /Users/myname/bin/blastn; /Users/myname/blastn_database;\n",
    "GRCh38; /Users/myname/bin/blastdbcmd; GTGCCAGCCACATTCAGAAC; AGAACAGGGTGTTCTG\n",
    "\n",
    "Press 'Enter' twice to complete.\n",
    "\n",
    "    \"\"\")\n",
    "            input_list = []\n",
    "            stopword = \"\"\n",
    "            while True:\n",
    "                input_str_temp = input()\n",
    "                if input_str_temp.strip() == stopword:\n",
    "                    break\n",
    "                else:\n",
    "                    input_str = input_str_temp.strip()\n",
    "            for x in input_str.split(';'):\n",
    "                input_list.append(x.strip())\n",
    "            output_directory = input_list[0].strip()\n",
    "            fastq_directory = input_list[1].strip()\n",
    "            blastn_path = input_list[2].strip()\n",
    "            db_path = input_list[3].strip()\n",
    "            db_prefix = input_list[4].strip()\n",
    "            blastdbcmd_path = input_list[5].strip()\n",
    "            guideRNA_seq = [i.strip() for i in input_list[6].split(',')]\n",
    "            extant_seq = [i.strip() for i in input_list[7].split(',')]\n",
    "        elif user_input2 == 'Yes' and user_input3 == 'No':\n",
    "            print(r\"\"\"\n",
    "----------------------------------\n",
    "User-specified input (list format)\n",
    "----------------------------------\n",
    "    \n",
    "Please paste input values directly at the interpreter prompt, specifying the following 7 values:\n",
    "\n",
    "    1-Location of OUTPUT DIRECTORY for output files\n",
    "    2-Location of INPUT FILES (directory containing fastq files)\n",
    "    3-Location of BLASTN EXECUTABLE\n",
    "    4-Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
    "    5-Location of BLASTDBCMD EXECUTABLE\n",
    "    6-Prefix common to BLASTN sequence database files\n",
    "    7-Optional guide RNA sequence(s) to identify in output alignments\n",
    "    \n",
    "** Input the values in the specified order in a single line of text\n",
    "** Separate each value by a single semicolon (';')\n",
    "    \n",
    "For example:\n",
    "\n",
    "/Users/myname/GenotypesOutput; /Users/myname/fastq_files; /Users/myname/bin/blastn; /Users/myname/blastn_database;\n",
    "GRCh38; /Users/myname/bin/blastdbcmd; GTGCCAGCCACATTCAGAAC\n",
    "\n",
    "Press 'Enter' twice to complete.\n",
    "    \n",
    "    \"\"\")\n",
    "            input_list = []\n",
    "            stopword = \"\"\n",
    "            while True:\n",
    "                input_str_temp = input()\n",
    "                if input_str_temp.strip() == stopword:\n",
    "                    break\n",
    "                else:\n",
    "                    input_str = input_str_temp.strip()\n",
    "            for x in input_str.split(';'):\n",
    "                input_list.append(x.strip())\n",
    "            output_directory = input_list[0].strip()\n",
    "            fastq_directory = input_list[1].strip()\n",
    "            blastn_path = input_list[2].strip()\n",
    "            db_path = input_list[3].strip()\n",
    "            db_prefix = input_list[4].strip()\n",
    "            blastdbcmd_path = input_list[5].strip()\n",
    "            guideRNA_seq = [i.strip() for i in input_list[6].split(',')]\n",
    "        elif user_input2 == 'No' and user_input3 == 'Yes':\n",
    "            print(r\"\"\"\n",
    "----------------------------------\n",
    "User-specified input (list format)\n",
    "----------------------------------\n",
    "    \n",
    "Please paste input values directly at the interpreter prompt, specifying the following 7 values:\n",
    "    \n",
    "    1-Location of OUTPUT DIRECTORY for output files\n",
    "    2-Location of INPUT FILES (directory containing fastq files)\n",
    "    3-Location of BLASTN EXECUTABLE\n",
    "    4-Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
    "    5-Prefix common to BLASTN sequence database files\n",
    "    6-Location of BLASTDBCMD EXECUTABLE\n",
    "    7-Optional sub-sequence(s) to identify in output alignments\n",
    "\n",
    "** Input the values in the specified order in a single line of text\n",
    "** Separate each value by a single semicolon (';')\n",
    "    \n",
    "For example:\n",
    "\n",
    "/Users/myname/GenotypesOutput; /Users/myname/fastq_files; /Users/myname/bin/blastn; /Users/myname/blastn_database;\n",
    "GRCh38; /Users/myname/bin/blastdbcmd; AGAACAGGGTGTTCTG\n",
    "\n",
    "Press 'Enter' twice to complete.\n",
    "    \n",
    "    \"\"\")  \n",
    "            input_list = []\n",
    "            stopword = \"\"\n",
    "            while True:\n",
    "                input_str_temp = input()\n",
    "                if input_str_temp.strip() == stopword:\n",
    "                    break\n",
    "                else:\n",
    "                    input_str = input_str_temp.strip()\n",
    "            for x in input_str.split(';'):\n",
    "                input_list.append(x.strip())\n",
    "            output_directory = input_list[0].strip()\n",
    "            fastq_directory = input_list[1].strip()\n",
    "            blastn_path = input_list[2].strip()\n",
    "            db_path = input_list[3].strip()\n",
    "            db_prefix = input_list[4].strip()\n",
    "            blastdbcmd_path = input_list[5].strip()\n",
    "            extant_seq = [i.strip() for i in input_list[6].split(',')]\n",
    "    elif test_seq == 'No':\n",
    "        print(r\"\"\"\n",
    "----------------------------------\n",
    "User-specified input (list format)\n",
    "----------------------------------\n",
    "    \n",
    "Please paste input values directly at the interpreter prompt, specifying the following 6 values:\n",
    "    \n",
    "    1-Location of OUTPUT DIRECTORY for output files\n",
    "    2-Location of INPUT FILES (directory containing fastq files)\n",
    "    3-Location of BLASTN EXECUTABLE\n",
    "    4-Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
    "    5-Prefix common to BLASTN sequence database files\n",
    "    6-Location of BLASTDBCMD EXECUTABLE\n",
    "\n",
    "** Input the values in the specified order in a single line of text\n",
    "** Separate each value by a single semicolon (';')\n",
    "    \n",
    "For example:\n",
    "\n",
    "/Users/myname/GenotypesOutput; /Users/myname/fastq_files; /Users/myname/bin/blastn; /Users/myname/blastn_database;\n",
    "GRCh38; /Users/myname/bin/blastdbcmd\n",
    "\n",
    "Press 'Enter' twice to complete.\n",
    "    \n",
    "    \"\"\")  \n",
    "        input_list = []\n",
    "        stopword = \"\"\n",
    "        while True:\n",
    "            input_str_temp = input()\n",
    "            if input_str_temp.strip() == stopword:\n",
    "                break\n",
    "            else:\n",
    "                input_str = input_str_temp.strip()\n",
    "        for x in input_str.split(';'):\n",
    "            input_list.append(x.strip())\n",
    "        output_directory = input_list[0].strip()\n",
    "        fastq_directory = input_list[1].strip()\n",
    "        blastn_path = input_list[2].strip()\n",
    "        db_path = input_list[3].strip()\n",
    "        db_prefix = input_list[4].strip()\n",
    "        blastdbcmd_path = input_list[5].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Convert directory and executable strings to operating system-appropriate paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Wait to create the directories and files until after input has been reviewed and accepted.\n",
    "# Convert fastq_directory input to operating system-appropriate filepath.\n",
    "output_directory = Path(str(output_directory))\n",
    "# Convert fastq_directory input to operating system-appropriate filepath.\n",
    "fastq_directory = Path(str(fastq_directory))\n",
    "# Convert blastn_path input to operating system-appropriate filepath.\n",
    "blastn_path = Path(str(blastn_path))\n",
    "# Convert db_path input to operating system-appropriate filepath.\n",
    "db_path = Path(str(db_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Collect fastq files from directory; sort alphanumerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "myFastqFilenames = [file for file in glob.glob(str(fastq_directory)+'/*') if Path(file).suffix in [\".gz\",\".fastq\"]]\n",
    "\n",
    "#Sort fastq file names\n",
    "myFastqFilenames = sorted(myFastqFilenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Print fastq file names, to double-check file inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/fastq_files_subset/KE4-1-C02_S1178_L001_R1_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/fastq_files_subset/KE4-1-C02_S1178_L001_R2_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/fastq_files_subset/KE4-2-A01_S1249_L001_R1_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/fastq_files_subset/KE4-2-A01_S1249_L001_R2_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/fastq_files_subset/KE4-4-G02_S1514_L001_R1_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/fastq_files_subset/KE4-4-G02_S1514_L001_R2_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/fastq_files_subset/KE4-4-G10_S1522_L001_R1_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/fastq_files_subset/KE4-4-G10_S1522_L001_R2_001.fastq\n"
     ]
    }
   ],
   "source": [
    "for file in myFastqFilenames:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Collect overview of fastq file contents:  \n",
    "<ul>\n",
    "  <li>Illumina runID</li>   \n",
    "  <li>read count in each fastq file</li>    \n",
    "  <li>file size</li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Collect Illumina run IDs from fastq files, consolidate to unique run IDs\n",
    "runIDlist = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    if Path(sourcefile).suffix == \".gz\":\n",
    "        with gzip.open(sourcefile, \"rt\") as f:\n",
    "            runID = \":\".join(f.readline().split(\":\",-2)[:2])\n",
    "            if not runID in runIDlist:\n",
    "                runIDlist.append(runID) \n",
    "    elif Path(sourcefile).suffix == \".fastq\":\n",
    "        with open(sourcefile, \"r\") as f:\n",
    "            runID = \":\".join(f.readline().split(\":\",-2)[:2])\n",
    "            if not runID in runIDlist:\n",
    "                runIDlist.append(runID)\n",
    "\n",
    "# Collect total read counts for fastq files\n",
    "readcount = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    if Path(sourcefile).suffix == \".gz\":\n",
    "        with gzip.open(sourcefile, \"rt\") as f:    \n",
    "            readcount.append(int(len((f).readlines())/4))\n",
    "    elif Path(sourcefile).suffix == \".fastq\":\n",
    "        with open(sourcefile, \"r\") as f:\n",
    "            readcount.append(int(len((f).readlines())/4))\n",
    "        \n",
    "# Collect file sizes for fastq files\n",
    "filesize = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    if Path(sourcefile).suffix == \".gz\":\n",
    "        with gzip.open(sourcefile, \"rt\") as f:\n",
    "            filesize.append(round((os.path.getsize(sourcefile)/1048576),5))\n",
    "    elif Path(sourcefile).suffix == \".fastq\":\n",
    "        filesize.append(round((os.path.getsize(sourcefile)/1048576),5))\n",
    "\n",
    "# fastq_overview prepares summation of fastq file names, their sizes, and read counts, to be reported in script_metrics.txt    \n",
    "fastq_overview = list(zip(myFastqFilenames, filesize, readcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Double-check whether user-specified entries look good. If a variable is inaccurately assigned, prompt user to restart kernel to begin again.\n",
    "\n",
    "Retrieve and/or calculate the following properties across the fastq files to be processed (these values will be reported in script_metrics.txt):  \n",
    "<ul>\n",
    "  <li>Illumina sequencing run ID(s)</li>\n",
    "  <li>Total number of fastq files</li>\n",
    "  <li>Total number of sequencing reads</li>\n",
    "  <li>Size distribution of fastq files</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------\n",
      "Preparation for output:\n",
      "Please double-check that your inputs were recorded as expected.\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Your OUTPUT DIRECTORY was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/Documents/GenotypesOutputGit2\n",
      "\n",
      "Your directory containing fastq INPUT FILES was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/fastq_files_subset\n",
      "\n",
      "    The following data were collected:  \n",
      "    Illumina sequencing run ID(s): \n",
      "        @M00582:216\n",
      "    # of fastq files to process: 8\n",
      "    size distribution of fastq files to process: \n",
      "      total... 3 MB \n",
      "      range... max: 0.58 MB; min: 0.05928 MB; median: 0.339 MB; mean +/- stdev: 0.329 +/- 0.206 MB\n",
      "    read distribution within fastq files to process: \n",
      "      total... 7,592 reads \n",
      "      range... max: 1667 reads; min: 171 reads; median: 979.0 reads; mean +/- stdev: 949.0 +/- 595.0 reads\n",
      "\n",
      "Your BLASTN EXECUTABLE location was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/anaconda3/bin/blastn\n",
      "\n",
      "Your BLASTN ALIGNMENT DATABASE DIRECTORY was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/Genotypes_testfiles/blastn_database\n",
      "\n",
      "Your PREFIX common to BLASTN ALIGNMENT DATABASE FILES was recorded as:\n",
      "\n",
      "GRCh38\n",
      "\n",
      "Your BLASTDBCMD EXECUTABLE location was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/anaconda3/bin/blastdbcmd\n",
      "\n",
      "Your DNA sub-sequence(s) were recorded as:\n",
      "\n",
      "guide RNA sequence(s): ['GTGCCAGCCACATTCAGAAC']\n",
      "sub-sequence(s) to query for presence: ['AGAACAGGGTGTTCTG']\n",
      "\n",
      "Is this list accurately recorded? Type 'Y' or 'N': \n",
      "Y\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "---------------------------------------------------------------\n",
    "Preparation for output:\n",
    "Please double-check that your inputs were recorded as expected.\n",
    "---------------------------------------------------------------\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "Your OUTPUT DIRECTORY was recorded as:\n",
    "\"\"\")\n",
    "print(str(output_directory))\n",
    "\n",
    "print(\"\"\"\n",
    "Your directory containing fastq INPUT FILES was recorded as:\n",
    "\"\"\")\n",
    "print(str(fastq_directory))\n",
    "\n",
    "print(\"\"\"\n",
    "    The following data were collected:  \"\"\")\n",
    "print(\"    Illumina sequencing run ID(s): \")\n",
    "for i in runIDlist:\n",
    "    print('        '+i)\n",
    "\n",
    "print(\"    # of fastq files to process: {0}\".format(len(myFastqFilenames)))\n",
    "\n",
    "print(\"    size distribution of fastq files to process: \\n      total... \"+str(round((sum(file for file in filesize))))+' MB \\n      range... max: '+str(round((max(file for file in filesize)),2))+' MB; min: '+str(round((min(file for file in filesize)),5))+' MB; median: '+str(round((numpy.median([file for file in filesize])),3))+' MB; mean +/- stdev: '+str(round((numpy.mean([file for file in filesize])),3))+' +/- '+str(round((numpy.std([file for file in filesize])),3))+' MB')\n",
    "\n",
    "print(\"    read distribution within fastq files to process: \\n      total... \"+locale.format_string(\"%d\", sum(readcount), grouping=True)+' reads \\n      range... max: '+str((max(file for file in readcount)))+' reads; min: '+str((min(file for file in readcount)))+' reads; median: '+str((numpy.median([file for file in readcount])))+' reads; mean +/- stdev: '+str(round((numpy.mean([file for file in readcount]))))+' +/- '+str(round((numpy.std([file for file in readcount]))))+' reads')\n",
    "\n",
    "print(\"\"\"\n",
    "Your BLASTN EXECUTABLE location was recorded as:\n",
    "\"\"\")\n",
    "print(str(blastn_path))\n",
    "\n",
    "print(\"\"\"\n",
    "Your BLASTN ALIGNMENT DATABASE DIRECTORY was recorded as:\n",
    "\"\"\")\n",
    "print(str(db_path))\n",
    "\n",
    "print(\"\"\"\n",
    "Your PREFIX common to BLASTN ALIGNMENT DATABASE FILES was recorded as:\n",
    "\"\"\")\n",
    "print(db_prefix)\n",
    "\n",
    "print(\"\"\"\n",
    "Your BLASTDBCMD EXECUTABLE location was recorded as:\n",
    "\"\"\")\n",
    "print(str(blastdbcmd_path))\n",
    "\n",
    "if test_seq == 'Yes':\n",
    "    print(\"\"\"\n",
    "Your DNA sub-sequence(s) were recorded as:\n",
    "\"\"\")\n",
    "    try:\n",
    "        guideRNA_seq\n",
    "    except NameError:\n",
    "        pass\n",
    "    else:\n",
    "        print('guide RNA sequence(s): '+str(guideRNA_seq))\n",
    "    try:\n",
    "        extant_seq\n",
    "    except NameError:\n",
    "        pass\n",
    "    else:\n",
    "        print('sub-sequence(s) to query for presence: '+str(extant_seq))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "check = input(\"\"\"\n",
    "Is this list accurately recorded? Type 'Y' or 'N': \n",
    "\"\"\")\n",
    "\n",
    "if check == 'Y':\n",
    "    pass\n",
    "elif check == 'N':\n",
    "    print(\"\"\"\n",
    "If you have corrections to make, please return to the appropriate cell to reset variables.\n",
    "To continue in the script, move to the next cell.\n",
    "To restart the script, click on the menu 'Kernel -> Restart'.  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Include or bypass frequency plot generation (optional file output, allele_evidence.pdf)**\n",
    "\n",
    "*Genotypes.py can produce a pdf containing frequency plots as evidence for allele contributions to extrapolated genotype(s). Frequency plot generation is time-intensive (for example, ~2-3 minutes per sample, depending on hardware parameters e.g., available RAM).* \n",
    "\n",
    "Indicate whether the script should create frequency plots (pdf) as **allele_evidence.pdf**, or whether this code block should be skipped at this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genotypes.py is ready to process fastq files. Before script operations begin, please indicate whether visual\n",
      "plots of allele frequencies should be rendered and delivered in an output file, allele_evidence.pdf.\n",
      "\n",
      "Note that production of allele_evidence.pdf can require hours of processing time, although the output timing of\n",
      "key text files with allele definitions and genotype inferences (e.g., allele_definitions.txt, genotypes.txt,\n",
      "allele_definitions.csv, population_summary.txt) will not be affected.\n",
      "\n",
      "To PROCEED with script operations that INCLUDE allele_evidence.pdf, type 'Y';\n",
      "\n",
      "To BYPASS script operations that generate allele_evidence.pdf, type 'N': \n",
      "Y\n"
     ]
    }
   ],
   "source": [
    "frequency_plot_check = input(\"\"\"\n",
    "Genotypes.py is ready to process fastq files. Before script operations begin, please indicate whether visual\n",
    "plots of allele frequencies should be rendered and delivered in an output file, allele_evidence.pdf.\n",
    "\n",
    "Note that production of allele_evidence.pdf can require hours of processing time, although the output timing of\n",
    "key text files with allele definitions and genotype inferences (e.g., allele_definitions.txt, genotypes.txt,\n",
    "allele_definitions.csv, population_summary.txt) will not be affected.\n",
    "\n",
    "To PROCEED with script operations that INCLUDE allele_evidence.pdf, type 'Y';\n",
    "\n",
    "To BYPASS script operations that generate allele_evidence.pdf, type 'N': \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### III. Generate output directory and files, ready for script output  \n",
    "Script generates a single directory, populated with 8 files ready to accept script output.  \n",
    "Files are automatically named as in **'Output notes'** above, with current date appended to filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on script operation duration\n",
    "startTime = datetime.now()\n",
    "startTimestr = str(startTime).split(' ')[1].split('.')[0]\n",
    "\n",
    "# Log time duration of user input\n",
    "userinputDuration = str(startTime - initialTime).split(':')[0]+' hr|'+str(startTime - initialTime).split(':')[1]+' min|'+str(startTime - initialTime).split(':')[2].split('.')[0]+' sec|'+str(startTime - initialTime).split(':')[2].split('.')[1]+' microsec'\n",
    "\n",
    "# Generate the directory and its files (to accept content later in script)\n",
    "path = str(output_directory)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "output_path = Path(output_directory)\n",
    "\n",
    "# Create output files\n",
    "if frequency_plot_check == 'Y':\n",
    "    filename_list = ['fasta.fa', 'blastn_alignments.txt', 'allele_definitions.txt', 'allele_evidence.pdf', 'genotypes.txt', 'population_summary.txt', 'allele_definitions.csv', 'script_metrics.txt']\n",
    "elif frequency_plot_check == 'N':\n",
    "    filename_list = ['fasta.fa', 'blastn_alignments.txt', 'allele_definitions.txt', 'genotypes.txt', 'population_summary.txt', 'allele_definitions.csv', 'script_metrics.txt']\n",
    "\n",
    "# Define current date as prefix to all filenames\n",
    "processdate = datetime.today().strftime(\"%m%d%Y\")\n",
    "\n",
    "for filename in filename_list:\n",
    "    with open(os.path.join(path, processdate+'_'+filename), 'wb') as file:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The file **script_metrics.txt** records script operation metadata (summarizes script input and performance); peform initial log of system information, user-defined variables and fastq file properties to script_metrics.txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Collect RAM info for local operating system\n",
    "mem = virtual_memory()\n",
    "ramem = mem.total/1073741824\n",
    "\n",
    "# Use print redirection to write to target file, in append mode (begin script_metrics.txt)\n",
    "filename = Path(str(output_path)+'/'+processdate+'_script_metrics.txt')\n",
    "with open(filename, 'a') as f:\n",
    "    print(\"\"\"Genotypes.py: Script Metrics\\nDate: \"\"\" + (datetime.today().strftime(\"%m/%d/%Y\")) +\n",
    "\"\"\"\\n\\nOperating system information:\n",
    "    name: \"\"\" + socket.gethostname() +\n",
    "'\\n    platform: ' + platform.platform() +\n",
    "'\\n    RAM (GB): ' + str(ramem) +\n",
    "'\\n    physical CPU/effective CPU: ' + str(psutil.cpu_count(logical=False)) +'/'+ str(psutil.cpu_count()) +\n",
    "'\\n    executable: ' + psutil.Process().exe() +\n",
    "\"\"\"\\n\\nUser-entered variables:\n",
    "    output_directory: \"\"\"+ str(output_directory) +\n",
    "\"\\n    fastq_directory: \"+ str(fastq_directory) +\n",
    "\"\\n    blastn_path: \"+ str(blastn_path) +\n",
    "\"\\n    db_path: \"+ str(db_path) +\n",
    "\"\\n    db_prefix: \"+ db_prefix +\n",
    "\"\\n    blastdbcmd_path: \"+ str(blastdbcmd_path), file = f)\n",
    "    try:\n",
    "        guideRNA_seq\n",
    "    except NameError:\n",
    "        print('    guideRNA_seq: not defined', file = f)\n",
    "    else:\n",
    "        print(\"    guideRNA_seq: \"+ str(guideRNA_seq).strip('[]').replace(\"'\",\"\"), file = f)\n",
    "    try:\n",
    "        extant_seq\n",
    "    except NameError:\n",
    "        print('    extant_seq: not defined', file = f)\n",
    "    else:\n",
    "        print(\"    extant_seq: \"+ str(extant_seq).strip('[]').replace(\"'\",\"\"), file = f)\n",
    "    print(\"\"\"\\nfastq file information:\n",
    "    Illumina sequencing run ID(s): \"\"\"+ str(runIDlist).strip('[]').replace(\"'\",\"\") +\n",
    "\"\\n    Number of fastq files processed: \"+ str(len(myFastqFilenames)) +\n",
    "\"\"\"\\n    Size distribution of fastq files processed: \n",
    "        total... \"\"\" +str(round((sum(file for file in filesize))))+' MB \\n        range... max: '+str(round((max(file for file in filesize)),2))+' MB; min: '+str(round((min(file for file in filesize)),5))+' MB; median: '+str(round((numpy.median([file for file in filesize])),3))+' MB; mean +/- stdev: '+str(round((numpy.mean([file for file in filesize])),3))+' +/- '+str(round((numpy.std([file for file in filesize])),3))+' MB'\n",
    "\"\\n    Read distribution within fastq files to process: \\n        total... \"+locale.format_string(\"%d\", sum(readcount), grouping=True)+' reads \\n        range... max: '+str((max(file for file in readcount)))+' reads; min: '+str((min(file for file in readcount)))+' reads; median: '+str((numpy.median([file for file in readcount])))+' reads; mean +/- stdev: '+str(round((numpy.mean([file for file in readcount]))))+' +/- '+str(round((numpy.std([file for file in readcount]))))+' reads', file = f)\n",
    "    print(\"\\nfastq files processed (name, size (MB), reads): \", file = f)\n",
    "    for i in (sorted(fastq_overview)):\n",
    "        print(\"    \" + str(i).strip(\"()\").replace(\"'\",\"\"), file = f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### IV. Identify candidate alleles: fasta file, BLASTN alignment, BLASTDBCMD consultation, and assignment of alleles to samples  \n",
    "Deep sequencing of amplicons can yield hundreds to thousands of reads per sample; read frequencies can be used to gauge relative read abundance and, ultimately, to infer probable genotype (sequence ID(s) of the source template(s)).\n",
    "<img src=\"Genotypes_img/fasta_thumbnail.png\" align=\"left\" width=\"750\">  \n",
    "\n",
    "*Operations:*  \n",
    "**Count reads in preparation to explore as \"Ranked Alleles\".** This script parses sample-specific fastq files for unique read types, counts the abundance of these read types, and reports the top 10 most abundant read types (in each of read1 and read2) in the form of fasta entries. For each sample, **each of the 10 ranked sequences is reported with its frequency metrics** in a corresponding fasta definition line (defline).   \n",
    "\n",
    "The output of this step is a fasta file (.fa) that will be created in the user-specified OUTPUT DIRECTORY.  \n",
    "\n",
    "**Align reads to reference.** This fasta file is then presented to **BLASTN** (with the reference sequence database specified during user input) for alignments.\n",
    "\n",
    "**Define candidate alleles.** The script then parses the alignments to organize alignment data for the 'top 10' reads assigned to each sample, in a single dictionary called **'alignmentoutput_dict'**.  Ranked Alleles with BLASTN alignments having >1 high-scoring pair (hsp) are recruited for specialized analysis using **BLASTDBCMD**; hsp's may be split in BLASTN alignments if separated by an intervening span >~60 bp (as may happen with long indels relative to a reference sequence).  Genotypes.py attempts hypothesized allele reconstitution, using BLASTDBCMD to retrieve the reference sequence span (end-to-end) between hsp's, if the hsp's do not overlap and are within 1 kb.  Valid alignments recovered by BLASTN and BLASTDBCMD-assisted allele reconstruction are then pooled to contribute to sample-specific genotype extrapolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on read count operation duration\n",
    "startTime_readcount = datetime.now()\n",
    "\n",
    "# For each fastq file (sourcefile) in fastq_directory, count top 10 most abundant read types and direct read sequence + annotation defline (sample name + frequency metrics) to fasta.fa (future alignment input)\n",
    "query_input = Path(str(output_path)+'/'+processdate+'_fasta.fa')\n",
    "\n",
    "# define Nextera adaptor sequence, in preparation to trim read 3' ends if necessary\n",
    "adaptor_str = 'CTGTCTCTTATACACATCT'\n",
    "adaptor_str_rev = 'AGATGTGTATAAGAGACAG'\n",
    "\n",
    "# proceed to R1+R2 merge, unique read identification & counting\n",
    "    \n",
    "# Merge R1 and R2 reads, if present, as single sequence\n",
    "R1_file_list = [sourcefile for sourcefile in myFastqFilenames if bool(re.split('_',os.path.basename(sourcefile))[3] == 'R1')]\n",
    "R2_file_list = [sourcefile for sourcefile in myFastqFilenames if bool(re.split('_',os.path.basename(sourcefile))[3] == 'R2')]\n",
    "      \n",
    "# R1, R2 cluster mapping (identify fastq file pairs representing R1 & R2 data for individual clusters)\n",
    "processed_files_list = []\n",
    "R1_R2_map_list = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    if sourcefile in processed_files_list:\n",
    "        pass\n",
    "    else:\n",
    "        testname = ''.join(re.split('_',os.path.basename(sourcefile))[0:3])\n",
    "        for sourcefile1 in R1_file_list:\n",
    "            if testname == ''.join(re.split('_',os.path.basename(sourcefile1))[0:3]):\n",
    "                R1 = sourcefile\n",
    "                if sourcefile not in processed_files_list:\n",
    "                    processed_files_list.append(sourcefile)\n",
    "        for sourcefile2 in R2_file_list:\n",
    "            if testname == ''.join(re.split('_',os.path.basename(sourcefile2))[0:3]):\n",
    "                R2 = sourcefile2\n",
    "                if sourcefile2 not in processed_files_list:\n",
    "                    processed_files_list.append(sourcefile2)\n",
    "        R1_R2_map_list.append((R1, R2))\n",
    "        \n",
    "for file_pair in R1_R2_map_list:\n",
    "    R1_file = file_pair[0]\n",
    "    R2_file = file_pair[1]\n",
    "    fastaname = re.split('_', os.path.basename(R1_file))\n",
    "    cluster_sequence_R1_dict = {}\n",
    "    cluster_sequence_R2_dict = {}\n",
    "    cluster_sequence_R2_revcomp_dict = {}\n",
    "    cluster_merged_R1_R2revcomp_dict = {}\n",
    "    cluster_merged_R1_R2revcomp_dict2 = {}\n",
    "    merged_read_list = []\n",
    "    counter=()\n",
    "    if Path(R1_file).suffix == \".gz\":\n",
    "        with gzip.open(R1_file, \"rt\") as f:\n",
    "            lines_R1 = f.readlines()\n",
    "    elif Path(R1_file).suffix == \".fastq\":\n",
    "        with open(R1_file, 'r') as f:\n",
    "            lines_R1 = f.readlines()    \n",
    "    for x in range(0,len(lines_R1),4):\n",
    "        # trim adaptor sequence and up to 3' end of read from R1 sequence, if adaptor sequence found\n",
    "        cluster_sequence_R1_dict[lines_R1[x].split(':')[5]+':'+lines_R1[x].split(':')[6].split(' ')[0]] = lines_R1[x+1].strip('\\n')[:lines_R1[x+1].strip('\\n').index(adaptor_str)] if adaptor_str in lines_R1[x+1].strip('\\n') else lines_R1[x+1].strip('\\n') \n",
    "    #cluster_IDs_list_R1 = [x.split(':')[5]+':'+x.split(':')[6].split(' ')[0] for x in lines_R1[0::4]]\n",
    "    if Path(R2_file).suffix == \".gz\":\n",
    "        with gzip.open(R2_file, \"rt\") as f:\n",
    "            lines_R2 = f.readlines()\n",
    "    elif Path(R2_file).suffix == \".fastq\":\n",
    "        with open(R2_file, 'r') as f:\n",
    "            lines_R2 = f.readlines()\n",
    "    for x in range(0,len(lines_R2),4):\n",
    "        # trim adaptor sequence and up to 3' end of read from R2 sequence, if adaptor sequence found\n",
    "        cluster_sequence_R2_dict[lines_R2[x].split(':')[5]+':'+lines_R2[x].split(':')[6].split(' ')[0]] = lines_R2[x+1].strip('\\n')[:lines_R2[x+1].strip('\\n').index(adaptor_str)] if adaptor_str in lines_R2[x+1].strip('\\n') else lines_R2[x+1].strip('\\n') \n",
    "    #cluster_IDs_list_R2 = [x.split(':')[5]+':'+x.split(':')[6].split(' ')[0] for x in lines_R2[0::4]]\n",
    "    for cluster in cluster_sequence_R2_dict:\n",
    "        cluster_sequence_R2_revcomp_dict[cluster] = ''.join(reversed(''.join(nt_dict.get(nt) for nt in cluster_sequence_R2_dict.get(cluster))))\n",
    "    for cluster in cluster_sequence_R1_dict:\n",
    "        if cluster in cluster_sequence_R2_revcomp_dict:\n",
    "            if merge(cluster_sequence_R1_dict.get(cluster), cluster_sequence_R2_revcomp_dict.get(cluster)) != 'no overlap':\n",
    "                cluster_merged_R1_R2revcomp_dict[cluster] = merge(cluster_sequence_R1_dict.get(cluster), cluster_sequence_R2_revcomp_dict.get(cluster))\n",
    "            else:\n",
    "                cluster_merged_R1_R2revcomp_dict2[cluster] = merge1(cluster_sequence_R1_dict.get(cluster), cluster_sequence_R2_revcomp_dict.get(cluster))\n",
    "    for cluster in cluster_merged_R1_R2revcomp_dict:\n",
    "        merged_read_list.append(cluster_merged_R1_R2revcomp_dict.get(cluster))\n",
    "    # create dictionary (counter) relating unique read sequence to its # of occurrences\n",
    "    counter=Counter(merged_read_list)\n",
    "    # assign top 10 reads by count in fastq file (sourcefile) to modified_read_list_top10\n",
    "    modified_read_list_top10 = []\n",
    "    for index, i in enumerate(counter.most_common(10)):\n",
    "        # read frequency relative to other reads that occur at >1% raw frequency\n",
    "        filtered1 = sum([x for x in counter.values() if x/(sum(counter.values())) > 0.01])\n",
    "        # read frequency relative to other reads that occur at >01% raw frequency\n",
    "        filtered10 = sum([x for x in counter.values() if x/(sum(counter.values())) > 0.1])\n",
    "        # read raw frequency\n",
    "        raw_freq = round((100*i[1]/sum(counter.values())),2)\n",
    "        modified_read_list_top10.append([i[0], '['+str(i[1])+'/'+str(sum(counter.values()))+']', 'rank'+str(index+1), raw_freq, int(stats.percentileofscore([i for i in counter.values()], i[1], 'rank')), round((100*i[1]/sum([i[1] for i in counter.most_common(10)])),2), round((100*i[1]/filtered1),2) if filtered1 > 0 and raw_freq >= 1 else 'None', round((100*i[1]/filtered10),2) if filtered10 > 0 and raw_freq >= 10 else 'None'])\n",
    "    # direct output in fasta format (with defline encoding sample name + frequency metrics) to fasta.fa\n",
    "    with open(str(query_input), 'a+') as file:\n",
    "        for i in modified_read_list_top10:\n",
    "            file.write('>'+fastaname[0]+'_'+'R1+R2'+'_'+str(i[1])+'_'+i[2]+'_%totalreads:'+str(i[3])+'_percentile:'+str(i[4])+'_%top10reads:'+str(i[5])+'_%readsfilteredfor1%:'+str(i[6])+'_%readsfilteredfor10%:'+str(i[7])+'\\n'+i[0]+'\\n')\n",
    "\n",
    "# Log read count time duration\n",
    "readcountDuration = str(datetime.now()- startTime_readcount).split(':')[0]+' hr|'+str(datetime.now() - startTime_readcount).split(':')[1]+' min|'+str(datetime.now() - startTime_readcount).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_readcount).split(':')[2].split('.')[1]+' microsec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process alignments to reference sequence database, using **BLASTN** (NCBI).  \n",
    "<img src=\"Genotypes_img/BLASTN_thumbnail.png\" align=\"left\" width=\"100\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on blastn alignments duration\n",
    "startTime_alignments = datetime.now()\n",
    "\n",
    "# Process alignments relative to reference sequence database, using blastn\n",
    "# Reference database\n",
    "db_input = db_path / db_prefix\n",
    "\n",
    "# Alignment output\n",
    "blast_directory = processdate+'_blastn_alignments.txt'\n",
    "query_output = output_directory / blast_directory\n",
    "\n",
    "# Alignment command\n",
    "cmd_align = str(blastn_path)+' -query '+str(query_input)+' -db '+str(db_input)+' -out '+str(query_output)+' -gapopen 1 -gapextend 1 -outfmt \"5\"'\n",
    "\n",
    "os.system(cmd_align)\n",
    "\n",
    "# Log alignment time duration\n",
    "alignmentsDuration = str(datetime.now()- startTime_alignments).split(':')[0]+' hr|'+str(datetime.now() - startTime_alignments).split(':')[1]+' min|'+str(datetime.now() - startTime_alignments).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_alignments).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Define alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on genotypes extrapolation duration\n",
    "startTime_imputation = datetime.now()\n",
    "\n",
    "# Import blastn alignments output as a list of strings (each string corresponds to a query alignment)\n",
    "alignments_list = []\n",
    "with open(str(query_output), 'r') as file:\n",
    "    reader = file.read()\n",
    "    for i,part in enumerate(reader.split('<Iteration_iter-num>')):\n",
    "        alignments_list.append(part)\n",
    "# Remove blastn header line from alignments_list\n",
    "alignments_list = alignments_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Convert alignments_list to list of lists (i.e., each query alignment string is encapsulateed into its own sublist within alignments_list2)\n",
    "alignments_list2 = [alignments_list[i:i+1] for i in range(0, len(alignments_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Subset sample IDs and/or associated reads for which *(1) no alignment* was found in reference database, or *(2) multiple hits* were identified in reference database. These are ultimately removed from further analysis, but the identities of samples and/or associated reads that were filtered by these criteria are ultimately reported in 'population_summary.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Identify & subset queries for which no alignments were found in reference database ('no hits found')\n",
    "no_hits_list = []\n",
    "for i in alignments_list2:\n",
    "    if re.search('No hits found', str(i)):\n",
    "        no_hits_list.append(str(i).split('<Iteration_query-def>')[1].split('</Iteration_query-def>')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Record sample names having reads with no alignment hits\n",
    "no_hits_samplename_list = []\n",
    "for i in no_hits_list:\n",
    "    samplename = i.split('_')[0]\n",
    "    if samplename not in no_hits_samplename_list:\n",
    "        no_hits_samplename_list.append(samplename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Within each sublist of alignments_list2, split each line into an individual string, remove beginning and trailing whitespace, and recapture specified subset of alignment information in alignments_list3\n",
    "alignments_list3 = []\n",
    "for i in alignments_list2:\n",
    "    if str(i).split('<Iteration_query-def>')[1].split('</Iteration_query-def>')[0] not in no_hits_list:\n",
    "        alignments_list3.append([y.strip() for x in i for y in x.split('\\n') if y.strip().startswith(('<Iteration_query-ID>', '<Iteration_query-def>', '<Hit_num>', '<Hit_id>', '<Hit_def>', '<Hit_accession>', '<Hsp_num>', '<Hsp_hit-from>', '<Hsp_hit-to>', '<Hsp_qseq>', '<Hsp_hseq>', '<Hsp_midline>'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Identify & subset reads with >1 alignment to sequences in reference database\n",
    "# Some reads with >1 alignment will be recovered to 'reconstitute' hypothesized allele (if BLASTN has split the read into multiple 'hits' or 'high-scoring pairs' (hsp's) within 1 kb)\n",
    "\n",
    "# There are in principle at least 3 ways a read could potentially align to >1 position in reference database (1 & 2a,b below):\n",
    "# (1) same sequence span aligns to >1 different locus (disparate <Hit_id>'s)\n",
    "# (2) one sequence span may be split into two (ore more) different alignment matches, because of intervening gap(s) or insertion(s) that exceed ~60 bp (an apparent BLASTN gap limit)\n",
    "#    (a) if the two (or more) 'split matches' align to the same <Hit_id>, but to different chromosomal coordinates of that <Hit_id>, they will be presented by BLASTN as belonging to the same <Hit_num>, but to different <Hsp_num> (Hsp=high scoring pair)\n",
    "#    (b) if the two (or more) 'split matches' span different <Hit_id>'s (essentially different 'chunks' of sequence with unique names, as organized within the alignment database), they will be presented by BLASTN as belonging to different <Hit_num>\n",
    "# These observations suggest that it is important to distinguish a read with alignment to >1 sequence as either one with poor genomic target resolution, vs. one that harbors sizeable deletions or insertions relative to the reference sequence\n",
    "# One way to make this distinction may be to gauge how close in chromosomal space the >1 alignments are to one another, and assume their continuity if their proximity falls within a defined constraint.  Genotypes.py assigns this constraint to be 1000 bp (1kb)\n",
    "# Genotypes.py attempts to reconstitute hypothesized alleles that span multiple non-overlapping hsp's (and does not attempt to reconstitute across multiple hits or for ambiguous reconstructions from overlapping hsp's)\n",
    "\n",
    "# Organize reads with multiple hit IDs\n",
    "# These reads are deprecated (not further analyzed)\n",
    "multiple_alignments_hits_list = []\n",
    "for i in alignments_list3:\n",
    "    if len(re.findall('<Hit_num>', str(i))) > 1:\n",
    "        multiple_alignments_hits_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Organize reads with single hit, but multiple associated hsp IDs\n",
    "# These reads will be processed by BLASTDBCMD in an effort to 'reconstitute' potential alleles, with high-scoring alignment pairs matched to the reference genome, but split into separate matches due to intervening non-aligning span between the alignment matches\n",
    "multiple_alignments_hsp_list = []\n",
    "for i in alignments_list3:\n",
    "    if len(re.findall('<Hit_num>', str(i))) > 1:\n",
    "        pass\n",
    "    elif len(re.findall('<Hsp_num>', str(i))) > 1:\n",
    "        multiple_alignments_hsp_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Identify read IDs with >1 alignment to sequences in reference database (hit class)\n",
    "# Note, in Genotypes.py v1.0, these reads are deprecated at this time (in step just prior)\n",
    "multiple_alignments_hits_readID_list = []\n",
    "for i in multiple_alignments_hits_list:\n",
    "    multiple_alignments_hits_readID_list.append(i[1].split('>')[1].split('<')[0])\n",
    "    \n",
    "# Identify read IDs with >1 alignment to sequences in reference database (hsp class)\n",
    "multiple_alignments_hsp_readID_list = []\n",
    "for i in multiple_alignments_hsp_list:\n",
    "    multiple_alignments_hsp_readID_list.append(i[1].split('>')[1].split('<')[0])\n",
    "\n",
    "# Record sample names having reads with >1 alignment to sequences in reference database (hit class)\n",
    "multiple_alignments_hits_samplename_list = []\n",
    "for i in multiple_alignments_hits_readID_list:\n",
    "    samplename = i.split('_')[0]\n",
    "    if samplename not in multiple_alignments_hits_samplename_list:\n",
    "        multiple_alignments_hits_samplename_list.append(samplename)\n",
    "        \n",
    "# Record sample names having reads with >1 alignment to sequences in reference database (hsp class)\n",
    "multiple_alignments_hsp_samplename_list = []\n",
    "for i in multiple_alignments_hsp_readID_list:\n",
    "    samplename = i.split('_')[0]\n",
    "    if samplename not in multiple_alignments_hsp_samplename_list:\n",
    "        multiple_alignments_hsp_samplename_list.append(samplename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare dictionary linking sample names to their reads having >1 alignment to sequences in reference database (hit class)\n",
    "multiple_alignments_hits_dict = {}\n",
    "for i in multiple_alignments_hits_samplename_list:\n",
    "    multiple_alignments_hits_dict[\"{0}\".format(i)] = tuple(x for x in multiple_alignments_hits_list if bool(re.search(i, x[1])))\n",
    "\n",
    "# Prepare dictionary linking sample names to their reads having >1 alignment to sequences in reference database (hsp class)\n",
    "multiple_alignments_hsp_dict = {}\n",
    "for i in multiple_alignments_hsp_samplename_list:\n",
    "    multiple_alignments_hsp_dict[\"{0}\".format(i)] = tuple(x for x in multiple_alignments_hsp_list if bool(re.search(i, x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Not all top 10 ranked alleles for every sample will be subject to a multiple-hsp search; will need to keep track of this, to regroup allele alignments for individual samples at later step (i.e., regroup and print by rank alleles that have been reconstituted by BLASTDBCMD as well as alleles that did not require reconstitution)\n",
    "# For reads that have hsp's that overlap with one another, it is unclear how best to reconstitute an alignment; discard these reads from further analysis ('deprecate', but record their deprecation in population_summary.txt)\n",
    "\n",
    "multiple_alignments_hsp_dict_valid = {}\n",
    "multiple_alignments_hsp_dict_invalid = {}\n",
    "for i in multiple_alignments_hsp_dict:\n",
    "    valid_hsp_reads_list = []\n",
    "    invalid_hsp_reads_list = []\n",
    "    for x in multiple_alignments_hsp_dict.get(i):\n",
    "        hsp_id_list = x[6::6]\n",
    "        hsp_from_to_list = []\n",
    "        hsp_sequence_identifier = x[5]\n",
    "        # assign sequence identifier\n",
    "        for hsp in hsp_id_list:\n",
    "            hsp_index = x.index(hsp)\n",
    "            hsp_from_to_list.append((x[hsp_index+1], x[hsp_index+2]))\n",
    "        # check whether hsp spans overlap; if they do, discard read\n",
    "        coordinate_range_subset_list = []\n",
    "        for index, span in enumerate(hsp_from_to_list):\n",
    "            coordinate_range_subset = sorted([int(span[0].split('>')[1].split('<')[0])]+[int(span[1].split('>')[1].split('<')[0])])\n",
    "            coordinate_range_subset_list.append(coordinate_range_subset)\n",
    "        coordinate_range_subset_list_expanded = [range(coordinate_range_subset[0],coordinate_range_subset[1]) for coordinate_range_subset in coordinate_range_subset_list]\n",
    "        # set default overlap validity to True (no hsp overlaps)\n",
    "        valid_hsp_overlap = True\n",
    "        for y in coordinate_range_subset_list_expanded:\n",
    "            coordinate_range_subset_list_expanded_copy = coordinate_range_subset_list_expanded.copy()\n",
    "            coordinate_range_subset_list_expanded_copy.remove(y)\n",
    "            for w in coordinate_range_subset_list_expanded_copy:\n",
    "                if set(y).intersection(set(w)):\n",
    "                    valid_hsp_overlap = False\n",
    "        if valid_hsp_overlap is True:\n",
    "            valid_hsp_reads_list.append(x)\n",
    "        else:\n",
    "            invalid_hsp_reads_list.append(x)\n",
    "    multiple_alignments_hsp_dict_valid[\"{0}\".format(i)] = valid_hsp_reads_list\n",
    "    multiple_alignments_hsp_dict_invalid[\"{0}\".format(i)] = invalid_hsp_reads_list\n",
    "\n",
    "# Make a copy of multiple_alignments_hsp_dict_valid, removing dictionary keys with empty lists (no valid multiple hsp's: hsp(s) either span >1 kb, or overlap coordinates)\n",
    "multiple_alignments_hsp_dict_valid2 = { k : v for k,v in multiple_alignments_hsp_dict_valid.items() if v}\n",
    "multiple_alignments_hsp_dict_invalid2 = { k : v for k,v in multiple_alignments_hsp_dict_invalid.items() if v}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For candidate Ranked Alleles with >1 hsp (non-overlapping, within 1 kb), attempt allele reconstitution: retrieve spanned reference sequence using **BLASTDBCMD** (NCBI).  \n",
    "<img src=\"Genotypes_img/BLASTDBCMD_thumbnail.png\" align=\"left\" width=\"100\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# BLASTDBCMD: use BLASTN reference genome database for BLASTDBCMD sequence retrieval\n",
    "# Reference database (same as for blastn in earlier alignment step)\n",
    "db_input = db_path / db_prefix\n",
    "    \n",
    "# Now prepare alignment 'reconstitutions' with aid of BLASTDBCMD\n",
    "blastdbcmd_alignments_list = []\n",
    "for index, i in enumerate(multiple_alignments_hsp_dict_valid2):\n",
    "    for read in multiple_alignments_hsp_dict_valid2.get(i):\n",
    "        blastdbcmd_alignments_list_read_sublist = []\n",
    "        intervening_bases = ''\n",
    "        try:\n",
    "            retrieved_sequence_updated\n",
    "        except NameError:\n",
    "            pass\n",
    "        else:\n",
    "            del retrieved_sequence_updated\n",
    "        # this sublist ultimately has 10 items; 1st 5 come from multiple_alignments_hsp_dict_valid, next 5 come from blastdbcmd & Genotypes.py in upcoming code below\n",
    "        blastdbcmd_alignments_list_read_sublist = [read[0]]+[read[1]]+[read[2]]+[read[3]]+[read[4]]\n",
    "        coordinate_range_exceeds_1kb_threshold = False\n",
    "        # number of high scoring pairs at/across single-hit accession number (sequence identifier)\n",
    "        hsp_count = len(read[6::6])\n",
    "        hsp_id_list = read[6::6]\n",
    "        hsp_from_to_list = []\n",
    "        hsp_sequence_identifier = read[5]\n",
    "        # assign sequence identifier\n",
    "        for hsp in hsp_id_list:\n",
    "            hsp_index = read.index(hsp)\n",
    "            hsp_from_to_list.append((read[hsp_index+1], read[hsp_index+2]))\n",
    "        # sequence_identifier shared by hsp's\n",
    "        sequence_identifier = hsp_sequence_identifier.split('>')[1].split('<')[0] \n",
    "        coordinates_list = []\n",
    "        for hsp_from_to in hsp_from_to_list:\n",
    "            for x in hsp_from_to:\n",
    "                coordinates_list.append(int(x.split('>')[1].split('<')[0]))\n",
    "        coordinate_range = str(min(set(coordinates_list)))+'-'+str(max(set(coordinates_list)))\n",
    "    # Check whether the hsp's are within 1 kb of one another.  If not, deprecate as multi-mapping.  If they are within 1 kb, assume that blastn split them as separate hsp's because of intervening deletion/insertion relative to reference sequence.  Attempt to reconstitute.\n",
    "        if max(set(coordinates_list))-min(set(coordinates_list)) > 1000:\n",
    "            coordinate_range_exceeds_1kb_threshold = True\n",
    "            # add this deprecated read to multiple_alignments_hsp_dict_invalid2\n",
    "            if i in multiple_alignments_hsp_dict_invalid2:\n",
    "                multiple_alignments_hsp_dict_invalid2[i].append(read)\n",
    "            else:\n",
    "                multiple_alignments_hsp_dict_invalid2[\"{0}\".format(i)] = [read]\n",
    "    # Extract sequence spanning multiple high-scoring pairs (hsp), (if within 1 kb), using blastdbcmd\n",
    "    # blastdbcmd format is: blastdbcmd -db database -dbtype nucl -entry sequence_identifier -range coordinate_range\n",
    "    # for example: blastdbcmd -db database -dbtype nucl -entry chr6 -range 20000-20500\n",
    "    # Sequence retrieval (blastdbcmd) command\n",
    "        if coordinate_range_exceeds_1kb_threshold is True:\n",
    "            pass\n",
    "        else:\n",
    "            cmd_retrieve_sequence = str(blastdbcmd_path)+' -db '+str(db_input)+' -dbtype nucl -entry '+sequence_identifier+' -range '+coordinate_range+' -outfmt %s'\n",
    "            retrieved_sequence = subprocess.check_output(cmd_retrieve_sequence, shell=True).decode('utf8').strip()\n",
    "        # Get ready to reconstruct alignment\n",
    "        # for each tuple of from-to coordinates in hsp_from_to_list, convert to integers and sort by coordinates\n",
    "            coordinates_integer_list = []\n",
    "            for hsp_from_to in hsp_from_to_list:\n",
    "                new_tuple = tuple(sorted([int(x.split('>')[1].split('<')[0]) for x in hsp_from_to]))\n",
    "                coordinates_integer_list.append(new_tuple)\n",
    "            # sort coordinate spans in sequential order\n",
    "            coordinates_integer_list_sorted = sorted(coordinates_integer_list)\n",
    "            # take stock of whether sorting changed the relative order of the alignment blocks (hsp's), which will need to be accounted for in eventual alignment reconstruction effort\n",
    "            new_index_list = []\n",
    "            for index, hsp_from_to in enumerate(hsp_from_to_list):\n",
    "                new_tuple = tuple(sorted([int(x.split('>')[1].split('<')[0]) for x in hsp_from_to]))\n",
    "                new_index = coordinates_integer_list_sorted.index(new_tuple)\n",
    "                if new_index == index:\n",
    "                    pass\n",
    "                else:\n",
    "                    new_index_list.append(new_index)\n",
    "            # address whether there needs to be a regrouping of hsp data to correspond to their order relative to an alignment reference span\n",
    "            # first, if no order adjustment needed:\n",
    "            if len(new_index_list) == 0:\n",
    "                hsp_queries_and_midlines_list = []\n",
    "                for hsp in range(len(hsp_from_to_list)):\n",
    "                    intervening_bases = ''\n",
    "                    cognate_read_sequence = ''\n",
    "                    result = ''\n",
    "                    hsp_query = read[9+(hsp*6)].split('>')[1].split('<')[0]\n",
    "                    hsp_midline = read[11+(hsp*6)].split('>')[1].split('<')[0]\n",
    "                    hsp_hit = read[10+(hsp*6)].split('>')[1].split('<')[0]\n",
    "                    if '-' in hsp_hit:\n",
    "                        hsp_hit_adjustment = 'hsp query has insertion(s) relative to hit'\n",
    "                    else:\n",
    "                        hsp_hit_adjustment = 'no hsp query insertion(s) relative to hit'\n",
    "                    if hsp < len(hsp_from_to_list)-1:\n",
    "                        gap_to_next_hsp = coordinates_integer_list_sorted[hsp+1][0] - coordinates_integer_list_sorted[hsp][1] - 1\n",
    "                    else:\n",
    "                        gap_to_next_hsp = 0\n",
    "                    # Determine whether there is/are insertion(s) to account for in read relative to hsp's\n",
    "                    hsp_crosscheck_back_to_read = []\n",
    "                    hsp_sequence_identifier = read[5]\n",
    "                    read_ID = '>'+read[1].split('>')[1].split('<')[0]\n",
    "                    # append read_ID (as fastaname) to hsp_crosscheck_back_to_read (making it index 0)\n",
    "                    hsp_crosscheck_back_to_read.append(read_ID)\n",
    "                    hsp_sequences_to_join = []\n",
    "                    for hsp in hsp_id_list:\n",
    "                        hsp_index = read.index(hsp)\n",
    "                        hsp_sequences_to_join.append((read[hsp_index+3].split('>')[1].split('<')[0]))\n",
    "                    hsp_sequences_joined = ''.join(hsp_sequences_to_join)\n",
    "                    # append hsp match sequences to hsp_crosscheck_back_to_read as a list (making them index 1)\n",
    "                    hsp_crosscheck_back_to_read.append(hsp_sequences_to_join)\n",
    "                    # refer to initial fasta.fa file (query_input) to retrieve cognate read sequence\n",
    "                    with open(query_input) as file_iterator:\n",
    "                        for line in file_iterator:\n",
    "                            if read_ID in line:\n",
    "                                cognate_read_sequence = next(file_iterator).strip()\n",
    "                    # append cognate read sequence to hsp_crosscheck_back_to_read (making it index 2)\n",
    "                    hsp_crosscheck_back_to_read.append(cognate_read_sequence)\n",
    "                    # find any intervening read bases that were not accounted for in an hsp\n",
    "                    result = re.search(hsp_crosscheck_back_to_read[1][0]+'(.*)'+hsp_crosscheck_back_to_read[1][1], hsp_crosscheck_back_to_read[2])\n",
    "                    if result:\n",
    "                        if hsp in range(0,len(hsp_from_to_list),2):\n",
    "                            intervening_bases = result.group(1)\n",
    "                            hsp_queries_and_midlines_list.append((hsp_query,intervening_bases,hsp_midline,hsp_hit,hsp_hit_adjustment,gap_to_next_hsp+len(intervening_bases)))\n",
    "                            try:\n",
    "                                retrieved_sequence_updated\n",
    "                            except NameError:\n",
    "                                retrieved_sequence_updated = ((result.span(1)[1]-result.span(1)[0])*'-').join([retrieved_sequence_updated[:result.span(1)[0]],retrieved_sequence_updated[result.span(1)[1]:]])\n",
    "                                # get indices of added\n",
    "                            else:\n",
    "                                retrieved_sequence_updated = ((result.span(1)[1]-result.span(1)[0])*'-').join([retrieved_sequence[:result.span(1)[0]],retrieved_sequence[result.span(1)[1]:]])\n",
    "                        else:\n",
    "                            hsp_queries_and_midlines_list.append((hsp_query,'',hsp_midline,hsp_hit,hsp_hit_adjustment,gap_to_next_hsp)) \n",
    "                    else:\n",
    "                        hsp_queries_and_midlines_list.append((hsp_query,'',hsp_midline,hsp_hit,hsp_hit_adjustment,gap_to_next_hsp))\n",
    "                    # Also determine whether insertion(s) exist in hsp qseq relative to hsp hseq: if the hsp hseq sequence has any '-' in it, this means that the qseq has insertion(s) relative to the qseq\n",
    "                    # Check for '-' in hseq for any of the hsp's. If any hsp hseq has '-', to accurately account for these changes in this hseq span, need to lift this qseq span entirely from the blastn file.\n",
    "                    \n",
    "            # alternatively, adjust hsp call series based on new index if needed:\n",
    "            else:\n",
    "                hsp_queries_and_midlines_list = []\n",
    "                #print('reversed')\n",
    "                hsp_count = 0\n",
    "                for hsp in new_index_list:\n",
    "                    intervening_bases = ''\n",
    "                    cognate_read_sequence = ''\n",
    "                    result = ''\n",
    "                    hsp_query = read[9+(hsp*6)].split('>')[1].split('<')[0]\n",
    "                    hsp_midline = read[11+(hsp*6)].split('>')[1].split('<')[0]\n",
    "                    hsp_hit = read[10+(hsp*6)].split('>')[1].split('<')[0]\n",
    "                    if '-' in hsp_hit:\n",
    "                        hsp_hit_adjustment = 'hsp query has insertion(s) relative to hit'\n",
    "                    else:\n",
    "                        hsp_hit_adjustment = 'no hsp query insertion(s) relative to hit'\n",
    "                    if hsp_count < len(hsp_from_to_list)-1:\n",
    "                        gap_to_next_hsp = coordinates_integer_list_sorted[hsp_count+1][0] - coordinates_integer_list_sorted[hsp_count][1] - 1\n",
    "                    else:\n",
    "                        gap_to_next_hsp = 0\n",
    "                    hsp_count = hsp_count+1\n",
    "                    # Determine whether there is/are insertion(s) to account for in read relative to hsp's\n",
    "                    hsp_crosscheck_back_to_read = []\n",
    "                    hsp_sequence_identifier = read[5]\n",
    "                    read_ID = '>'+read[1].split('>')[1].split('<')[0]\n",
    "                    # append read_ID (as fastaname) to hsp_crosscheck_back_to_read (making it index 0)\n",
    "                    hsp_crosscheck_back_to_read.append(read_ID)\n",
    "                    hsp_sequences_to_join = []\n",
    "                    for hsp in hsp_id_list:\n",
    "                        hsp_index = read.index(hsp)\n",
    "                        hsp_sequences_to_join.append((read[hsp_index+3].split('>')[1].split('<')[0]))\n",
    "                    hsp_sequences_joined = ''.join(hsp_sequences_to_join)\n",
    "                    # append hsp match sequences to hsp_crosscheck_back_to_read as a list (making them index 1)\n",
    "                    hsp_crosscheck_back_to_read.append(hsp_sequences_to_join)\n",
    "                    # refer to initial fasta.fa file (query_input) to retrieve cognate read sequence\n",
    "                    with open(query_input) as file_iterator:\n",
    "                        for line in file_iterator:\n",
    "                            if read_ID in line:\n",
    "                                cognate_read_sequence = next(file_iterator).strip()\n",
    "                    # append cognate read sequence to hsp_crosscheck_back_to_read (making it index 2)\n",
    "                    hsp_crosscheck_back_to_read.append(cognate_read_sequence)\n",
    "                    # find any intervening read bases that were not accounted for in an hsp\n",
    "                    result = re.search(hsp_crosscheck_back_to_read[1][0]+'(.*)'+hsp_crosscheck_back_to_read[1][1], hsp_crosscheck_back_to_read[2])\n",
    "                    if result:\n",
    "                        if hsp in range(0,len(hsp_from_to_list),2):\n",
    "                            intervening_bases = result.group(1)\n",
    "                            hsp_queries_and_midlines_list.append((hsp_query,intervening_bases,hsp_midline,hsp_hit,hsp_hit_adjustment,gap_to_next_hsp+len(intervening_bases)))\n",
    "                            try:\n",
    "                                retrieved_sequence_updated\n",
    "                            except NameError:\n",
    "                                retrieved_sequence_updated = ((result.span(1)[1]-result.span(1)[0])*'-').join([retrieved_sequence_updated[:result.span(1)[0]],retrieved_sequence_updated[result.span(1)[1]:]])\n",
    "                                # get indices of added\n",
    "                            else:\n",
    "                                retrieved_sequence_updated = ((result.span(1)[1]-result.span(1)[0])*'-').join([retrieved_sequence[:result.span(1)[0]],retrieved_sequence[result.span(1)[1]:]])\n",
    "                        else:\n",
    "                            hsp_queries_and_midlines_list.append((hsp_query,'',hsp_midline,hsp_hit,hsp_hit_adjustment,gap_to_next_hsp)) \n",
    "                    else:\n",
    "                        hsp_queries_and_midlines_list.append((hsp_query,'',hsp_midline,hsp_hit,hsp_hit_adjustment,gap_to_next_hsp))\n",
    "            # retrieved_sequence\n",
    "            # reconstructed alignment midline\n",
    "            reconstructed_midline = ''.join([(hsp_queries_and_midlines_list[hsp][2]+(hsp_queries_and_midlines_list[hsp][5]*' ')) for hsp in range(len(hsp_from_to_list))])\n",
    "            # reconstructed alignment sequence\n",
    "            reconstructed_alignment_sequence = ''.join([(hsp_queries_and_midlines_list[hsp][0]+hsp_queries_and_midlines_list[hsp][1]+(hsp_queries_and_midlines_list[hsp][5]*'-')) for hsp in range(len(hsp_from_to_list))])\n",
    "            # provide reconstituted 'hsp hit from-to'\n",
    "            blastdbcmd_alignments_list_read_sublist.append('<Hsp_hit-from>'+coordinate_range.split('-')[0]+'</Hsp_hit-from>')\n",
    "            blastdbcmd_alignments_list_read_sublist.append('<Hsp_hit-to>'+coordinate_range.split('-')[1]+'</Hsp_hit-to>')\n",
    "            blastdbcmd_alignments_list_read_sublist.append('<Hsp_qseq>'+reconstructed_alignment_sequence+'</Hsp_qseq>')\n",
    "            try:\n",
    "                retrieved_sequence_updated\n",
    "            except NameError:\n",
    "                # check whether any hsp has a retrieved sequence alignment needing adjustment (in the retrieved sequence) across the hsp span\n",
    "                adjustment_required = False\n",
    "                for index, hsp in enumerate(hsp_queries_and_midlines_list):\n",
    "                    if 'hsp query has insertion(s) relative to hit' in hsp:\n",
    "                        adjustment_required = True\n",
    "                if adjustment_required == True:\n",
    "                    for index, hsp in enumerate(hsp_queries_and_midlines_list):\n",
    "                        if 'hsp query has insertion(s) relative to hit' in hsp:\n",
    "                            hit_sequence = hsp_queries_and_midlines_list[index][3].replace('-','')\n",
    "                            try:\n",
    "                                retrieved_sequence_updated\n",
    "                            except NameError:\n",
    "                                retrieved_sequence_updated = retrieved_sequence.replace(hit_sequence, hsp_queries_and_midlines_list[index][3])\n",
    "                            else:\n",
    "                                 retrieved_sequence_updated = retrieved_sequence_updated.replace(hit_sequence, hsp_queries_and_midlines_list[index][3])\n",
    "                    blastdbcmd_alignments_list_read_sublist.append('<Hsp_hseq>'+retrieved_sequence_updated+'</Hsp_hseq>')\n",
    "                elif adjustment_required == False:\n",
    "                    blastdbcmd_alignments_list_read_sublist.append('<Hsp_hseq>'+retrieved_sequence+'</Hsp_hseq>')\n",
    "            else:\n",
    "                # check whether any hsp has a retrieved sequence alignment needing adjustment (in the retrieved sequence [already updated with any insertion(s) in the span between hsp's]) across the hsp span\n",
    "                adjustment_required = False\n",
    "                for index, hsp in enumerate(hsp_queries_and_midlines_list):\n",
    "                    if 'hsp query has insertion(s) relative to hit' in hsp:\n",
    "                        adjustment_required = True\n",
    "                if adjustment_required == True:\n",
    "                    for index, hsp in enumerate(hsp_queries_and_midlines_list):\n",
    "                        if 'hsp query has insertion(s) relative to hit' in hsp:\n",
    "                            hit_sequence = hsp_queries_and_midlines_list[index][3].replace('-','')\n",
    "                            try:\n",
    "                                retrieved_sequence_updated2\n",
    "                            except NameError:\n",
    "                                retrieved_sequence_updated2 = retrieved_sequence_updated.replace(hit_sequence, hsp_queries_and_midlines_list[index][3])\n",
    "                            else:\n",
    "                                 retrieved_sequence_updated2 = retrieved_sequence_updated2.replace(hit_sequence, hsp_queries_and_midlines_list[index][3])\n",
    "                    blastdbcmd_alignments_list_read_sublist.append('<Hsp_hseq>'+retrieved_sequence_updated+'</Hsp_hseq>')\n",
    "                elif adjustment_required == False:\n",
    "                    blastdbcmd_alignments_list_read_sublist.append('<Hsp_hseq>'+retrieved_sequence_updated+'</Hsp_hseq>')\n",
    "            blastdbcmd_alignments_list_read_sublist.append('<Hsp_midline>'+reconstructed_midline+'</Hsp_midline>')\n",
    "            blastdbcmd_alignments_list.append(blastdbcmd_alignments_list_read_sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Take note of sample IDs with reads that were considered for multiple-hsp reconstruction, but deprecated because\n",
    "# of overlapping hsp's and/or hsp span exceeding 1kb\n",
    "multiple_alignments_hsp_invalid2_list = [i for i in multiple_alignments_hsp_dict_invalid2]\n",
    "\n",
    "# Log alignment time duration\n",
    "alignmentsDuration = str(datetime.now()- startTime_alignments).split(':')[0]+' hr|'+str(datetime.now() - startTime_alignments).split(':')[1]+' min|'+str(datetime.now() - startTime_alignments).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_alignments).split(':')[2].split('.')[1]+' microsec' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Finalize list containing candidate alleles with single alignment hit in reference database.  \n",
    "Prepare **'alignmentoutput_dict'**, a dictionary that aggregates all sample-associated alleles as sublists within a single list (value) assigned to appropriate sample name ID (key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# for reads & their alignment data in alignments_list3 that were not identified as associated with >1 hsp, trim back each sublist to 10 indices (rather than 12 [remove accession and hsp_num indices, located at indices 5 & 6 of each sublist in alignments_list3]) (make these compatible with alignments_list4)\n",
    "# First exclude these reads from alignments_list4, because they will be instead delivered via blastdbcmd_alignments_list\n",
    "multiple_alignments_hsp_list_to_exclude_from_alignments_list4 = []\n",
    "for i in multiple_alignments_hsp_dict:\n",
    "    for read in multiple_alignments_hsp_dict.get(i):\n",
    "        multiple_alignments_hsp_list_to_exclude_from_alignments_list4.append(read)\n",
    "\n",
    "alignments_list_temp = []\n",
    "for i in alignments_list3:\n",
    "    if i not in multiple_alignments_hits_list:\n",
    "        if i not in multiple_alignments_hsp_list_to_exclude_from_alignments_list4:\n",
    "            alignments_list_temp.append([i[0]]+[i[1]]+[i[2]]+[i[3]]+[i[4]]+[i[7]]+[i[8]]+[i[9]]+[i[10]]+[i[11]])\n",
    "            \n",
    "# Now pool alignment data delivered strictly from BLASTN (alignments_list4), with alignment data 'reconstituted' by BLASTDBCMD (blastdbcmd_alignments_list)\n",
    "alignments_list4 = alignments_list_temp + blastdbcmd_alignments_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Among lists containing alignment data in alignments_list4, determine which queries (reads) correspond to the same sample; where querydef = i[1].split(\">\")[1].split(\"_[\")[0], reads belonging to the same sample share identical querydef\n",
    "# Fasta deflines encode frequency metrics for reads, based on defline format:\n",
    "# sampleID_[reads/total reads]_percentile_% read abundance_% top 10 reads_% reads filtered for 1%_% reads filtered for 10%\n",
    "querydef_list = []\n",
    "for i in alignments_list3:\n",
    "    querydef = i[1].split(\">\")[1].split(\"_\")[0]\n",
    "    querydef_list.append(querydef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# collapse querydef_list content into list of UNIQUE sample IDs\n",
    "querydef_uniq_list = []\n",
    "for i in querydef_list:\n",
    "    if i in querydef_uniq_list:\n",
    "        pass\n",
    "    else:\n",
    "        querydef_uniq_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare dictionary relating sample IDs to their associated reads ('alleles')\n",
    "# Reorder ranked alleles as necessary\n",
    "alignmentoutput_dict = {}\n",
    "for i in querydef_uniq_list:\n",
    "    temp_ranked_read_list = [x for x in alignments_list4 if bool(re.search(i, x[1]))]\n",
    "    temp_ranked_read_order = []\n",
    "    new_ranked_read_order = []\n",
    "    for index, ranked_read in enumerate(temp_ranked_read_list):\n",
    "        rank = int(ranked_read[1].split('>')[1].split('<')[0].split('_')[3].split('k')[1])\n",
    "        temp_ranked_read_order.append([rank, ranked_read])\n",
    "    for read in sorted(temp_ranked_read_order):\n",
    "        new_ranked_read_order.append(read[1])\n",
    "    alignmentoutput_dict[\"{0}\".format(i)] = tuple(new_ranked_read_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Identify sample IDs for which no valid candidate alleles were identified. These samples are not further analyzed, but their identities are reported in 'population_summary.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Identify & subset sample ID's that do not have output alleles (empty tuple values in dictionary)\n",
    "empty_sampleIDs_list = []\n",
    "for i in alignmentoutput_dict:\n",
    "    if bool(alignmentoutput_dict.get(i) == ()):\n",
    "        empty_sampleIDs_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Make a copy of alignmentoutput_dict, removing dictionary keys with empty tuple values\n",
    "alignmentoutput_dict2 = { k : v for k,v in alignmentoutput_dict.items() if v}\n",
    "# Alignmentoutput_dict2 is the key input dictionary for genotype extrapolations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### V. Infer genotypes \n",
    "Data for sample-specific alleles were assembled in **alignmentoutput_dict**, a dictionary that collected alignment data for each sample's top 10 reads, with each read's frequency metrics maintained in the allele name (defline). The contents of this dictionary are now further parsed to assemble a second dictionary--**imputedgenotypes_dict**--in which analytics for each read are collected in sample-specific values: \n",
    "  - **allele type** is defined as 'wild-type' or 'mutant'\n",
    "  - if mutant, **allele specification** is further defined as 'deletion', 'insertion', 'substitution', 'indel', etc.\n",
    "  - if guide RNA or DNA test sequence(s) were specified during user input, the script searches for these user-specified sequence(s) in the read alignment (in both 'query' and 'hit') and records the starting position of the sequence match within the read string, for later positional mapping relative to the alignment\n",
    "  - finally, **genotype is inferred** for each sample based on the allele type(s) and specification(s) for reads that occur at >10% abundance (adjusted for all reads that occur at >10% raw frequency)\n",
    "\n",
    "--------\n",
    "**imputedgenotypes_dict**, the key data structure in which allele and genotype data are collected for individual samples, operates on the following organizational logic:  \n",
    "  - each sample ID is a unique dictionary key\n",
    "  - each sample value is a list, with data for all associated alleles individualized within sublists\n",
    "  - for each allele, four subdictionaries organize data for that allele within its sublist\n",
    "    - subdictionary 1 (with keys 'allele_name', 'chr+build', 'locus_ID', 'coordinates', 'alignment') organizes alignment data\n",
    "      (including frequency metrics within the 'allele_name' string value)\n",
    "    - subdictionary 2 (with keys 'allele_type', 'allele_specs') organizes allele definitions\n",
    "    - subdictionary 3 (with keys for each guide and/or its reverse) organizes positional mapping information to locate a guide sequence relative to the sequence alignment\n",
    "    - subdictionary 4 (with keys for each test sequence and/or its reverse) organizes positional mapping information to locate a test sequence relative to the sequence alignment  \n",
    "    \n",
    "*example*:  \n",
    "**imputedgenotypes_dict** = {'**sample ID1**': \\[[{'allele1_name':'.....', 'chr+build':'.....', 'locus_ID':'.....', 'coordinates':'.....', 'alignment':'query \\n midline \\n hit'}, {'allele_type':'mutant | wild-type', 'allele_specs':'deletion | insertion | substitution | indel, size'}, {'guide1':'sequence position', 'guide2':'sequence position}, {'test sequence1':'sequence position', 'test sequence2':'sequence position'}\\], \\[{'allele2_name':'.....', 'chr+build':'.....', 'locus_ID':'.....', 'coordinates':'.....', 'alignment':'query \\n midline \\n hit'}, {'allele_type':'mutant | wild-type', 'allele_specs':'deletion | insertion | substitution | indel, size'}, {'guide1':'sequence position', 'guide2':'sequence position}, {'test sequence1':'sequence position', 'test sequence2':'sequence position'}\\]], '**sample ID2**': \\[[{...},{...},{...},{...}\\],\\[{...},{...},{...},{...}\\],...], '**sample ID3**' : \\[[{...},{...},{...},{...}\\],\\[{...},{...},{...},{...}\\],...], . . . }  \n",
    "\n",
    "--------\n",
    "The output of these analytics is reported in **'allele_definitions.txt'** and **'imputed_genotypes.txt'**.  \n",
    "These files overlap in content, except that samples are reported in alphanumeric order based on sample ID name in **'allele_definitions.txt'** whereas samples are reported in ranked order of inferred genotype class (*e.g., homozygous deletions first*) in **'imputed_genotypes.txt'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare dictionary relating sample IDs to their associated 'alleles', allele interpretations/definitions, and inferred genotype\n",
    "imputedgenotypes_dict = {}\n",
    "for i in alignmentoutput_dict2:\n",
    "    imputedgenotypes_dict[\"{0}\".format(i)] = []\n",
    "    imputed_genotype = []\n",
    "    allele_data = ['allele_name', 'chr+build', 'locusID', 'coordinates', 'alignment']\n",
    "    allele_descriptions = ['allele_type', 'allele_specs']\n",
    "    guideRNA_match = ''\n",
    "    extant_match = ''\n",
    "    for x in range(0,len(alignmentoutput_dict2.get(i))):\n",
    "        imputedgenotypes_dict[i].extend([[]])\n",
    "        allele_data_x = []\n",
    "        allele_data_x.append(alignmentoutput_dict2.get(i)[x][1].split(\">\")[1].split(\"<\")[0].replace('_', ' '))\n",
    "        allele_data_x.append(alignmentoutput_dict2.get(i)[x][4].split(\">\")[1].split(\"<\")[0])\n",
    "        allele_data_x.append(alignmentoutput_dict2.get(i)[x][3].split(\">\")[1].split(\"<\")[0])\n",
    "        allele_data_x.append(alignmentoutput_dict2.get(i)[x][5].split(\">\")[1].split(\"<\")[0]+'-'+alignmentoutput_dict2.get(i)[x][6].split(\">\")[1].split(\"<\")[0])\n",
    "        allele_data_x.append('\\n'+'    query  '+alignmentoutput_dict2.get(i)[x][7].split(\">\")[1].split(\"<\")[0]+'\\n'+'           '+alignmentoutput_dict2.get(i)[x][9].split(\">\")[1].split(\"<\")[0]+'\\n'+'reference  '+alignmentoutput_dict2.get(i)[x][8].split(\">\")[1].split(\"<\")[0])\n",
    "        imputedgenotypes_dict[i][x].append(((dict(zip(allele_data, allele_data_x)))))\n",
    "        allele_descriptions_x = []\n",
    "        if bool(re.search(' ', alignmentoutput_dict2.get(i)[x][9])):\n",
    "            allele_descriptions_x.append('mutant')\n",
    "            if bool(re.search('-', alignmentoutput_dict2.get(i)[x][7])) and not bool(re.search('-', alignmentoutput_dict2.get(i)[x][8])):\n",
    "                allele_descriptions_x.append('likely deletion, '+str(alignmentoutput_dict2.get(i)[x][7].count('-'))+' bp')\n",
    "                imputedgenotypes_dict[i][x].append(((dict(zip(allele_descriptions, allele_descriptions_x)))))\n",
    "                # imputed genotype is based on alleles with frequency adjusted as relative to reads that occurred at >10% raw frequency\n",
    "                if imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1].strip()) > 10:\n",
    "                    imputed_genotype.append(imputedgenotypes_dict.get(i)[x][1].get('allele_specs'))\n",
    "            elif bool(re.search('-', alignmentoutput_dict2.get(i)[x][8])) and not bool(re.search('-', alignmentoutput_dict2.get(i)[x][7])):\n",
    "                allele_descriptions_x.append('likely insertion, '+str(alignmentoutput_dict2.get(i)[x][8].count('-'))+' bp')\n",
    "                imputedgenotypes_dict[i][x].append(((dict(zip(allele_descriptions, allele_descriptions_x)))))\n",
    "                if imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1]) > 10:\n",
    "                    imputed_genotype.append(imputedgenotypes_dict.get(i)[x][1].get('allele_specs'))\n",
    "            elif bool(re.search('-', alignmentoutput_dict2.get(i)[x][7])) and bool(re.search('-', alignmentoutput_dict2.get(i)[x][8])):\n",
    "                allele_descriptions_x.append('likely complex indel')\n",
    "                imputedgenotypes_dict[i][x].append(((dict(zip(allele_descriptions, allele_descriptions_x)))))\n",
    "                if imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1]) > 10:\n",
    "                    imputed_genotype.append(imputedgenotypes_dict.get(i)[x][1].get('allele_specs'))\n",
    "            else:\n",
    "                allele_descriptions_x.append('likely substitution')\n",
    "                imputedgenotypes_dict[i][x].append(((dict(zip(allele_descriptions, allele_descriptions_x)))))\n",
    "                if imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1]) > 10:\n",
    "                    imputed_genotype.append(imputedgenotypes_dict.get(i)[x][1].get('allele_specs'))\n",
    "        else:\n",
    "            allele_descriptions_x.append('wild-type')\n",
    "            imputedgenotypes_dict[i][x].append(((dict(zip(allele_descriptions, allele_descriptions_x)))))\n",
    "            if imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                pass\n",
    "            elif float(imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1]) > 10:\n",
    "                imputed_genotype.append('wild-type')\n",
    "        # find guide RNA sequence in reference sequence, and record location so that guide can be printed at appropriate position above reference sequence\n",
    "        try:\n",
    "            guideRNA_seq\n",
    "        except NameError:\n",
    "            imputedgenotypes_dict[i][x].extend([{}])\n",
    "        else:\n",
    "            guideRNA_seq_orientation_list = []\n",
    "            guide_positions_list = []\n",
    "            guideRNA_match = ''\n",
    "            guideRNA_revcomp_match = ''\n",
    "            for guide in guideRNA_seq:\n",
    "                if bool(re.search('-', alignmentoutput_dict2.get(i)[x][7])):\n",
    "                    if bool(re.search('-', alignmentoutput_dict2.get(i)[x][8])):\n",
    "                        guideRNA_match = re.search(guide, alignmentoutput_dict2.get(i)[x][8].replace('-', '')) or re.search(guide, alignmentoutput_dict2.get(i)[x][7].replace('-', ''))\n",
    "                    else:\n",
    "                        guideRNA_match = re.search(guide, alignmentoutput_dict2.get(i)[x][8].replace('-', ''))\n",
    "                else:\n",
    "                    guideRNA_match = re.search(guide, alignmentoutput_dict2.get(i)[x][7].replace('-', '')) \n",
    "                if not guideRNA_match:\n",
    "                    guide_revcomp = ''.join(reversed(''.join(nt_dict.get(nt) for nt in guide)))\n",
    "                    guide_rev = ''.join(reversed(guide))\n",
    "                    if bool(re.search('-', alignmentoutput_dict2.get(i)[x][7])):\n",
    "                        if bool(re.search('-', alignmentoutput_dict2.get(i)[x][8])):\n",
    "                            guideRNA_revcomp_match = re.search(guide_revcomp, alignmentoutput_dict2.get(i)[x][8].replace('-', '')) or re.search(guide_revcomp, alignmentoutput_dict2.get(i)[x][7].replace('-', ''))\n",
    "                        else:\n",
    "                            guideRNA_revcomp_match = re.search(guide_revcomp, alignmentoutput_dict2.get(i)[x][8].replace('-', '')) or re.search(guide_revcomp, alignmentoutput_dict2.get(i)[x][7].replace('-', ''))\n",
    "                    if not guideRNA_revcomp_match:\n",
    "                        guideRNA_seq_orientation_list.append('guide')\n",
    "                        guide_positions_list.append('None')\n",
    "                    else:\n",
    "                        guideRNA_seq_orientation_list.append(guide_rev)\n",
    "                        guide_positions_list.append(guideRNA_revcomp_match.start())\n",
    "                else:\n",
    "                    guideRNA_seq_orientation_list.append(guide)\n",
    "                    guide_positions_list.append(guideRNA_match.start())\n",
    "            imputedgenotypes_dict[i][x].append(((dict(zip(guideRNA_seq_orientation_list, guide_positions_list)))))\n",
    "        try:\n",
    "            extant_seq\n",
    "        except NameError:\n",
    "            imputedgenotypes_dict[i][x].extend([{}])\n",
    "        else:\n",
    "            extant_seq_orientation_list = []\n",
    "            seq_positions_list = []\n",
    "            extant_match = ''\n",
    "            seq_revcomp_match = ''\n",
    "            for seq in extant_seq:\n",
    "                # if test sequence is found in forward direction in query or hit:\n",
    "                extant_match = re.search(seq, alignmentoutput_dict2.get(i)[x][8]) or re.search(seq, alignmentoutput_dict2.get(i)[x][7])\n",
    "                if not extant_match:\n",
    "                    seq_revcomp = ''.join(reversed(''.join(nt_dict.get(nt) for nt in seq)))\n",
    "                    seq_rev = ''.join(reversed(seq))\n",
    "                    # if test sequence is found in reverse direction in query:\n",
    "                    seq_revcomp_match = re.search(seq_revcomp, alignmentoutput_dict2.get(i)[x][8]) or re.search(seq_revcomp, alignmentoutput_dict2.get(i)[x][7])\n",
    "                    if not seq_revcomp_match:\n",
    "                        extant_match = re.search(seq, alignmentoutput_dict2.get(i)[x][8].replace('-', '')) or re.search(seq, alignmentoutput_dict2.get(i)[x][7].replace('-', ''))\n",
    "                        if extant_match:\n",
    "                            pad_match = len(re.findall('-', alignmentoutput_dict2.get(i)[x][8])) or len(re.findall('-', alignmentoutput_dict2.get(i)[x][8]))\n",
    "                            extant_seq_orientation_list.append(seq)\n",
    "                            seq_positions_list.append(extant_match.start()+pad_match)\n",
    "                        if not extant_match:\n",
    "                            seq_revcomp_match = re.search(seq_revcomp, alignmentoutput_dict2.get(i)[x][8].replace('-', '')) or re.search(seq_revcomp, alignmentoutput_dict2.get(i)[x][7].replace('-', ''))\n",
    "                            if seq_revcomp_match:\n",
    "                                pad_match = len(re.findall('-', alignmentoutput_dict2.get(i)[x][8])) or len(re.findall('-', alignmentoutput_dict2.get(i)[x][7]))\n",
    "                            if not seq_revcomp_match:\n",
    "                                extant_seq_orientation_list.append(seq)\n",
    "                                seq_positions_list.append('None')\n",
    "                            else:\n",
    "                                extant_seq_orientation_list.append(seq_rev)     \n",
    "                                seq_positions_list.append(seq_revcomp_match.start())\n",
    "                    else:\n",
    "                        extant_seq_orientation_list.append(seq_rev)     \n",
    "                        seq_positions_list.append(seq_revcomp_match.start()) \n",
    "                else:\n",
    "                    extant_seq_orientation_list.append(seq)\n",
    "                    seq_positions_list.append(extant_match.start())\n",
    "            imputedgenotypes_dict[i][x].append(((dict(zip(extant_seq_orientation_list, seq_positions_list))))) \n",
    "    # impute genotype based on allele(s) recorded as occurring at >10% frequency in imputed_genotypes list; deliver to index[0] position of imputedgenotypes_dict value for sampleID key\n",
    "    # homozygous states\n",
    "    if len(set(imputed_genotype)) == 1:\n",
    "        if bool('wild-type' in imputed_genotype):\n",
    "            imputedgenotypes_dict[i].insert(0, '|homozygous| wild-type (wt/wt)')\n",
    "        for n in set(imputed_genotype):\n",
    "            if bool(re.search('deletion', n)):\n",
    "                imputedgenotypes_dict[i].insert(0, '|homozygous| deletion (delta/delta)')\n",
    "            if bool(re.search('insertion', n)):\n",
    "                imputedgenotypes_dict[i].insert(0, '|homozygous| insertion (++/++)')\n",
    "            if bool(re.search('indel', n)):\n",
    "                imputedgenotypes_dict[i].insert(0, '|homozygous| indel (indel/indel')\n",
    "            if bool(re.search('substitution', n)):\n",
    "                imputedgenotypes_dict[i].insert(0, '|homozygous| substitution (sub/sub)')\n",
    "    #heterozygous states\n",
    "    elif len(set(imputed_genotype)) == 2:\n",
    "    # with wild-type allele\n",
    "        if bool('wild-type' in imputed_genotype):\n",
    "            for n in set(imputed_genotype):\n",
    "                if re.search('deletion', n):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| deletion + wild-type (delta/wt)')\n",
    "                elif re.search('insertion', n):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| insertion + wild-type (++/wt)')\n",
    "                elif re.search('indel', n):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| indel + wild-type  (indel/wt)')\n",
    "                elif re.search('substitution', n):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| substitution + wild-type (sub/wt)')\n",
    "    #heterozygous states (no wild-type allele)\n",
    "        elif not bool('wild-type' in imputed_genotype):\n",
    "            genotype_impute_summary = []\n",
    "            for n in set(imputed_genotype):\n",
    "                if re.search('wild-type', n):\n",
    "                    genotype_impute_summary.append('wild-type')\n",
    "                elif re.search('deletion', n):\n",
    "                    genotype_impute_summary.append('deletion')\n",
    "                elif re.search('insertion', n):\n",
    "                    genotype_impute_summary.append('insertion')\n",
    "                elif re.search('indel', n):\n",
    "                    genotype_impute_summary.append('indel')\n",
    "                elif re.search('substitution', n):\n",
    "                    genotype_impute_summary.append('substitution')\n",
    "            if len(set(genotype_impute_summary)) == 1:\n",
    "                if 'deletion' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| deletion1 + deletion2 (del1/del2)')\n",
    "                elif 'insertion' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| insertion1 + insertion2 (++1/++2)')\n",
    "                elif 'indel' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| indel1 + indel2 (indel1/indel2)')\n",
    "                elif 'substitution' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| substitution1 + substitution2 (sub1/sub2)')\n",
    "            else:\n",
    "                if 'deletion' in set(genotype_impute_summary) and 'insertion' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| deletion + insertion (del/++)')\n",
    "                elif 'deletion' in set(genotype_impute_summary) and 'indel' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| deletion + indel (del/indel)')\n",
    "                elif 'deletion' in set(genotype_impute_summary) and 'substitution' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| deletion + substitution (del/sub)')\n",
    "                elif 'insertion' in set(genotype_impute_summary) and 'indel' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| insertion + indel (++/indel)')\n",
    "                elif 'insertion' in set(genotype_impute_summary) and 'substitution' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| insertion + indel (++/sub)')                    \n",
    "                elif 'indel' in set(genotype_impute_summary) and 'substitution' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| indel + substitution (indel/sub)')\n",
    "    #multizygous states\n",
    "    elif len(set(imputed_genotype)) > 2:\n",
    "        imputed_genotype_str = '|multizygous|'\n",
    "        genotype_impute_summary = []\n",
    "        for n in set(imputed_genotype):\n",
    "            if re.search('wild-type', n):\n",
    "                genotype_impute_summary.append('wild-type')\n",
    "            elif re.search('deletion', n):\n",
    "                genotype_impute_summary.append('deletion')\n",
    "            elif re.search('insertion', n):\n",
    "                genotype_impute_summary.append('insertion')\n",
    "            elif re.search('indel', n):\n",
    "                genotype_impute_summary.append('indel')\n",
    "            elif re.search('substitution', n):\n",
    "                genotype_impute_summary.append('substitution')\n",
    "        if 'wild-type' in genotype_impute_summary:\n",
    "            imputed_genotype_str = imputed_genotype_str+' wild-type'\n",
    "            if 'deletion' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + deletion ('+str(genotype_impute_summary.count('deletion'))+')'\n",
    "            if 'insertion' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + insertion ('+str(genotype_impute_summary.count('insertion'))+')'\n",
    "            if 'indel' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + indel ('+str(genotype_impute_summary.count('indel'))+')'\n",
    "            if 'substitution' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + substitution ('+str(genotype_impute_summary.count('substitution'))+')'\n",
    "        elif 'deletion' in genotype_impute_summary:\n",
    "            imputed_genotype_str = imputed_genotype_str+' deletion ('+str(genotype_impute_summary.count('deletion'))+')'\n",
    "            if 'insertion' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + insertion ('+str(genotype_impute_summary.count('insertion'))+')'\n",
    "            if 'indel' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + indel ('+str(genotype_impute_summary.count('indel'))+')'\n",
    "            if 'substitution' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + substitution ('+str(genotype_impute_summary.count('substitution'))+')'\n",
    "        elif 'insertion' in genotype_impute_summary:\n",
    "            imputed_genotype_str = imputed_genotype_str+' insertion ('+str(genotype_impute_summary.count('insertion'))+')'\n",
    "            if 'indel' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + indel ('+str(genotype_impute_summary.count('indel'))+')'\n",
    "            if 'substitution' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + substitution ('+str(genotype_impute_summary.count('substitution'))+')'\n",
    "        elif 'indel' in genotype_impute_summary:\n",
    "            imputed_genotype_str = imputed_genotype_str+' indel ('+str(genotype_impute_summary.count('indel'))+')'\n",
    "            if 'substitution' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + substitution ('+str(genotype_impute_summary.count('substitution'))+')'\n",
    "        elif 'substitution' in genotype_impute_summary:\n",
    "            imputed_genotype_str = imputed_genotype_str+' + substitution ('+str(genotype_impute_summary.count('substitution'))+')'   \n",
    "        imputedgenotypes_dict[i].insert(0, imputed_genotype_str)\n",
    "    elif not imputed_genotype:\n",
    "        imputedgenotypes_dict[i].insert(0, '|unclear or multi-allelic| insufficient representation of any allele (i.e., no allele exceeds >10% of total reads when adjusted for 10% read threshold)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Create list containing reversed guideRNA_seq & extant_seq sequences, for use with R2 sequences\n",
    "try:\n",
    "    guideRNA_seq\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    guideRNA_seq_rev = [''.join(reversed(i)) for i in guideRNA_seq]\n",
    "    \n",
    "try:\n",
    "    extant_seq\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    extant_seq_rev = [''.join(reversed(i)) for i in extant_seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Report alleles and inferred genotypes to output file, **'allele_definitions.txt'**. Print location of guide RNA and/or test sequence matches relative to sequence alignments (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Print summaries of sample-specific allele definitions to output files; first to allele_definitions.txt, preserving sample order\n",
    "allele_definitions_output = Path(str(output_path)+'/'+processdate+'_allele_definitions.txt')\n",
    "with open(str(allele_definitions_output), 'a+') as file:\n",
    "    file.write('Genotypes.py: Allele Definitions\\nDate: ' + (datetime.today().strftime(\"%m/%d/%Y\")) + '\\n\\n')\n",
    "    for i in querydef_uniq_list:\n",
    "        if i in imputedgenotypes_dict:\n",
    "            file.write((len(i)*'=')+'\\n'+i+'\\n'+(len(i)*'=')+'\\n')\n",
    "            file.write('Inferred Genotype: '+imputedgenotypes_dict.get(i)[0]+'\\n')\n",
    "            # display alleles and their descriptions\n",
    "            read_checklist = []\n",
    "            read_abundance_checklist = []\n",
    "            for n in range(1, len(imputedgenotypes_dict.get(i))):\n",
    "                if imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[1] == 'R1+R2':\n",
    "                    if 'R1+R2' not in read_checklist:\n",
    "                        read_checklist.append('R1+R2')\n",
    "                        file.write('\\n'+3*' '+'*'+17*'~'+'*\\n'+3*' '+'| READ 1 + READ 2 |\\n'+3*' '+'*'+17*'~'+'*\\n\\n')\n",
    "                    else:\n",
    "                        pass\n",
    "                    if float(imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[4].split(':')[1]) < 10:\n",
    "                        if 'R1+R2dregs' not in read_abundance_checklist:\n",
    "                            read_abundance_checklist.append('R1+R2dregs')\n",
    "                            file.write(3*' '+'*'+56*'~'+'*\\n'+3*' '+'|  >>>>> remaining alleles occur at frequency <10% <<<<< |\\n'+3*' '+'*'+56*'~'+'*\\n\\n')\n",
    "                        else:\n",
    "                            pass\n",
    "                if imputedgenotypes_dict.get(i)[n][1].get('allele_type') == 'wild-type':\n",
    "                    file.write(3*' '+'Allele: '+imputedgenotypes_dict.get(i)[n][0].get('allele_name')+' | '+imputedgenotypes_dict.get(i)[n][1].get('allele_type')+'\\n    Locus: '+imputedgenotypes_dict.get(i)[n][0].get('chr+build')+', '+imputedgenotypes_dict.get(i)[n][0].get('locusID')+' '+imputedgenotypes_dict.get(i)[n][0].get('coordinates')+'\\n')\n",
    "                else:\n",
    "                    file.write(3*' '+'Allele: '+imputedgenotypes_dict.get(i)[n][0].get('allele_name')+' | '+imputedgenotypes_dict.get(i)[n][1].get('allele_type')+', '+imputedgenotypes_dict.get(i)[n][1].get('allele_specs')+'\\n    Locus: '+imputedgenotypes_dict.get(i)[n][0].get('chr+build')+', '+imputedgenotypes_dict.get(i)[n][0].get('locusID')+' '+imputedgenotypes_dict.get(i)[n][0].get('coordinates')+'\\n')           \n",
    "                for guide in imputedgenotypes_dict.get(i)[n][2]:\n",
    "                    if imputedgenotypes_dict.get(i)[n][2].get(guide) != 'None':\n",
    "                        if guide in guideRNA_seq:\n",
    "                            file.write('\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))-2)*' '+\"5'-\"+guide+\"-3' (guide sequence)\"+'\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))+len(guide)-3)*' '+'v')\n",
    "                        elif guide in guideRNA_seq_rev:\n",
    "                            file.write('\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))-2)*' '+\"3'-\"+guide+\"-5' (guide sequence)\"+'\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))+4)*' '+'v')\n",
    "                file.write(imputedgenotypes_dict.get(i)[n][0].get('alignment'))\n",
    "                for seq in imputedgenotypes_dict.get(i)[n][3]:\n",
    "                    if imputedgenotypes_dict.get(i)[n][3].get(seq) != 'None':\n",
    "                        file.write('\\n')\n",
    "                        if seq in extant_seq:\n",
    "                            file.write((1+int(imputedgenotypes_dict.get(i)[n][3].get(seq)))*' '+len(seq)*'^'+'\\n'+(int(imputedgenotypes_dict.get(i)[n][3].get(seq))-2)*' '+\"5'-\"+seq+\"-3' (sequence of interest)\\n\")\n",
    "                        elif seq in extant_seq_rev:\n",
    "                            file.write((1+int(imputedgenotypes_dict.get(i)[n][3].get(seq)))*' '+len(seq)*'^'+'\\n'+(int(imputedgenotypes_dict.get(i)[n][3].get(seq))-2)*' '+\"3'-\"+seq+\"-5' (sequence of interest)\\n\")\n",
    "                    elif imputedgenotypes_dict.get(i)[n][3].get(seq) == 'None':\n",
    "                        file.write('\\n')\n",
    "                file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Report alleles and inferred genotypes to output file, **'genotypes.txt'**. Print location of guide RNA and/or test sequence matches relative to sequence alignments (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Next print to genotypes.txt, using extrapolated genotype criteria as basis for reporting order\n",
    "# First prepare lists that bin sampleIDs based on inferred genotype\n",
    "# homo genotypes\n",
    "imputedgenotypes_homowildtype = []\n",
    "imputedgenotypes_homodeletion = []\n",
    "imputedgenotypes_homoinsertion = []\n",
    "imputedgenotypes_homoindel = []\n",
    "imputedgenotypes_homosubstitution = []\n",
    "# biallelic mutant genotypes\n",
    "imputedgenotypes_biallelic_deletion = []\n",
    "imputedgenotypes_biallelic_insertion = []\n",
    "imputedgenotypes_biallelic_indel = []\n",
    "imputedgenotypes_biallelic_substitution = []\n",
    "imputedgenotypes_biallelic_other = []\n",
    "# hetero genotypes (containing wt allele)\n",
    "imputedgenotypes_heterodeletion = []\n",
    "imputedgenotypes_heteroinsertion = []\n",
    "imputedgenotypes_heteroindel = []\n",
    "imputedgenotypes_heterosubstitution = []\n",
    "# multizygous\n",
    "imputedgenotypes_multizygous = []\n",
    "# unclear\n",
    "imputedgenotypes_unclear = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Add sampleIDs to appropriate lists, based on genotype class inferred for each sample\n",
    "for i in imputedgenotypes_dict:\n",
    "    if imputedgenotypes_dict.get(i)[0] in ('|homozygous| wild-type (wt/wt)'):\n",
    "        imputedgenotypes_homowildtype.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|homozygous| deletion (delta/delta)'):\n",
    "        imputedgenotypes_homodeletion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|homozygous| insertion (++/++)'):\n",
    "        imputedgenotypes_homoinsertion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|homozygous| indel (indel/indel)'):\n",
    "        imputedgenotypes_homoindel.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|homozygous| substitution (sub/sub)'):\n",
    "        imputedgenotypes_homosubstitution.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| deletion1 + deletion2 (del1/del2)'):\n",
    "        imputedgenotypes_biallelic_deletion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| insertion1 + insertion2 (++1/++2)'):\n",
    "        imputedgenotypes_biallelic_insertion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| indel1 + indel2 (indel1/indel2)'):\n",
    "        imputedgenotypes_biallelic_indel.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| substitution1 + substitution2 (sub1/sub2)'):\n",
    "        imputedgenotypes_biallelic_substitution.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| deletion + insertion (del/++)', '|heterozygous| deletion + indel (del/indel)', '|heterozygous| deletion + substitution (del/sub)', '|heterozygous| insertion + indel (++/indel)', '|heterozygous| insertion + indel (++/sub)', '|heterozygous| indel + substitution (indel/sub)'):\n",
    "        imputedgenotypes_biallelic_other.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| deletion + wild-type  (delta/wt)'):\n",
    "        imputedgenotypes_heterodeletion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| insertion + wild-type (++/wt)'):\n",
    "        imputedgenotypes_heteroinsertion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| indel + wild-type (indel/wt)'):\n",
    "        imputedgenotypes_heteroindel.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| substitution + wild-type (sub/wt)'):\n",
    "        imputedgenotypes_heterosubstitution.append(i)\n",
    "    elif re.search('multizygous', imputedgenotypes_dict.get(i)[0]):\n",
    "        imputedgenotypes_multizygous.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|unclear or multi-allelic| insufficient representation of any allele (i.e., no allele exceeds >10% of total reads when adjusted for 10% read threshold)'):\n",
    "        imputedgenotypes_unclear.append(i)\n",
    "    elif re.search('', imputedgenotypes_dict.get(i)[0]):\n",
    "        imputedgenotypes_unclear.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Alphanumerically sort the imputedgenotypes lists in place\n",
    "imputedgenotypes_homowildtype.sort()\n",
    "imputedgenotypes_homodeletion.sort()\n",
    "imputedgenotypes_homoinsertion.sort()\n",
    "imputedgenotypes_homoindel.sort()\n",
    "imputedgenotypes_homosubstitution.sort()\n",
    "imputedgenotypes_biallelic_deletion.sort()\n",
    "imputedgenotypes_biallelic_insertion.sort()\n",
    "imputedgenotypes_biallelic_indel.sort()\n",
    "imputedgenotypes_biallelic_substitution.sort()\n",
    "imputedgenotypes_biallelic_other.sort()\n",
    "imputedgenotypes_heterodeletion.sort()\n",
    "imputedgenotypes_heteroinsertion.sort()\n",
    "imputedgenotypes_heteroindel.sort()\n",
    "imputedgenotypes_heterosubstitution.sort()\n",
    "imputedgenotypes_multizygous.sort()\n",
    "imputedgenotypes_unclear.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Print to genotypes.txt\n",
    "imputed_genotypes_output = Path(str(output_path)+'/'+processdate+'_genotypes.txt')\n",
    "# samples are reported in this file based on the following priority:\n",
    "    # imputedgenotypes_homodeletion\n",
    "    # imputedgenotypes_homoinsertion\n",
    "    # iputedgenotypes_homoindel\n",
    "    # imputedgenotypes_homosubstitution\n",
    "    # imputedgenotypes_biallelic_deletion\n",
    "    # imputedgenotypes_biallelic_insertion\n",
    "    # imputedgenotypes_biallelic_indel\n",
    "    # imputedgenotypes_biallelic_substitution\n",
    "    # imputedgenotypes_biallelic_other\n",
    "    # imputedgenotypes_heterodeletion\n",
    "    # imputedgenotypes_heteroinsertion\n",
    "    # imputedgenotypes_heteroindel\n",
    "    # imputedgenotypes_heterosubstitution\n",
    "    # imputedgenotypes_multizygous\n",
    "    # imputedgenotypes_homowildtype\n",
    "    # imputedgenotypes_unclear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Call upon allele_output function to report alleles and inferred genotypes based on inferred genotype class\n",
    "with open(str(imputed_genotypes_output), 'a+') as file:\n",
    "    file.write('Genotypes.py: Genotypes\\nDate: ' + (datetime.today().strftime(\"%m/%d/%Y\")) + '\\n\\n')\n",
    "    if len(imputedgenotypes_homodeletion) > 0:\n",
    "        file.write('\\n\\nHOMOZYGOUS DELETION\\n...................\\n\\n')\n",
    "        allele_output(imputedgenotypes_homodeletion)\n",
    "    if len(imputedgenotypes_homoinsertion) > 0:\n",
    "        file.write('\\n\\nHOMOZYGOUS INSERTION\\n....................\\n\\n')\n",
    "        allele_output(imputedgenotypes_homoinsertion)\n",
    "    if len(imputedgenotypes_homoindel) > 0:\n",
    "        file.write('\\n\\nHOMOZYGOUS INDEL\\n................\\n\\n')\n",
    "        allele_output(imputedgenotypes_homoindel)\n",
    "    if len(imputedgenotypes_homosubstitution) > 0:\n",
    "        file.write('\\n\\nHOMOZYGOUS SUBSTITUTION\\n.......................\\n\\n')\n",
    "        allele_output(imputedgenotypes_homosubstitution)\n",
    "    if len(imputedgenotypes_biallelic_deletion) > 0:\n",
    "        file.write('\\n\\nBIALLELIC DELETION\\n..................\\n\\n')\n",
    "        allele_output(imputedgenotypes_biallelic_deletion)\n",
    "    if len(imputedgenotypes_biallelic_insertion) > 0:\n",
    "        file.write('\\n\\nBIALLELIC INSERTION\\n...................\\n\\n')\n",
    "        allele_output(imputedgenotypes_biallelic_insertion)\n",
    "    if len(imputedgenotypes_biallelic_indel) > 0:\n",
    "        file.write('\\n\\nBIALLELIC INDEL\\n...............\\n\\n')\n",
    "        allele_output(imputedgenotypes_biallelic_indel)\n",
    "    if len(imputedgenotypes_biallelic_substitution) > 0:\n",
    "        file.write('\\n\\nBIALLELIC SUBSTITUTION\\n......................\\n\\n')\n",
    "        allele_output(imputedgenotypes_biallelic_substitution)\n",
    "    if len(imputedgenotypes_biallelic_other) > 0:\n",
    "        file.write('\\n\\nBIALLELIC MUTANT (VARIOUS)\\n..........................\\n\\n')\n",
    "        allele_output(imputedgenotypes_biallelic_other)        \n",
    "    if len(imputedgenotypes_heterodeletion) > 0:\n",
    "        file.write('\\n\\nHETEROZYGOUS DELETION\\n.....................\\n\\n')\n",
    "        allele_output(imputedgenotypes_heterodeletion)\n",
    "    if len(imputedgenotypes_heteroinsertion) > 0:\n",
    "        file.write('\\n\\nHETEROZYGOUS INSERTION\\n......................\\n\\n')\n",
    "        allele_output(imputedgenotypes_heteroinsertion)\n",
    "    if len(imputedgenotypes_heteroindel) > 0:\n",
    "        file.write('\\n\\nHETEROZYGOUS INDEL\\n..................\\n\\n')\n",
    "        allele_output(imputedgenotypes_heteroindel)\n",
    "    if len(imputedgenotypes_heterosubstitution) > 0:\n",
    "        file.write('\\n\\nHETEROZYGOUS SUBSTITUTION\\n.........................\\n\\n')\n",
    "        allele_output(imputedgenotypes_heterosubstitution)\n",
    "    if len(imputedgenotypes_multizygous) > 0:\n",
    "        file.write('\\n\\nMULTIZYGOUS (>2 ALLELES)\\n........................\\n\\n')\n",
    "        allele_output(imputedgenotypes_multizygous)\n",
    "    if len(imputedgenotypes_homowildtype) > 0:\n",
    "        file.write('\\n\\nHOMOZYGOUS WILD-TYPE\\n....................\\n\\n')\n",
    "        allele_output(imputedgenotypes_homowildtype)\n",
    "    if len(imputedgenotypes_unclear) > 0:\n",
    "        file.write('\\n\\nGENOTYPE UNCLEAR (e.g., UNUSUAL ALLELE FREQUENCIES)\\n..................................................\\n\\n')\n",
    "        allele_output(imputedgenotypes_unclear)\n",
    "\n",
    "# Log allele definition & genotype inference time duration\n",
    "imputationDuration = str(datetime.now()- startTime_imputation).split(':')[0]+' hr|'+str(datetime.now() - startTime_imputation).split(':')[1]+' min|'+str(datetime.now() - startTime_imputation).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_imputation).split(':')[2].split('.')[1]+' microsec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### VI. Process accessory files  \n",
    "#### *Transfer allele data to .csv spreadsheet, complete population summary*  \n",
    "**Data availability:** The raw data underlying allele definitions and extrapolated genotypes are housed in a session-specific dictionary, **imputedgenotypes_dict**. These data are made available to a user in spreadsheet format, by transferring dictionary content to a pandas dataframe and then to a comma-separated output file, **allele_definitions.csv**.\n",
    "\n",
    "**Population summary:** Genotypes.py focuses on sample-specific designation of alleles and inferred genotypes, but also reports aggregate population-level statistics in **population_summary.txt**.  Reads (initial candidate 'Ranked Alleles') deprecated from genotype analysis are also recorded here (deprecation may be due to 1) no hit in database, 2) multiple hits in database, or 3) hsp's that overlap or exceed 1 kb span end-to-end).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Allele_definitions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on accessory file processing duration (allele_definitions.csv, population_summary.txt)\n",
    "startTime_fileprocessing = datetime.now()\n",
    "\n",
    "# Import data into pandas dataframe\n",
    "imputedgenotypes_dataframe = pd.DataFrame(\n",
    "    {\n",
    "        \"allele\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[0]+'_'+str(x) for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"read\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"sample\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[0] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"reads\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[2].split('/')[0].strip('[') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"totalreads\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[2].split('/')[1].strip(']') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"%totalreads\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[4].split(':')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"%top10reads\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[6].split(':')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"%readsfilteredfor>1%\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"%readsfilteredfor>10%\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[8].split(':')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],  \n",
    "        \"chr\": [imputedgenotypes_dict.get(i)[x][0].get('chr+build').split(',')[0] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"locusID\": [imputedgenotypes_dict.get(i)[x][0].get('locusID') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"coordinates\": [imputedgenotypes_dict.get(i)[x][0].get('coordinates') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"alignment_query\": [imputedgenotypes_dict.get(i)[x][0].get('alignment').split('\\n')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"alignment_midline\": [imputedgenotypes_dict.get(i)[x][0].get('alignment').split('\\n')[2] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"alignment_hit\": [imputedgenotypes_dict.get(i)[x][0].get('alignment').split('\\n')[3] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"allele_type\": [imputedgenotypes_dict.get(i)[x][1].get('allele_type') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"allele_specs\": [imputedgenotypes_dict.get(i)[x][1].get('allele_specs') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"inferred_genotype\": [imputedgenotypes_dict.get(i)[0] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))]\n",
    "     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare output file containing allele data in comma-separated, tabular format (allele_definitions.csv)\n",
    "allele_definitions_csv_output = Path(str(output_path)+'/'+processdate+'_allele_definitions.csv')\n",
    "\n",
    "imputedgenotypes_dataframe.to_csv(path_or_buf=allele_definitions_csv_output, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Population_summary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare population summary and print to population_summary.txt\n",
    "population_summary_output = Path(str(output_path)+'/'+processdate+'_population_summary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KE4-1-C02', 'KE4-2-A01', 'KE4-4-G02', 'KE4-4-G10']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list containing contents of pandas dataframe, summarizing sample-specific allele definitions and inferred genotype properties\n",
    "imputedgenotypes_dataframe['sample'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: total sample #\n",
    "total_samples = []\n",
    "total_sample_count = 0\n",
    "for sourcefile in myFastqFilenames:\n",
    "    fastaname = re.split('_', os.path.basename(sourcefile))\n",
    "    if fastaname[0] not in total_samples:\n",
    "        total_samples.append(fastaname[0])\n",
    "        total_sample_count = total_sample_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics\n",
    "sample_checklist = []\n",
    "genotype_checklist = []\n",
    "for i in imputedgenotypes_dataframe['sample'].tolist():\n",
    "    if i not in sample_checklist:\n",
    "        sample_checklist.append(i)\n",
    "        genotype_checklist.append(set(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['inferred_genotype']))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: Genotype counts\n",
    "diploid = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) or re.search('heterozygous', str(i)):\n",
    "        diploid = diploid+1\n",
    "        \n",
    "multiploid = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('multizygous', str(i)):\n",
    "        multiploid = multiploid+1\n",
    "\n",
    "unclear = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('unclear', str(i)):\n",
    "        unclear = unclear+1\n",
    "        \n",
    "homo_wt = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and re.search('wild-type', str(i)):\n",
    "        homo_wt = homo_wt+1\n",
    "        \n",
    "homo_mutant = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and not re.search('wild-type', str(i)):\n",
    "        homo_mutant = homo_mutant+1\n",
    "        \n",
    "homo_deletion = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and re.search('deletion', str(i)):\n",
    "        homo_deletion = homo_deletion+1\n",
    "        \n",
    "homo_insertion = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and re.search('insertion', str(i)):\n",
    "        homo_insertion = homo_insertion+1\n",
    "        \n",
    "homo_substitution = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and re.search('substitution', str(i)):\n",
    "        homo_substitution = homo_substitution+1\n",
    "        \n",
    "homo_indel = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and re.search('indel', str(i)):\n",
    "        homo_indel = homo_indel+1\n",
    "        \n",
    "hetero_wt = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('wild-type', str(i)):\n",
    "        hetero_wt  = hetero_wt+1\n",
    "        \n",
    "hetero_wt_deletion = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('wild-type', str(i)) and re.search('deletion', str(i)):\n",
    "        hetero_wt_deletion  = hetero_wt_deletion+1\n",
    "        \n",
    "hetero_wt_insertion = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('wild-type', str(i)) and re.search('insertion', str(i)):\n",
    "        hetero_wt_insertion = hetero_wt_insertion+1\n",
    "        \n",
    "hetero_wt_substitution = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('wild-type', str(i)) and re.search('substitution', str(i)):\n",
    "        hetero_wt_substitution = hetero_wt_substitution+1\n",
    "        \n",
    "hetero_wt_indel = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('wild-type', str(i)) and re.search('indel', str(i)):\n",
    "        hetero_wt_indel = hetero_wt_indel+1\n",
    "        \n",
    "hetero_mutant_mutant = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and not re.search('wild-type', str(i)):\n",
    "        hetero_mutant_mutant = hetero_mutant_mutant+1\n",
    "        \n",
    "hetero_deletion_insertion = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('deletion', str(i)) and re.search('insertion', str(i)):\n",
    "        hetero_deletion_insertion = hetero_deletion_insertion+1\n",
    "        \n",
    "hetero_deletion_substitution = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('deletion', str(i)) and re.search('substitution', str(i)):\n",
    "        hetero_deletion_substitution = hetero_deletion_substitution+1\n",
    "\n",
    "hetero_insertion_substitution = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('insertion', str(i)) and re.search('substitution', str(i)):\n",
    "        hetero_insertion_substitution = hetero_insertion_substitution+1\n",
    "        \n",
    "hetero_deletion_indel = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('deletion', str(i)) and re.search('indel', str(i)):\n",
    "        hetero_deletion_indel = hetero_deletion_indel+1\n",
    "        \n",
    "hetero_insertion_indel = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('insertion', str(i)) and re.search('indel', str(i)):\n",
    "        hetero_insertion_indel = hetero_insertion_indel+1\n",
    "        \n",
    "hetero_substitution_indel = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('substitution', str(i)) and re.search('indel', str(i)):\n",
    "        hetero_substitution_indel = hetero_substitution_indel+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: Allele counts\n",
    "sample_checklist = []\n",
    "allele_type_checklist = []\n",
    "for i in imputedgenotypes_dataframe['sample'].tolist():\n",
    "    sample_alleles = []\n",
    "    if i not in sample_checklist:\n",
    "        sample_checklist.append(i)\n",
    "        R1R2_check = []\n",
    "        for x in range(0, len(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'])):\n",
    "            if imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'].iloc[x] == 'None':\n",
    "                pass\n",
    "            elif float(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'].iloc[x]) > 10:\n",
    "                if imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['read'].iloc[x] == 'R1+R2':\n",
    "                    R1R2_check.append('R1+R2/'+imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_type'].iloc[x])\n",
    "                    sample_alleles.append(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_type'].iloc[x])\n",
    "        if len(sample_alleles) != 0:\n",
    "            allele_type_checklist.append(sample_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: Compile counts of total defined alleles, wild-type alleles, and mutant alleles \n",
    "wt_alleles = 0\n",
    "mutant_alleles = 0\n",
    "\n",
    "for i in allele_type_checklist:\n",
    "    if len(i) == 1:\n",
    "        if re.search('wild-type', str(i)):\n",
    "            wt_alleles = wt_alleles+2\n",
    "        if re.search('mutant', str(i)):\n",
    "            mutant_alleles = mutant_alleles+2\n",
    "    elif len(i) == 2:\n",
    "        if re.search('wild-type', str(i)):\n",
    "            wt_alleles = wt_alleles+1\n",
    "        if re.findall('mutant', str(i)):\n",
    "            mutant_alleles = mutant_alleles+len(re.findall('mutant', str(i)))\n",
    "    elif len(i) == 3:\n",
    "        if re.search('wild-type', str(i)):\n",
    "            wt_alleles = wt_alleles+1\n",
    "        if re.findall('mutant', str(i)):\n",
    "            mutant_alleles = mutant_alleles+len(re.findall('mutant', str(i)))\n",
    "\n",
    "total_alleles = wt_alleles+mutant_alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics\n",
    "sample_checklist = []\n",
    "allele_specs_checklist = []\n",
    "for i in imputedgenotypes_dataframe['sample'].tolist():\n",
    "    sample_alleles = []\n",
    "    if i not in sample_checklist:\n",
    "        sample_checklist.append(i)\n",
    "        R1R2_check = []\n",
    "        for x in range(0, len(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'])):\n",
    "            if imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'].iloc[x] == 'None':\n",
    "                pass\n",
    "            elif imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_specs'].iloc[x] is None:\n",
    "                if 'wild-type' not in sample_alleles:\n",
    "                    sample_alleles.append('wild-type')\n",
    "            elif float(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'].iloc[x]) > 10:\n",
    "                if imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['read'].iloc[x] == 'R1+R2':\n",
    "                    if 'R1+R2/'+imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_specs'].iloc[x] not in R1R2_check:\n",
    "                        R1R2_check.append('R1+R2/'+imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_specs'].iloc[x])\n",
    "                        sample_alleles.append(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_specs'].iloc[x])\n",
    "                elif imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['read'].iloc[x] == 'R1+R2':\n",
    "                    if 'R1+R2'+imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_specs'].iloc[x] in R1R2_check:\n",
    "                        pass\n",
    "        if len(sample_alleles) != 0:\n",
    "            allele_specs_checklist.append(sample_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: Compile counts of total deletion, insertion, substitution and indel alleles\n",
    "deletion_alleles = 0\n",
    "insertion_alleles = 0\n",
    "substitution_alleles = 0\n",
    "indel_alleles = 0\n",
    "\n",
    "for i in allele_specs_checklist:\n",
    "    if len(i) == 1:\n",
    "        if re.search('deletion', str(i)):\n",
    "            deletion_alleles = deletion_alleles+2\n",
    "        elif re.search('insertion', str(i)):\n",
    "            insertion_alleles = insertion_alleles+2\n",
    "        elif re.search('substitution', str(i)):\n",
    "            substitution_alleles = substitution_alleles+2\n",
    "        elif re.search('indel', str(i)):\n",
    "            indel_alleles = indel_alleles+2\n",
    "    elif len(i) == 2:\n",
    "        if re.findall('deletion', str(i)):\n",
    "            deletion_alleles = deletion_alleles+len(re.findall('deletion', str(i)))\n",
    "        if re.findall('insertion', str(i)):\n",
    "            insertion_alleles = insertion_alleles+len(re.findall('insertion', str(i)))\n",
    "        if re.findall('substitution', str(i)):\n",
    "            substitution_alleles = substitution_alleles+len(re.findall('substitution', str(i)))\n",
    "        if re.findall('indel', str(i)):\n",
    "            indel_alleles = indel_alleles+len(re.findall('indel', str(i)))\n",
    "    elif len(i) == 3:\n",
    "        if re.findall('deletion', str(i)):\n",
    "            deletion_alleles = deletion_alleles+len(re.findall('deletion', str(i)))\n",
    "        if re.findall('insertion', str(i)):\n",
    "            insertion_alleles = insertion_alleles+len(re.findall('insertion', str(i)))\n",
    "        if re.findall('substitution', str(i)):\n",
    "            substitution_alleles = substitution_alleles+len(re.findall('substitution', str(i)))\n",
    "        if re.findall('indel', str(i)):\n",
    "            indel_alleles = indel_alleles+len(re.findall('indel', str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: Compile list of sampleIDs for which there were no alignment hits for any of the top 10 reads\n",
    "no_hits_and_hits_samplename_list = []\n",
    "no_hits_for_any_top10_reads_samplename_list = []\n",
    "for i in no_hits_samplename_list:\n",
    "    if i in querydef_uniq_list:\n",
    "        no_hits_and_hits_samplename_list.append(i)\n",
    "    else:\n",
    "        no_hits_for_any_top10_reads_samplename_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare population_summary.txt file\n",
    "with open(str(population_summary_output), 'a+') as file:\n",
    "    file.write('Genotypes.py: Population Summary\\nDate: ' + (datetime.today().strftime(\"%m/%d/%Y\")) +\n",
    "\"\"\"\\n\\nI. Synopsis of Interpretations: Allele Definitions & Genotype Extrapolations\n",
    "\n",
    "    (A) Sample summary\n",
    "        (i) Number of samples processed: \"\"\" + str(total_sample_count) +\n",
    "'\\n        (ii) % samples called (genotype inferred): ' + str(len(sample_checklist)) + ' (' + str(round((100*(len(sample_checklist)/total_sample_count)),2))+'%)' +\n",
    "\"\"\"\\n\\n    (B) Genotypes summary\n",
    "        (i) % samples diploid (1-2 prominent alleles inferred): \"\"\" + str(diploid) + ' (' + str(round((100*(diploid/total_sample_count)),2))+'%)' +\n",
    "'\\n            (1) % homozygous wild-type (wt): ' + str(homo_wt) + ' (' + str(round((100*(homo_wt/total_sample_count)),2))+'%)' +\n",
    "'\\n            (2) % homozygous mutant: ' + str(homo_mutant) + ' (' + str(round((100*(homo_mutant/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % homozygous deletion: ' + str(homo_deletion) + ' (' + str(round((100*(homo_deletion/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % homozygous insertion: ' + str(homo_insertion) + ' (' + str(round((100*(homo_insertion/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % homozygous substitution: ' + str(homo_substitution) + ' (' + str(round((100*(homo_substitution/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % homozygous complex indel: ' + str(homo_indel) + ' (' + str(round((100*(homo_indel/total_sample_count)),2))+'%)' +\n",
    "'\\n            (3) % heterozygous (wt + mutant): ' + str(hetero_wt) + ' (' + str(round((100*(hetero_wt/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous deletion: ' + str(hetero_wt_deletion) + ' (' + str(round((100*(hetero_wt_deletion/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous insertion: ' + str(hetero_wt_insertion) + ' (' + str(round((100*(hetero_wt_insertion/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous substitution: ' + str(hetero_wt_substitution) + ' (' + str(round((100*(hetero_wt_substitution/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous complex indel: ' + str(hetero_wt_indel) + ' (' + str(round((100*(hetero_wt_indel/total_sample_count)),2))+'%)' +\n",
    "'\\n            (4) % heterozygous (mutant + mutant): ' + str(hetero_mutant_mutant) + ' (' + str(round((100*(hetero_mutant_mutant/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous deletion + insertion: ' + str(hetero_deletion_insertion) + ' (' + str(round((100*(hetero_deletion_insertion/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous deletion + substitution: ' + str(hetero_deletion_substitution) + ' (' + str(round((100*(hetero_deletion_substitution/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous insertion + substitution: ' + str(hetero_insertion_substitution) + ' (' + str(round((100*(hetero_insertion_substitution/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous deletion + complex indel: ' + str(hetero_deletion_indel) + ' (' + str(round((100*(hetero_deletion_indel/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous insertion + complex indel: ' + str(hetero_insertion_indel) + ' (' + str(round((100*(hetero_insertion_indel/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous substitution + complex indel: ' + str(hetero_substitution_indel) + ' (' + str(round((100*(hetero_substitution_indel/total_sample_count)),2))+'%)' +\n",
    "'\\n        (ii) % samples multiploid (>2 prominent alleles inferred): ' + str(multiploid) + ' (' + str(round((100*(multiploid/total_sample_count)),2))+'%)' +\n",
    "\"\"\"\\n\\n    (B) Alleles summary\n",
    "        (i) % wild-type alleles: \"\"\" + str(wt_alleles) + ' (' + str(round((100*(wt_alleles/total_alleles)),2)) + '% of total alleles)' +\n",
    "'\\n        (ii) % mutant alleles: ' + str(mutant_alleles) + ' (' + str(round((100*(mutant_alleles/total_alleles)),2)) + '% of total alleles)' +\n",
    "'\\n            (1) % deletion alleles: ' + str(deletion_alleles) + ' (' + str(round((100*(deletion_alleles/total_alleles)),2)) + '% of total alleles)' +\n",
    "'\\n            (2) % insertion alleles: ' + str(insertion_alleles) + ' (' + str(round((100*(insertion_alleles/total_alleles)),2)) + '% of total alleles)' +\n",
    "'\\n            (3) % substitution alleles: ' + str(substitution_alleles) + ' (' + str(round((100*(substitution_alleles/total_alleles)),2)) + '% of total alleles)' +\n",
    "'\\n            (4) % complex indel alleles: ' + str(indel_alleles) + ' (' + str(round((100*(indel_alleles/total_alleles)),2)) + '% of total alleles)')\n",
    "    file.write(\"\"\"\\n\\nII. Synopsis of Reads Lost to Analysis\n",
    "    Reads among the 'Top 10' reads are deprecated (not analyzed by Genotypes.py) if they fall into the following categories:\n",
    "    (A) no hits, (B) multiple hits, or (C) (if >1 hsp for 1 hit) overlapping hsp's in reference database and/or hsp span (end-to-end) that exceeds 1 kb\n",
    "    \n",
    "    (A) Samples with reads among the 'top 10 most abundant reads', that did not map to the reference genome\n",
    "        (i) For the following sample IDs (\"\"\"+str(len(no_hits_for_any_top10_reads_samplename_list))+\"\"\"), NO reads among the \"top 10 most abundant reads\" could be mapped to the reference genome:\"\"\")\n",
    "    if len(no_hits_for_any_top10_reads_samplename_list) == 0:\n",
    "        file.write('\\n               None')\n",
    "    else:\n",
    "        for i in no_hits_for_any_top10_reads_samplename_list:\n",
    "            file.write('\\n             '+i)\n",
    "    file.write('')\n",
    "    \n",
    "    file.write('\\n        (ii) For the following sample IDs ('+str(len(no_hits_samplename_list))+'), the indicated reads among the \"top 10 most abundant reads\" did not map to the reference genome:')\n",
    "    # Print this output to population summary\n",
    "    if len(no_hits_samplename_list) == 0:\n",
    "        file.write('\\n               None')\n",
    "    else:\n",
    "        for i in no_hits_samplename_list:\n",
    "            file.write('\\n             '+i+':')\n",
    "            for x in no_hits_list:\n",
    "                if i == x.split('_')[0]:\n",
    "                    file.write('\\n               '+x)\n",
    "            file.write('')\n",
    "        \n",
    "    file.write('\\n\\n    (B) Samples with reads among the \"top 10 most abundant reads\", that mapped to multiple loci in the reference genome' +\n",
    "'\\n        (i) For the following sample IDs ('+str(len(multiple_alignments_hits_samplename_list))+'), the indicated reads among the \"top 10 most abundant reads\" mapped to more than one locus in the reference genome:')\n",
    "    if len(multiple_alignments_hits_samplename_list) > 0:\n",
    "        for i in multiple_alignments_hits_samplename_list:\n",
    "            file.write('\\n               '+i.strip()) \n",
    "        file.write('\\n\\n               Details:')\n",
    "        for i in multiple_alignments_hits_dict:\n",
    "            file.write('\\n               '+i+'\\n               '+len(i)*'=')\n",
    "            for x in multiple_alignments_hits_dict.get(i):\n",
    "                chunked_list = []\n",
    "                subchunk = 0\n",
    "                for index, y in enumerate(x):   \n",
    "                    if y.split('>')[0] == '<Hit_num':\n",
    "                        chunked_list.append(x[subchunk:index])\n",
    "                        subchunk = index\n",
    "                    if index == len(x)-1:\n",
    "                        chunked_list.append(x[subchunk:])\n",
    "                file.write('\\n               Read: '+chunked_list[0][1].split('>')[1].split('<')[0])\n",
    "                for hit in chunked_list[1:]:\n",
    "                    file.write('\\n               Hit '+hit[0].split('>')[1].split('<')[0]+': '+hit[2].split('>')[1].split('<')[0]+': '+hit[1].split('>')[1].split('<')[0]+', '+hit[5].split('>')[1].split('<')[0]+'-'+hit[6].split('>')[1].split('<')[0])\n",
    "                    file.write('\\n                   '+hit[7].split('>')[1].split('<')[0])\n",
    "                    file.write('\\n                   '+hit[9].split('>')[1].split('<')[0])\n",
    "                    file.write('\\n                   '+hit[8].split('>')[1].split('<')[0])\n",
    "                file.write('\\n')\n",
    "            file.write('\\n')\n",
    "    else:\n",
    "        file.write('\\n               None')\n",
    "    file.write(\"\"\"\\n\\n    (C) Samples with reads among the 'top 10 most abundant reads', with high-scoring pairs (hsp's) that were attempted \n",
    "        for reconstruction with BLASTDBCMD sequence retrieval across hsp span, but deprecated because the hsp's\n",
    "        a) overlapped in the reference genome (potential artefact or signature of inversion, duplication and/or\n",
    "        b) exceeded 1 kb span (end-to-end)\n",
    "        Consult fasta.fa and/or BLASTN output if any of these reads is of further interest to examine manually:\\n\"\"\")\n",
    "    file.write(\"\\n        (i) For the following sample IDs (\"+str(len(multiple_alignments_hsp_samplename_list))+\"), the indicated reads among the 'top 10 most abundant reads' exhibited overlapping hsp's aligned to the reference genome:\")\n",
    "    if len(multiple_alignments_hsp_invalid2_list) > 0:\n",
    "        for i in multiple_alignments_hsp_invalid2_list:\n",
    "            file.write('\\n               '+i.strip())\n",
    "        file.write('\\n\\n               Details:')   \n",
    "        for i in multiple_alignments_hsp_dict_invalid2:\n",
    "            file.write('\\n               '+i+'\\n               '+len(i)*'=')\n",
    "            for x in multiple_alignments_hsp_dict_invalid2.get(i):\n",
    "                chunked_list = []\n",
    "                subchunk = 0\n",
    "                for index, y in enumerate(x):\n",
    "                    if y.split('>')[0] == '<Hsp_num':\n",
    "                        chunked_list.append(x[subchunk:index])\n",
    "                        subchunk = index\n",
    "                    if index == len(x)-1:\n",
    "                        chunked_list.append(x[subchunk:])\n",
    "                file.write('\\n               Read: '+chunked_list[0][1].split('>')[1].split('<')[0])\n",
    "                file.write('\\n               Hit: '+chunked_list[0][4].split('>')[1].split('<')[0]+': '+chunked_list[0][3].split('>')[1].split('<')[0])\n",
    "                for hsp in chunked_list[1:]:\n",
    "                    file.write('\\n               Hsp '+hsp[0].split('>')[1].split('<')[0]+': '+hsp[1].split('>')[1].split('<')[0]+'-'+hsp[2].split('>')[1].split('<')[0])\n",
    "                    file.write('\\n                   '+hsp[3].split('>')[1].split('<')[0])\n",
    "                    file.write('\\n                   '+hsp[5].split('>')[1].split('<')[0])\n",
    "                    file.write('\\n                   '+hsp[4].split('>')[1].split('<')[0])\n",
    "                file.write('\\n')\n",
    "            file.write('\\n')\n",
    "    else:\n",
    "        file.write('\\n               None')\n",
    "                \n",
    "# Log file processing time duration                \n",
    "fileprocessingDuration = str(datetime.now()- startTime_fileprocessing).split(':')[0]+' hr|'+str(datetime.now() - startTime_fileprocessing).split(':')[1]+' min|'+str(datetime.now() - startTime_fileprocessing).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_fileprocessing).split(':')[2].split('.')[1]+' microsec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### VII. Compile visualization of evidence supporting inferred genotypes (optional)\n",
    "This script extrapolated genotypes based on allele definitions (*e.g.* wild-type or mutant relative alignment reference) and the relative frequencies of defined alleles. **If you chose to include frequency plots as a file output (at script outset), supporting evidence for inferred genotypes will now be reported in the form of plots that visualize read frequency metrics for each sample**. For the top 10 ranked reads (ten 'allele ranks'), frequency is plotted at four levels:\n",
    " - raw frequency (# reads/total reads)\n",
    " - frequency adjusted for top 10 most abundant reads (# reads/total reads among top 10 reads)\n",
    " - frequency adjusted for reads that occur at >1% raw frequency (# reads/total reads among reads that occur at >1% raw frequency)\n",
    " - frequency adjusted for reads that occur at >10% raw frequency (# reads/total reads among reads that occur at >10% raw frequency).  \n",
    " \n",
    "In many cases, relative abundance of a robust candidate allele increases as low-frequency reads (attributable to PCR artefacts) are filtered out.\n",
    "\n",
    "Frequency plots are recorded in a PDF output file, **allele_evidence.pdf**. If you chose not to include frequency plots as a file output at script onset, allele_evidence.pdf will not appear in the final file output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if frequency_plot_check == 'Y':\n",
    "    frequency_plots()\n",
    "elif frequency_plot_check == 'N':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Log script processing time duration \n",
    "processingDuration = str(datetime.now()- startTime).split(':')[0]+' hr|'+str(datetime.now() - startTime).split(':')[1]+' min|'+str(datetime.now() - startTime).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime).split(':')[2].split('.')[1]+' microsec'\n",
    "\n",
    "# Log script end time\n",
    "endTime = datetime.now()\n",
    "endTimestr = str(endTime).split(' ')[1].split('.')[0]     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### VIII. Prepare final report of file size metrics and time durations to **script_metrics.txt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Script has completed.  Please find output files at /Users/kirkehmsen/Documents/GenotypesOutputGit2\n"
     ]
    }
   ],
   "source": [
    "# Assess output file set created by script\n",
    "file_set = [file for file in os.listdir(output_directory) if Path(file).suffix in ('.pdf','.txt','.fa')]\n",
    "\n",
    "# Log further script operation metrics to script_metrics.txt\n",
    "filename = Path(str(output_path)+ '/'+processdate+'_script_metrics.txt')\n",
    "\n",
    "if frequency_plot_check == 'Y':\n",
    "    with open(filename, 'a') as f:\n",
    "        print(\"\"\"\\nFile output information:\n",
    "    Output directory: \"\"\" + str(output_directory) +\n",
    "'\\n    Total file #: ' + str(len(file_set)) +\n",
    "'\\n    Total file output sizes: ', file = f)\n",
    "        for file in file_set:\n",
    "            print('        '+file+': '+path_size(str(output_directory)+'/'+file), file = f)\n",
    "        print(\"\"\"\\nScript operation times:\n",
    "    start time: \"\"\"+startTimestr+\n",
    "    '\\n    fasta processing time: '+readcountDuration+\n",
    "    '\\n    alignments processing time: '+alignmentsDuration+\n",
    "    '\\n    genotype inference processing time: '+imputationDuration+\n",
    "    '\\n    frequency plots compilation time: '+frequencyplotsDuration+\n",
    "    '\\n    accessory file processing time: '+fileprocessingDuration+\n",
    "    '\\n    total processing time: '+processingDuration+\n",
    "    '\\n    end time: ' + endTimestr, file = f)\n",
    "    f.close()\n",
    "elif frequency_plot_check == 'N':\n",
    "    with open(filename, 'a') as f:\n",
    "        print(\"\"\"\\nFile output information:\n",
    "    Output directory: \"\"\" + str(output_directory) +\n",
    "'\\n    Total file #: ' + str(len(file_set)) +\n",
    "'\\n    Total file output sizes: ', file = f)\n",
    "        for file in file_set:\n",
    "            print('        '+file+': '+path_size(str(output_directory)+'/'+file), file = f)\n",
    "        print(\"\"\"\\nScript operation times:\n",
    "    start time: \"\"\"+startTimestr+\n",
    "    '\\n    fasta processing time: '+readcountDuration+\n",
    "    '\\n    alignments processing time: '+alignmentsDuration+\n",
    "    '\\n    genotype inference processing time: '+imputationDuration+\n",
    "    '\\n    accessory file processing time: '+fileprocessingDuration+\n",
    "    '\\n    total processing time: '+processingDuration+\n",
    "    '\\n    end time: ' + endTimestr, file = f)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "# End of script operations\n",
    "print(\"\"\"\n",
    "Script has completed.  Please find output files at \"\"\"+str(output_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "############################################################################# end"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
