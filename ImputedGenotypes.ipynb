{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## ImputedGenotypes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/YamamotoLabUCSF/ImputedGenotypes  \n",
    "v1.0/Committed 8-02-2019\n",
    "\n",
    "<img src=\"ImputedGenotypes_img/NGS_overview.png\" align=\"left\" width=\"540\">\n",
    "\n",
    "### Background: \n",
    "Genetic variation is foundational in biology. Identification of alleles, allele frequencies, and rare variants in populations is central to many biological questions. Massively parallel DNA sequencing has made it increasingly feasible to collect DNA sequence information at specific genomic positions (loci) for 100s-1000s of individual cells or organisms (*samples*) within a population.  \n",
    "\n",
    "**This script automates sample-specific genotype imputation at target loci**, expediting (1) analysis of genetic variation in a sample population, and (2) identification of individual (potentially rare) samples bearing specific alleles and genotypic properties.\n",
    " \n",
    "**Figure**. *Briefly, sample-specific target loci can be PCR-amplified in arrayed format, with sample identity defined by short DNA indices appended as 'barcodes'. After pooling and sequencing by synthesis (SBS), reads are assigned to source samples (demultiplexed) and stored in sample-specific fastq files. **Using fastq files as input, this script identifies probable alleles in each sample, and based on their frequencies, imputes genotype at the locus in question.** The script reports overall allele frequencies across the sampled population, and enables identification of specific sample(s) that harbor potentially rare genetic variants.*\n",
    "\n",
    "### Potential uses:\n",
    "This script was developed to enable rapid identification of mutant clones following Cas9-editing (CRISPR-Cas9 mutagenesis) and clonal isolation. This script should be useful for additional applications needing rapid imputation of sample-specific genotypes at specific loci recovered by PCR (*e.g.*, from individual organisms or from clonally isolated cell populations), as well as applications that involve summation of population genetic diversity. \n",
    "\n",
    "### Synopsis:\n",
    "**This script returns allele definitions (and imputed genotypes) for samples from a demultiplexed NGS fastq dataset** \n",
    ">(see 'Output notes' for file output\n",
    "details).  \n",
    "\n",
    "**Users are asked for paths to specific directories (*e.g.*, output and input directories, BLASTN reference sequence database), a locally installed BLASTN (NCBI) executable, and (optional) DNA sub-sequences to map onto alignments**  \n",
    ">(see 'Input notes' for details).\n",
    "    \n",
    "Python3 and BLASTN (NCBI) are required for operation.  \n",
    "BLASTN can be downloaded and locally installed at <https://www.ncbi.nlm.nih.gov/guide/howto/run-blast-local/>.  \n",
    "\n",
    "A sequence reference database is required for BLASTN alignment operations, and can be obtained in one of two ways:\n",
    "- create custom database from a fasta file containing reference sequence(s) using MAKEBLASTDB (NCBI)  \n",
    "(details at <https://www.ncbi.nlm.nih.gov/books/NBK279688/>)\n",
    "- download pre-formatted NCBI BLAST database (details at <https://www.ncbi.nlm.nih.gov/books/NBK537770/>)\n",
    "    \n",
    "For usage details, please refer to README file at GitHub and to the following manuscript:  \n",
    ">*Ehmsen, Knuesel, Martinez, Asahina, Aridomi, Yamamoto (2019)*\n",
    "    \n",
    "Please cite usage as:  \n",
    ">ImputedGenotypes.py  \n",
    ">*Ehmsen, Knuesel, Martinez, Asahina, Aridomi, Yamamoto (2019)*\n",
    " \n",
    "--------\n",
    "\n",
    "<img src=\"ImputedGenotypes_img/ImputedGenotypes_thumbnail_sketch-01.png\" align=\"right\" width=\"650\">\n",
    "\n",
    "### Operation notes:\n",
    "*What does this script do?*\n",
    " 1. **classify & count reads:** counts unique read types per well (*i.e.*, sample); fastq file name provides the sample name  \n",
    " \n",
    " \n",
    " 2. **identify top 10 reads** per well (in terms of read abundance); calculates representation among reads within the well at four levels:\n",
    " \n",
    "   (a) raw frequency (% read type in question, relative to total reads)  \n",
    "   (b) percentile (% of other read types that fall below the frequency of the read type in question)  \n",
    "   (c) adjusted frequency @ 1% (% read type in question, relative to reads that occur at >1% frequency)  \n",
    "   (d) adjusted frequency @ 10% (% read type in question, relative to reads that occur at >10% frequency)    \n",
    "   \n",
    "   \n",
    " 3. **align to reference database:** aligns top 10 reads to reference genome using BLASTN  \n",
    " *(National Center for Biotechnology Information;\n",
    "    Altschul S.F. et al. (1990) \"Basic local alignment search tool\")*    \n",
    "    \n",
    "    \n",
    " 4. **return alignments as alleles & imputed genotypes;**  \n",
    " **(optional) map sub-sequence(s) onto alleles:**  \n",
    "    -  for mutants, the alignment shows location of Cas9 cut(s) and indel(s) relative to wt,\n",
    "       if Cas9 guide sequence(s) supplied by user  \n",
    "    -  also indicates location of test sub-sequence(s) and whether sub-sequence is altered (ablated),\n",
    "       if test sub-sequence(s) supplied by user  \n",
    "       \n",
    "       \n",
    " 5. **provide overall population statistics:**  \n",
    " \n",
    "   (a) total sample # for which genotypes were imputed  \n",
    "   (b) distribution of genotypes among samples (homozygous, heterozygous, etc.)  \n",
    "   (c) estimated wild-type *vs.* mutant allele frequencies  \n",
    "   (d) summary of samples and reads that either had 'no hit' in reference database provided to BLASTN,\n",
    "       or multiple hits (>1)  \n",
    "       \n",
    "--------\n",
    "### Input notes:\n",
    "You will be prompted for the following user-specific information (10 items):\n",
    "\n",
    "   **Required** (4 strings specifying directory or executable locations, 1 string specifying sequence database file prefix): \n",
    "      <ul>\n",
    "      <li>where should output files go?</li>\n",
    "          *path to* **output directory** *for output files*\n",
    "      <li>where are input files found?</li>\n",
    "          *path to single directory containing* **demultiplexed fastq files**                                         \n",
    "      <li>where is BLASTN executable found?</li>\n",
    "          *path to* **BLASTN** *installation*\n",
    "      <li>where is the reference sequence database used for alignment?</li>\n",
    "          *path to directory containing six files that compose the* **reference sequence database** *used\n",
    "    for BLASTN alignments (.nhr, .nin, .nog, .nsd, .nsi, .nsg)*\n",
    "      <li>what prefix is common to the six files that compose the reference sequence database?</li>\n",
    "          *prefix common to database files .nhr, .nin, .nog, .nsd, .nsi, .nsg*\n",
    "      </ul>\n",
    "                                                                                                           \n",
    "   **Optional** (up to 2 lines of comma-separated strings specifying DNA sub-sequence(s):    \n",
    " **DNA sub-sequence(s)** to be mapped onto sequence alignments\n",
    "      <ul>\n",
    "      <li>**guide RNA sequence** (in 5'-3' DNA representation, excluding PAM sequence)</li>\n",
    "      <li>**test sequence** (5'-3' sub-sequence motif(s) of interest, to query whether lost or gained in allele(s))</li>\n",
    "      </ul>\n",
    "      \n",
    "--------\n",
    "### Output notes:\n",
    "This script produces 8 output files in the user-specified output directory.  \n",
    "These include:  \n",
    "\t 1. fasta.fa  \n",
    "        (collection of fasta entries representing top 10 most abundant sequences assigned to a single sample ID)\n",
    "        \n",
    "\t 2. blastn_alignments.txt  \n",
    "        (output of blastn operation on fasta.fa)\n",
    "     \n",
    "     3. allele_definitions.txt\n",
    "        (output of script operation on blastn_alignments.txt, samples returned in order of processing)  \n",
    "        \n",
    "     4. allele_evidence.pdf  \n",
    "        (output of script operation on blastn_alignments.txt, plots of calculated read/allele frequencies)  \n",
    "        \n",
    "     5. imputed_genotypes.txt  \n",
    "        (output of script operation on blastn_alignments.txt, samples returned in ranked order based on  \n",
    "        genotype imputation)  \n",
    "        \n",
    "     6. allele_definitions.csv  \n",
    "        (tabular representation of allele data for all samples)  \n",
    "         \n",
    "\t 7. population_summary.txt  \n",
    "        (output of script operation on imputed_genotypes.txt)  \n",
    "        \n",
    "     8. script_metrics.txt  \n",
    "        (summary/analysis of script operation metrics [metadata])  \n",
    "\n",
    "           Directory structure under an output directory specified as 'ImputedGenotypes', for example,  \n",
    "           would contain the following files after ImputedGenotypes.py operations:  \n",
    "\n",
    "           /ImputedGenotypes  \n",
    "                          `-----allele_definitions.csv  \n",
    "                          `-----allele_definitions.txt  \n",
    "                          `-----allele_evidence.pdf  \n",
    "                          `-----blastn_alignments.txt  \n",
    "                          `-----fasta.fa  \n",
    "                          `-----imputed_genotypes.txt  \n",
    "                          `-----population_summary.txt  \n",
    "                          `-----script_metrics.txt\n",
    "--------\n",
    "### Visual summary of key script operations:\n",
    "In short, sequencing data in a sample-specific **fastq file** (*e.g.,* below), are converted to user-interpretable  genotype imputations (**key output files**, below), for 100s to 1000s of samples.  \n",
    "<img src=\"ImputedGenotypes_img/fastq_example.png\" align=\"left\" width=\"700\">\n",
    "<br clear=\"all\" />\n",
    "#### Key output files:  \n",
    "##### allele_definitions.txt \n",
    "Samples are reported with sequence alignments to document alleles, along with imputed genotypes. \n",
    "<img src=\"ImputedGenotypes_img/imputed_genotype_example.png\" align=\"left\" width=\"800\">\n",
    "<br clear=\"all\" />\n",
    "##### allele_evidence.pdf\n",
    "Samples are reported with frequency plots as evidence.\n",
    "<img src=\"ImputedGenotypes_img/frequency_plots_example.png\" align=\"left\" width=\"700\">  \n",
    "<br clear=\"all\" />\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "**Welcome.**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### I. Setup  \n",
    "Import libraries, modules  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating system interfaces\n",
    "import os\n",
    "\n",
    "# Time access and conversions, Basic data and time types\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# System-specific parameters and functions\n",
    "import sys\n",
    "\n",
    "# Process and system utilities\n",
    "import psutil\n",
    "from psutil import virtual_memory\n",
    "\n",
    "# Low-level networking interface\n",
    "import socket\n",
    "\n",
    "# System version information\n",
    "import platform\n",
    "\n",
    "# Unix-style pathname pattern expansion\n",
    "import glob\n",
    "\n",
    "# Object-oriented filesystem paths\n",
    "from pathlib import Path\n",
    "\n",
    "# NumPy (numeric operations)\n",
    "import numpy\n",
    "\n",
    "# SciPy (for percentile) \n",
    "from scipy import stats\n",
    "\n",
    "# Container datatypes (for Counter operation)\n",
    "from collections import Counter\n",
    "\n",
    "# Decimal fixed point and floating point arithmetic\n",
    "from decimal import Decimal\n",
    "\n",
    "# Internationalization services (for use of thousands separator in numbers where appropriate)\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "\n",
    "# Regular expression operations\n",
    "import re\n",
    "\n",
    "# Python plotting\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Python PDF tools\n",
    "from fpdf import FPDF\n",
    "from PyPDF2 import PdfFileMerger, PdfFileReader\n",
    "\n",
    "# Python panel data frames\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Log start time\n",
    "initialTime = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Define functions     \n",
    "*User inputs can be entered either in rapid succession ('List' format), or in response to individually coached prompts. 'Prompts' defines a series of 6 coached entries that provide a user with instructive detail regarding the nature of required input.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'prompts' function for coached user input\n",
    "def prompts():\n",
    "    \"\"\"Coached prompts to collect user input\"\"\"\n",
    "    # Make variables assigned in prompts() function globally available\n",
    "    global output_directory\n",
    "    global fastq_directory\n",
    "    global blastn_path\n",
    "    global db_path\n",
    "    global db_prefix\n",
    "    global test_seq\n",
    "    global guideRNA_seq\n",
    "    global extant_seq\n",
    "    global test_seq\n",
    "    # 1-Specify output directory.\n",
    "    print(r\"\"\"\n",
    "---------------------------------------------\n",
    "Location of OUTPUT DIRECTORY for output files\n",
    "---------------------------------------------\n",
    "    \n",
    "The script generates 8 separate files, all in the directory you indicate here.  It is important that this directory\n",
    "either not exist prior to running the script, or if it does exist, it must be *empty* of any files with the names\n",
    "to be created below.  These files are:\n",
    "    \n",
    "    1. fasta.fa\n",
    "\n",
    "    2. blastn_alignments.txt\n",
    "        (output of blastn operation on fasta.fa)\n",
    "\n",
    "    3. allele_definitions.txt\n",
    "        (output of script operation on blastn_alignments.txt, samples returned in order of processing)\n",
    "                  \n",
    "    4. allele_evidence.pdf \n",
    "        (optional; output of script operation on blastn_alignments.txt, plot of calculated read/allele frequencies)\n",
    "\n",
    "    5. imputed_genotypes.txt\n",
    "        (output of script operation on blastn_alignments.txt, samples returned in order of genotype imputation)\n",
    "\n",
    "    6. population_summary.txt\n",
    "        (output of script operation on imputed_genotypes.txt)\n",
    "                  \n",
    "    7. allele_definitions.csv\n",
    "        (allele metrics (frequency representations) and definitions for each sample, in spreadsheet format)\n",
    "                  \n",
    "    8. script_metrics.txt \n",
    "        (summary/analysis of script operation metrics)\n",
    "            \n",
    "        Notes: \n",
    "        * These files do not exist before the script is run. The files are made by the script.\n",
    "        * The primary data outputs for genotypes are found in:\n",
    "            allele_definitions.txt, allele_evidence.pdf, imputed_genotypes.txt & population_summary.txt\n",
    "        \n",
    "        \n",
    "At this prompt, indicate an absolute path to a ** directory ** that will be created by the script as the location\n",
    "for output files.  This directory should not exist yet -- it will be created as an output of this script, and will\n",
    "be populated with the file outputs of this specific instance of the script operation.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators, regardless of operating system (Mac or Windows).\n",
    "\n",
    "Example: if you'd like to create a directory ('ImputedGenotypes') in an existing directory ('Illumina'), accessed\n",
    "with absolute path of '/Users/myname/Illumina/ImputedGenotypes' (Mac) or 'C:\\Users\\myname\\Illumina\\ImputedGenotypes'\n",
    "(Windows), enter '/Users/myname/Illumina/ImputedGenotypes' at the command line prompt. Replace 'myname' with the\n",
    "appropriate intervening directory identifiers. Do *not* flank your entry with quotation marks (') at the command\n",
    "line.\n",
    "    \n",
    "Alternatively, simply enter a desired directory name (e.g., 'ImputedGenotypes') and run this script from\n",
    "within a directory where you'd like to create this new directory.\"\"\"+'\\n')\n",
    "    output_directory = input(r\"\"\"    -----> Output directory name and path:  \"\"\")\n",
    "    # 2-Specify the fastq files to be used for input, by indicating directory location of the file list.\n",
    "    print(r\"\"\"\n",
    "------------------------------------------------------------------------------\n",
    "Location of INPUT FILES (single directory containing demutiplexed fastq files)\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "You will now be asked to enter the path to the directory containing the fastq files\n",
    "to be processed as ImputedGenotypes.py input.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "\n",
    "Example: if your fastq input files are named file1.fastq, file2.fastq, etc. and are found in a directory\n",
    "named 'Sequences' with absolute path of '/Users/myname/Sequences' (Mac) or 'C:\\Users\\myname\\Sequences' (PC),\n",
    "enter '/Users/myname/Sequences' at the command line prompt.\n",
    "\n",
    "When you're done entering the fastq file location, press 'Enter' again to proceed in the script.\"\"\"+'\\n')\n",
    "    fastq_directory = input(r\"\"\"    -----> Directory name and path:  \"\"\")\n",
    "    # 3-Collect path to blastn executable.\n",
    "    print(\"\"\"\n",
    "-----------------------------\n",
    "Location of BLASTN EXECUTABLE\n",
    "-----------------------------\n",
    "\n",
    "This script uses BLASTN (NCBI) to align reads from your fastq files to a reference sequence database\n",
    "(such as a genome database or sequence database).\n",
    "Please indicate the absolute path to the BLASTN executable.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "    \n",
    "Example: if your BLASTN executable is found at absolute path /Users/myname/blastn, type '/Users/myname/blastn'\n",
    "and press Enter.\"\"\"+'\\n')\n",
    "    blastn_path = input(r\"\"\"    -----> Path to BLASTN executable:  \"\"\")\n",
    "    # 4-Collect location of blastn database directory.\n",
    "    print(\"\"\"\n",
    "-----------------------------------------------\n",
    "Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
    "-----------------------------------------------\n",
    "\n",
    "Because this script uses BLASTN (NCBI) to align reads from your fastq files a reference sequence database,\n",
    "an alignment reference database is needed. This reference database consists of a single directory containing\n",
    "six files (.nhr, .nin, .nog, .nsd, .nsi, .nsg) (generated by the program MAKEBLASTDB (NCBI) from a file\n",
    "containing sequences in fasta format, or downloaded from NCBI as an existing database).\n",
    "    \n",
    "Please indicate the absolute path to the directory you are using as your reference sequence database.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "    \n",
    "Example: if your reference sequence database is found at absolute path /Users/myname/database, type\n",
    "'/Users/myname/database' and press Enter.\"\"\"+'\\n')\n",
    "    db_path = input(r\"\"\"    -----> Path to BLASTN alignment reference sequence database:  \"\"\")\n",
    "    # 5-Collect prefix of blastn database files.\n",
    "    print(\"\"\"\n",
    "------------------------------------------------\n",
    "PREFIX common to BLASTN ALIGNMENT DATABASE FILES\n",
    "------------------------------------------------\n",
    "\n",
    "A BLASTN reference sequence database consists of six files in a single directory, with each of the six\n",
    "files sharing a common prefix (usually determined by the name of the fasta file provided to MAKEBLASTDB\n",
    "during database generation).\n",
    "    \n",
    "Please indicate the common prefix for files of the reference sequence database.\"\"\"+'\\n')\n",
    "    db_prefix = input(r\"\"\"    -----> Prefix for alignment reference sequence database files:  \"\"\")\n",
    "    # 6-Specify whether to include sequence(s) of interest to query in alignment outputs.\n",
    "    print(\"\"\"      \n",
    "-----------------------------------------------------------------\n",
    "Optional: Nucleotide sequence(s) to identify in output alignments\n",
    "-----------------------------------------------------------------\n",
    "    \n",
    "Some applications of 'allele definition' and 'genotype imputation' may call for identification of the presence\n",
    "or absence of a specific anticipated sub-sequence (few nucleotides), and/or for the mapping of the location of\n",
    "a sub-sequence if present in the sequence alignment.\n",
    "    \n",
    "ImputedGenotypes.py allows for the optional testing of sub-sequences.\n",
    "    \n",
    "If you would like to specify subsequences, type 'Yes' and press Enter.\n",
    "Otherwise, if you do not wish to specify subsequences, type 'No' and press Enter.\"\"\"+'\\n')\n",
    "    test_seq = input(\"\"\"    -----> 'Yes' or 'No' to sub-sequence specification:  \"\"\")\n",
    "    if test_seq == 'Yes':\n",
    "        print(\"\"\"  \n",
    "--------------------------------------------------------------------------------------------------\n",
    "Nucleotide sequence(s): guide RNA annealing sites and/or test for presence/absence of sub-sequence\n",
    "--------------------------------------------------------------------------------------------------\"\"\")\n",
    "        # 6a-Collect guide RNA sequence details.\n",
    "        print(\"\"\"\n",
    "............................................................\n",
    "***** guide RNA details: specify guide RNA sequence(s) *****\n",
    "    \n",
    "To specify guide RNA sequence(s), enter text for each directly at the command line,\n",
    "separated by a comma ('x,y').\n",
    "    \n",
    "Please specify guide RNA sequence(s) [excluding PAM]:\n",
    "    \n",
    "When text entries are entered, press ‘enter’ again to proceed in the script.\n",
    "To skip text entries for these fields, simply press ‘enter’ until the next prompt appears.\n",
    "\n",
    "Examples:\n",
    "    If your single guide RNA sequence is 'ATCCAGTTCTCCAGTCTCCC', enter: 'ATCCAGTTCTCCAGTCTCCC'.\n",
    "    If you have two guide RNA sequences and they are 'ATCCAGTTCTCCAGTCTCCC' and 'GCGAGCTCGTGTCTGTGACG',\n",
    "    enter: 'ATCCAGTTCTCCAGTCTCCC, GCGAGCTCGTGTCTGTGACG'.\"\"\"+'\\n')\n",
    "        guideRNA_seq = input(r\"\"\"    -----> guide RNA sequence(s):  \"\"\")\n",
    "        guideRNA_seq = [i.strip() for i in guideRNA_seq.split(',')]\n",
    "        # 6b-Collect sub-sequence details (extant in allele or not?).\n",
    "        print(\"\"\"\n",
    "......................................................................................\n",
    "***** query DNA sequence(s): specify sequence(s) to test for presence or absence *****\n",
    "    \n",
    "To specify query DNA sequence(s), enter text for each directly at the command line,\n",
    "separated by a comma ('x,y').\n",
    "    \n",
    "Please specify short DNA sequence to test for presence vs. ablation.\n",
    "    \n",
    "When text entries are entered, press ‘enter’ again to proceed in the script.\n",
    "To skip text entries for these fields, simply press ‘enter’ until the next prompt appears.\n",
    "\n",
    "Examples:\n",
    "    If your single query sequence is 'TACTCAATATCGATC', enter: 'TACTCAATATCGATC'.\n",
    "    If you have two query sequences and they are 'TACTCAATATCGATC' and 'CGGGAGCCCGAG', enter:\n",
    "    'TACTCAATATCGATC, CGGGAGCCCGAG'.\"\"\"+'\\n')\n",
    "        extant_seq = input(r\"\"\"    -----> query DNA sequence(s):  \"\"\")\n",
    "        extant_seq = [i.strip() for i in extant_seq.split(',')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*'allele_output' defines a function that is called upon when populating the 'imputed_genotypes.txt' output file; the function reports alleles for samples that belong to a specified genotype class (e.g., homozygous deletion)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define 'allele_output' function to report defined alleles for samples based on genotype class designation\n",
    "def allele_output(genotype_class):\n",
    "    \"\"\"\n",
    "    This function outputs allele definitions for samples belonging to a specified class of imputed genotypes\n",
    "    \"\"\"\n",
    "    for i in genotype_class:\n",
    "        file.write(i+'\\n'+(18+len(imputedgenotypes_dict.get(i)[0]))*'*'+'\\n'+'IMPUTED GENOTYPE: '+imputedgenotypes_dict.get(i)[0]+'\\n'+(18+len(imputedgenotypes_dict.get(i)[0]))*'*'+'\\n\\n')\n",
    "        read_checklist = []\n",
    "        read_abundance_checklist = []\n",
    "        for n in range(1, len(imputedgenotypes_dict.get(i))):\n",
    "            if imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[1] == 'R1':\n",
    "                if 'R1' not in read_checklist:\n",
    "                    read_checklist.append('R1')\n",
    "                    file.write('\\n'+3*' '+'*'+8*'~'+'*\\n'+3*' '+'| READ 1 |\\n'+3*' '+'*'+8*'~'+'*\\n\\n')\n",
    "                else:\n",
    "                    pass\n",
    "                if float(imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[3].split(':')[1]) < 10:\n",
    "                    if 'R1dregs' not in read_abundance_checklist:\n",
    "                        read_abundance_checklist.append('R1dregs')\n",
    "                        file.write(3*' '+'*'+56*'~'+'*\\n'+3*' '+'|  >>>>> remaining alleles occur at frequency <10% <<<<< |\\n'+3*' '+'*'+56*'~'+'*\\n\\n')\n",
    "                    else:\n",
    "                        pass    \n",
    "            elif imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[1] == 'R2':\n",
    "                if 'R2' not in read_checklist:\n",
    "                    read_checklist.append('R2')\n",
    "                    if 'R1' not in read_checklist:\n",
    "                        file.write('\\n'+3*' '+'*'+8*'~'+'*\\n'+3*' '+'| READ 2 |\\n'+3*' '+'*'+8*'~'+'*\\n\\n')\n",
    "                    else:\n",
    "                        file.write(3*' '+'*'+8*'~'+'*\\n'+3*' '+'| READ 2 |\\n'+3*' '+'*'+8*'~'+'*\\n\\n')\n",
    "                else:\n",
    "                    pass\n",
    "                if float(imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[3].split(':')[1]) < 10:\n",
    "                    if 'R2dregs' not in read_abundance_checklist:\n",
    "                        read_abundance_checklist.append('R2dregs')\n",
    "                        file.write(3*' '+'*'+56*'~'+'*\\n'+3*' '+'|  >>>>> remaining alleles occur at frequency <10% <<<<< |\\n'+3*' '+'*'+56*'~'+'*\\n\\n')\n",
    "                    else:\n",
    "                        pass\n",
    "            if imputedgenotypes_dict.get(i)[n][1].get('allele_type') == 'wild-type':\n",
    "                file.write(3*' '+'Allele: '+imputedgenotypes_dict.get(i)[n][0].get('allele_name')+' | '+imputedgenotypes_dict.get(i)[n][1].get('allele_type')+'\\n    Locus: '+imputedgenotypes_dict.get(i)[n][0].get('chr+build')+', '+imputedgenotypes_dict.get(i)[n][0].get('locusID')+' '+imputedgenotypes_dict.get(i)[n][0].get('coordinates')+'\\n')\n",
    "            else:\n",
    "                file.write(3*' '+'Allele: '+imputedgenotypes_dict.get(i)[n][0].get('allele_name')+' | '+imputedgenotypes_dict.get(i)[n][1].get('allele_type')+', '+imputedgenotypes_dict.get(i)[n][1].get('allele_specs')+'\\n    Locus: '+imputedgenotypes_dict.get(i)[n][0].get('chr+build')+', '+imputedgenotypes_dict.get(i)[n][0].get('locusID')+' '+imputedgenotypes_dict.get(i)[n][0].get('coordinates')+'\\n')           \n",
    "            for guide in imputedgenotypes_dict.get(i)[n][2]:\n",
    "                if imputedgenotypes_dict.get(i)[n][2].get(guide) != 'None':\n",
    "                    if guide in guideRNA_seq:\n",
    "                        file.write('\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))-2)*' '+\"5'-\"+guide+\"-3' (guide sequence)\"+'\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))+len(guide)-3)*' '+'v')\n",
    "                    elif guide in guideRNA_seq_rev:\n",
    "                        file.write('\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))-2)*' '+\"3'-\"+guide+\"-5' (guide sequence)\"+'\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))+4)*' '+'v')\n",
    "            file.write(imputedgenotypes_dict.get(i)[n][0].get('alignment'))\n",
    "            for seq in imputedgenotypes_dict.get(i)[n][3]:\n",
    "                if imputedgenotypes_dict.get(i)[n][3].get(seq) != 'None':\n",
    "                    file.write('\\n')\n",
    "                    if seq in extant_seq:\n",
    "                        file.write((1+int(imputedgenotypes_dict.get(i)[n][3].get(seq)))*' '+len(seq)*'^'+'\\n'+(int(imputedgenotypes_dict.get(i)[n][3].get(seq))-2)*' '+\"5'-\"+seq+\"-3' (test sequence)\\n\")\n",
    "                    elif seq in extant_seq_rev:\n",
    "                        file.write((1+int(imputedgenotypes_dict.get(i)[n][3].get(seq)))*' '+len(seq)*'^'+'\\n'+(int(imputedgenotypes_dict.get(i)[n][3].get(seq))-2)*' '+\"3'-\"+seq+\"-5' (test sequence)\\n\")\n",
    "                elif imputedgenotypes_dict.get(i)[n][3].get(seq) == 'None':\n",
    "                    file.write('\\n')\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'frequency_plots' function to plot sample allele frequency metrics for visualization in pdf file\n",
    "def frequency_plots():\n",
    "    \"\"\"\n",
    "    This function plots sample allele frequency metrics for visualization in a pdf file\n",
    "    \"\"\"\n",
    "    # Make variable assigned in frequency_plots() function globally available\n",
    "    global frequencyplotsDuration\n",
    "    # Start the clock on plot time duration\n",
    "    startTime_frequencyplots = datetime.now()\n",
    "    # Assign allele_evidence.pdf file to output path\n",
    "    allele_evidence_output = Path(str(output_path)+'/'+processdate+'_allele_evidence.pdf')\n",
    "    # Initiate PDF file to record allele frequency plots for each sample\n",
    "    pdf = FPDF(format='letter')\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=20, style='B')\n",
    "    pdf.ln(20)\n",
    "    pdf.write(5, 'Frequency plots to support imputed genotypes')\n",
    "    pdf.output(allele_evidence_output)\n",
    "    # Generate allele frequency plots for each sample, based on the following principles and frequency metrics:\n",
    "    # for each sample, up to 10 candidate alleles are 'ranked' based on relative read frequency in the initial fastq file\n",
    "    # four frequency plots are generated, (1) raw read frequency relative to all other reads, (2) frequency relative to the\n",
    "    # top 10 most abundant reads, (3) frequency relative to reads that occur at >1% raw abundance; (4) frequency relative to\n",
    "    # reads that occur at >10% raw abundance\n",
    "    for samplename in imputedgenotypes_dict:\n",
    "        plot_name = output_directory / (samplename+'_plot.png')\n",
    "        pdf_output = output_directory / (samplename+'_.pdf')\n",
    "        R1_allele_list = []\n",
    "        R2_allele_list = []\n",
    "        R1_allele_names = []\n",
    "        R2_allele_names = []\n",
    "        R1_allele_frequency = []\n",
    "        R2_allele_frequency = []\n",
    "        R1_allele_type = []\n",
    "        R2_allele_type = []\n",
    "        R1_allele_specs = []\n",
    "        R2_allele_specs = []\n",
    "        for x in range(1, len(imputedgenotypes_dict[samplename])):\n",
    "            if imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[1] == 'R1':\n",
    "                R1_allele_list.append(imputedgenotypes_dict[samplename][x][0].get('allele_name'))\n",
    "                R1_allele_type.append(imputedgenotypes_dict[samplename][x][1].get('allele_type'))\n",
    "                R1_allele_specs.append(imputedgenotypes_dict[samplename][x][1].get('allele_specs'))\n",
    "            if imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[1] == 'R2':\n",
    "                R2_allele_list.append(imputedgenotypes_dict[samplename][x][0].get('allele_name'))\n",
    "                R2_allele_type.append(imputedgenotypes_dict[samplename][x][1].get('allele_type'))\n",
    "                R2_allele_specs.append(imputedgenotypes_dict[samplename][x][1].get('allele_specs')) \n",
    "        for i in range(1, len(R1_allele_list)+1):\n",
    "            R1_allele_names.append(i)\n",
    "        for i in range(1, len(R2_allele_list)+1):\n",
    "            R2_allele_names.append(i)\n",
    "        for i in R1_allele_list:\n",
    "            R1_allele_frequency.append(float(i.split(' ')[3].split(':')[1]))\n",
    "        for i in R2_allele_list:\n",
    "            R2_allele_frequency.append(float(i.split(' ')[3].split(':')[1]))\n",
    "#        \n",
    "        x1 = R1_allele_names\n",
    "        x2= R2_allele_names\n",
    "#\n",
    "        N = max(len(R1_allele_names), len(R2_allele_names))\n",
    "        width = 0.4\n",
    "        spacing1 = [float(i-width/2) for i in range(1,N+1)]\n",
    "        spacing2 = [float(i+width/2) for i in range(1,N+1)]\n",
    "#\n",
    "        y1a = R1_allele_frequency\n",
    "        y2a = R2_allele_frequency\n",
    "        while len(y1a) < N:\n",
    "            y1a.append(float(0))\n",
    "        while len(y2a) < N:\n",
    "            y2a.append(float(0))\n",
    "        label_list_a = [value for value in zip(x1,y1a,spacing1,R1_allele_type,R1_allele_specs)] + [value for value in zip(x2,y2a,spacing2,R2_allele_type,R2_allele_specs)]\n",
    "#\n",
    "        R1_allele_frequency_top10 = []\n",
    "        R2_allele_frequency_top10 = []\n",
    "        for i in R1_allele_list:\n",
    "            freq1 = i.split(' ')[5].split(':')[1]\n",
    "            R1_allele_frequency_top10.append(float(freq1) if freq1 != 'None' else 0)\n",
    "        for i in R2_allele_list:\n",
    "            freq2 = i.split(' ')[5].split(':')[1]\n",
    "            R2_allele_frequency_top10.append(float(freq2) if freq2 != 'None' else 0)\n",
    "        y1b = R1_allele_frequency_top10\n",
    "        y2b = R2_allele_frequency_top10\n",
    "        while len(y1b) < N:\n",
    "            y1b.append(float(0))\n",
    "        while len(y2b) < N:\n",
    "            y2b.append(float(0))\n",
    "        label_list_b = [value for value in zip(x1,y1b,spacing1,R1_allele_type,R1_allele_specs)] + [value for value in zip(x2,y2b,spacing2,R2_allele_type,R2_allele_specs)]    \n",
    "#  \n",
    "        R1_allele_frequency_1 = []\n",
    "        R2_allele_frequency_1 = []\n",
    "        for i in R1_allele_list:\n",
    "            freq1 = i.split(' ')[6].split(':')[1]\n",
    "            R1_allele_frequency_1.append(float(freq1) if freq1 != 'None' else 0)\n",
    "        for i in R2_allele_list:\n",
    "            freq2 = i.split(' ')[6].split(':')[1]\n",
    "            R2_allele_frequency_1.append(float(freq2) if freq2 != 'None' else 0)\n",
    "        y1c = R1_allele_frequency_1\n",
    "        y2c = R2_allele_frequency_1\n",
    "        while len(y1c) < N:\n",
    "            y1c.append(float(0))\n",
    "        while len(y2c) < N:\n",
    "            y2c.append(float(0))\n",
    "        label_list_c = [value for value in zip(x1,y1c,spacing1,R1_allele_type,R1_allele_specs)] + [value for value in zip(x2,y2c,spacing2,R2_allele_type,R2_allele_specs)]\n",
    "#\n",
    "        R1_allele_frequency_10 = []\n",
    "        R2_allele_frequency_10 = []\n",
    "        for i in R1_allele_list:\n",
    "            freq1 = i.split(' ')[7].split(':')[1]\n",
    "            R1_allele_frequency_10.append(float(freq1) if freq1 != 'None' else 0)\n",
    "        for i in R2_allele_list:\n",
    "            freq2 = i.split(' ')[7].split(':')[1]\n",
    "            R2_allele_frequency_10.append(float(freq2) if freq2 != 'None' else 0)\n",
    "        y1d = R1_allele_frequency_10\n",
    "        y2d = R2_allele_frequency_10\n",
    "        while len(y1d) < N:\n",
    "            y1d.append(float(0))\n",
    "        while len(y2d) < N:\n",
    "            y2d.append(float(0))\n",
    "        label_list_d = [value for value in zip(x1,y1d,spacing1,R1_allele_type,R1_allele_specs)] + [value for value in zip(x2,y2d,spacing2,R2_allele_type,R2_allele_specs)]    \n",
    "#\n",
    "# Plots    \n",
    "        fig = plt.figure(figsize=(10,7), dpi=100)\n",
    "# Subplot 1\n",
    "        ax1 = fig.add_subplot(141)\n",
    "        ax1.grid(color='#808080', linestyle='--', linewidth=0.2, axis='x')\n",
    "        rects1 = ax1.barh(spacing1, y1a, width, color='#FFB90F', alpha=0.5, edgecolor='black', align='center')\n",
    "        rects2 = ax1.barh(spacing2, y2a, width, color='#0147FA', alpha=0.5, edgecolor='black', align='center')\n",
    "        ax1.set_ylabel('Allele Rank', fontsize=10, fontname='Myriad Pro')\n",
    "        ax1.set_xlabel('Frequency', fontsize=10, fontname='Myriad Pro')\n",
    "        ax1.set_title('Allele frequencies\\n(% total reads)', fontsize=9, fontweight='bold', fontname='Myriad Pro')\n",
    "        plt.xlim([0,120])\n",
    "        plt.ylim([0.5, N+0.5])\n",
    "        plt.gca().invert_yaxis()\n",
    "        ax1 = plt.gca()\n",
    "        ax1.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax1.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "        ax1.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.legend((rects1[0], rects2[0]), ('R1', 'R2'), loc = 'lower right')\n",
    "        for i in label_list_a:\n",
    "            if i[1] != 0:\n",
    "                if i[1] > 20:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax1.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', weight = 'bold', fontsize=7)\n",
    "                        ax1.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax1.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', weight = 'bold', fontsize=7)\n",
    "                else:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax1.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', fontsize=7)\n",
    "                        ax1.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax1.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', fontsize=7)\n",
    "#\n",
    "# Subplot 2\n",
    "        ax2 = fig.add_subplot(142)\n",
    "        ax2.grid(color='#808080', linestyle='--', linewidth=0.2, axis='x')\n",
    "        rects1 = ax2.barh(spacing1, y1b, width, color='#FFB90F', alpha=0.5, edgecolor='black', align='center')\n",
    "        rects2 = ax2.barh(spacing2, y2b, width, color='#0147FA', alpha=0.5, edgecolor='black', align='center')\n",
    "        ax2.set_ylabel('Allele Rank', fontsize=10, fontname='Myriad Pro')\n",
    "        ax2.set_xlabel('Frequency', fontsize=10, fontname='Myriad Pro')\n",
    "        ax2.set_title('Allele frequencies\\n(% top 10 most abundant reads)', fontsize=9, fontweight='bold', fontname='Myriad Pro')\n",
    "        plt.xlim([0,120])\n",
    "        plt.ylim([0.5, N+0.5])\n",
    "        plt.gca().invert_yaxis()\n",
    "        ax2 = plt.gca()\n",
    "        ax2.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "        ax2.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.legend((rects1[0], rects2[0]), ('R1', 'R2'), loc = 'lower right')\n",
    "        for i in label_list_b:\n",
    "            if i[1] != 0:\n",
    "                if i[1] > 20:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax2.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', weight = 'bold', fontsize=7)\n",
    "                        ax2.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax2.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', weight = 'bold', fontsize=7)\n",
    "                else:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax2.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', fontsize=7)\n",
    "                        ax2.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax2.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', fontsize=7)\n",
    "#\n",
    "# Subplot 3       \n",
    "        ax3 = fig.add_subplot(143)\n",
    "        ax3.grid(color='#808080', linestyle='--', linewidth=0.2, axis='x')\n",
    "        rects1 = ax3.barh(spacing1, y1c, width, color='#FFB90F', alpha=0.5, edgecolor='black', align='center')\n",
    "        rects2 = ax3.barh(spacing2, y2c, width, color='#0147FA', alpha=0.5, edgecolor='black', align='center')\n",
    "        ax3.set_ylabel('Allele Rank', fontsize=10, fontname='Myriad Pro')\n",
    "        ax3.set_xlabel('Frequency', fontsize=10, fontname='Myriad Pro')\n",
    "        ax3.set_title('Allele frequencies\\n(% reads adjusted for frequency >1%)', fontsize=9, fontweight='bold', fontname='Myriad Pro')\n",
    "        plt.xlim([0,120])\n",
    "        plt.ylim([0.5, N+0.5])\n",
    "        plt.gca().invert_yaxis()\n",
    "        ax3 = plt.gca()\n",
    "        ax3.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax3.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "        ax3.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax3.spines['right'].set_visible(False)\n",
    "        ax3.legend((rects1[0], rects2[0]), ('R1', 'R2'), loc = 'lower right')\n",
    "        for i in label_list_c:\n",
    "            if i[1] != 0:\n",
    "                if i[1] > 20:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax3.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', weight = 'bold', fontsize=7)\n",
    "                        ax3.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax3.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', weight = 'bold', fontsize=7)\n",
    "                else:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax3.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', fontsize=7)\n",
    "                        ax3.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax3.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', fontsize=7)\n",
    "#\n",
    "# Subplot 4\n",
    "        ax4 = fig.add_subplot(144)\n",
    "        ax4.grid(color='#808080', linestyle='--', linewidth=0.2, axis='x')\n",
    "        rects1 = ax4.barh(spacing1, y1d, width, color='#FFB90F', alpha=0.5, edgecolor='black', align='center')\n",
    "        rects2 = ax4.barh(spacing2, y2d, width, color='#0147FA', alpha=0.5, edgecolor='black', align='center')\n",
    "        ax4.set_ylabel('Allele Rank', fontsize=10, fontname='Myriad Pro')\n",
    "        ax4.set_xlabel('Frequency', fontsize=10, fontname='Myriad Pro')\n",
    "        ax4.set_title('Allele frequencies\\n(% reads adjusted for frequency >10%)', fontsize=9, fontweight='bold', fontname='Myriad Pro')\n",
    "        plt.xlim([0,120])\n",
    "        plt.ylim([0.5, N+0.5])\n",
    "        plt.gca().invert_yaxis()\n",
    "        ax4 = plt.gca()\n",
    "        ax4.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax4.xaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "        ax4.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax4.spines['right'].set_visible(False)\n",
    "        ax4.legend((rects1[0], rects2[0]), ('R1', 'R2'), loc = 'lower right')\n",
    "        for i in label_list_d:\n",
    "            if i[1] != 0:\n",
    "                if i[1] > 20:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax4.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', weight = 'bold', fontsize=7)\n",
    "                        ax4.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax4.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', weight = 'bold', fontsize=7)\n",
    "                else:\n",
    "                    if str(i[4]) != 'None':\n",
    "                        ax4.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'bottom', color = 'black', fontsize=7)\n",
    "                        ax4.text(i[1]+2, i[2], str(i[4]), va = 'top', color = 'black', style = 'italic', fontsize=7)\n",
    "                    else:\n",
    "                        ax4.text(i[1]+2, i[2], str(i[1])+'% | '+i[3], va = 'center', color = 'black', fontsize=7)\n",
    "#\n",
    "        plt.tight_layout()\n",
    "#\n",
    "        plt.savefig(plot_name, format='png', dpi=250)\n",
    "        plt.close(fig)\n",
    "#   \n",
    "        pdf = FPDF('L', 'mm', (400, 250))\n",
    "        pdf.add_page()\n",
    "        pdf.set_font(\"Arial\", size=8, style='BU')\n",
    "        pdf.write(5, samplename)\n",
    "        pdf.ln(3)\n",
    "        pdf.set_font(\"Arial\", size=7)\n",
    "        pdf.write(5, 'imputed genotype: '+imputedgenotypes_dict[samplename][0].split('|')[1]+','+imputedgenotypes_dict[samplename][0].split('|')[2])\n",
    "        pdf.ln(5)\n",
    "        allele_count_R1 = 1\n",
    "        allele_count_R2 = 1\n",
    "        read1_check = []\n",
    "        read2_check = []\n",
    "        for x in range(1, len(imputedgenotypes_dict[samplename])):\n",
    "            if imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[1] == 'R1':\n",
    "                if imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[7].split(':')[1]) > 20:\n",
    "                    if len(read1_check) == 0:\n",
    "                        read1_check.append('R1')\n",
    "                        pdf.set_font(\"Arial\", size=7, style='U')\n",
    "                        pdf.write(5, 'Read 1, sequences with >20% representation among reads:')\n",
    "                        pdf.ln(3)\n",
    "                    else:\n",
    "                        pass\n",
    "                    pdf.set_font(\"Arial\", size=6)\n",
    "                    if imputedgenotypes_dict[samplename][x][1].get('allele_specs') is not None:\n",
    "                        pdf.write(5, 'Allele '+str(allele_count_R1)+': '+imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[2]+' '+imputedgenotypes_dict[samplename][x][1].get('allele_type')+', '+imputedgenotypes_dict[samplename][x][1].get('allele_specs'))\n",
    "                    else:\n",
    "                        pdf.write(5, 'Allele '+str(allele_count_R1)+': '+imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[2]+' '+imputedgenotypes_dict[samplename][x][1].get('allele_type'))     \n",
    "                    pdf.ln(3)\n",
    "                    pdf.set_font(\"Courier\", size=6)\n",
    "                    pdf.write(5, imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[1])\n",
    "                    pdf.ln(3)\n",
    "                    pdf.write(5, imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[2])\n",
    "                    pdf.ln(3)\n",
    "                    pdf.write(5, imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[3])\n",
    "                    allele_count_R1 = allele_count_R1+1\n",
    "                    pdf.ln(4)\n",
    "            elif imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[1] == 'R2':\n",
    "                if imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[7].split(':')[1]) > 20:\n",
    "                    if len(read2_check) == 0:\n",
    "                        read2_check.append('R2')\n",
    "                        pdf.set_font(\"Arial\", size=7, style='U')\n",
    "                        pdf.write(5, 'Read 2, sequences with >20% representation among reads:')\n",
    "                        pdf.ln(3)\n",
    "                    else:\n",
    "                        pass\n",
    "                    pdf.set_font(\"Arial\", size=6)\n",
    "                    if imputedgenotypes_dict[samplename][x][1].get('allele_specs') is not None:\n",
    "                        pdf.write(5, 'Allele '+str(allele_count_R2)+': '+imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[2]+' '+imputedgenotypes_dict[samplename][x][1].get('allele_type')+', '+imputedgenotypes_dict[samplename][x][1].get('allele_specs'))\n",
    "                    else:\n",
    "                        pdf.write(5, 'Allele '+str(allele_count_R2)+': '+imputedgenotypes_dict[samplename][x][0].get('allele_name').split(' ')[2]+' '+imputedgenotypes_dict[samplename][x][1].get('allele_type'))\n",
    "                    pdf.ln(3)\n",
    "                    pdf.set_font(\"Courier\", size=6)\n",
    "                    pdf.write(5, imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[1])\n",
    "                    pdf.ln(3)\n",
    "                    pdf.write(5, imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[2])\n",
    "                    pdf.ln(3)\n",
    "                    pdf.write(5, imputedgenotypes_dict[samplename][x][0].get('alignment').split('\\n')[3])\n",
    "                    allele_count_R2 = allele_count_R2+1\n",
    "                    pdf.ln(4)\n",
    "        pdf.ln(5)\n",
    "        pdf.image(plot_name, x = None, y = None, w = 195, h = 0, type = '', link = '')\n",
    "        pdf.output(pdf_output)\n",
    "#    \n",
    "        merger = PdfFileMerger()\n",
    "#   \n",
    "        filenames =[str(allele_evidence_output), pdf_output]\n",
    "#\n",
    "        for filename in filenames:\n",
    "            merger.append(PdfFileReader(filename, 'rb'))\n",
    "#   \n",
    "        merger.write(str(allele_evidence_output))\n",
    "    # Remove sample png file and pdf file as intermediaries\n",
    "        try:\n",
    "            os.remove(plot_name)\n",
    "        except OSError:\n",
    "            pass\n",
    "#    \n",
    "        try:\n",
    "            os.remove(pdf_output)\n",
    "        except OSError:\n",
    "            pass  \n",
    "# Log frequency plotting time duration\n",
    "    frequencyplotsDuration = str(datetime.now()- startTime_frequencyplots).split(':')[0]+' hr|'+str(datetime.now() - startTime_frequencyplots).split(':')[1]+' min|'+str(datetime.now() - startTime_frequencyplots).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_frequencyplots).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*'convert_bytes' and 'path_size' define functions that are used when populating 'script_metrics.txt' with script directory and file size metadata; 'convert_bytes' reframes a path size (in bytes) to a higher-order of magnitude, if appropriate (e.g., KB, MB, GB, TB); 'path_size' defines a function that returns file or directory size (in bytes, KB, MB, GB, or TB)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define 'convert_bytes' function to be used in data collection for script_metrics.txt\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    This function converts bytes to convenient order of magnitude prefixes\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "        \n",
    "# Define 'path_size' function to be used in data collection for script_metrics.txt\n",
    "def path_size(given_path):\n",
    "    \"\"\"\n",
    "    This function returns file or directory size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(given_path):\n",
    "        file_info = os.stat(given_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "    elif os.path.isdir(given_path):\n",
    "        dir_info = os.stat(given_path)\n",
    "        return convert_bytes(dir_info.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### II. Define user-specified variables\n",
    "\n",
    "A user defines input variables by entering individual lines of text at the Jupyter interface.  \n",
    "\n",
    "Up to 7 variables will now be defined as inputs (see **'User inputs'** above). \n",
    "\n",
    "First, specify whether user input is provided at individually coached prompts (**'Prompt'**) or in rapid succession that bypasses detailed prompts (**'List'**).\n",
    "\n",
    "In either format, a user will also be asked whether **optional DNA sub-sequence(s)** will be provided, to map onto sequence alignments. Specifically, the script classifies these optional sub-sequences as either **guide RNA sequences** (5'->3' in DNA form, excluding PAM) or **test sequences** (5'->3', to query for presence/absence in aligned sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify 'Prompt' or 'List' format for entry of user-defined variables \n",
    "user_input = input(r\"\"\"\n",
    "---------------------------------------------------------------------\n",
    "User-specified input: choice of coached prompts vs. single-list entry\n",
    "---------------------------------------------------------------------\n",
    "    \n",
    "Values for the user-specified input indicated above can be entered at individually coached command-line prompts\n",
    "(default), or as a single list of variables provided in a single command-line entry without coached prompts.\n",
    "    \n",
    "To proceed with input at individual command-line PROMPTS, type 'Prompt' and press Enter;\n",
    "To proceed with input provided as a single LIST in one command-line entry, type 'List' and press Enter:  \"\"\")\n",
    "\n",
    "if user_input == 'Prompt':\n",
    "    prompts()\n",
    "elif user_input == 'List':\n",
    "    print(\"\"\"\n",
    "\n",
    "You specified LIST format to specify input values.\n",
    "..............................................................................................................\n",
    "Some applications of 'allele definition' and 'genotype imputation' may call for identification of the presence\n",
    "or absence of a specific anticipated sub-sequence (few nucleotides), and/or for the mapping of the location of\n",
    "a sub-sequence if present in the sequence alignment.\n",
    "    \n",
    "ImputedGenotypes.py allows for the optional testing of sub-sequences.\n",
    "    \n",
    "If you would like to specify subsequences, type 'Yes' and press Enter.\n",
    "Otherwise, if you do not wish to specify subsequences, type 'No' and press Enter.\"\"\"+'\\n')\n",
    "    test_seq = input(r\"\"\"    -----> 'Yes' or 'No' to sub-sequence specification:  \"\"\")\n",
    "    if test_seq == 'Yes':\n",
    "        print(r\"\"\"    \n",
    "    Will you specify guide RNA sequence(s) to map onto output alignments?\"\"\")\n",
    "        user_input2 = input(r\"\"\"    -----> 'Yes' or 'No' to guide RNA specification:  \"\"\")\n",
    "        print(r\"\"\"    \n",
    "    Will you specify query DNA sequence(s) (sequence(s) to test for presence or absence) to map onto output\n",
    "    alignments?\"\"\")\n",
    "        user_input3 = input(r\"\"\"    -----> 'Yes' or 'No' to query sub-sequence specification:  \"\"\")\n",
    "        if user_input2 == 'Yes' and user_input3 == 'Yes':\n",
    "            print(r\"\"\"\n",
    "----------------------------------\n",
    "User-specified input (list format)\n",
    "----------------------------------\n",
    "Please paste individual input values directly at the command line prompts, specifying the following 7 values\n",
    "in the specified order.\n",
    "\n",
    "Press 'Enter' twice to complete.\n",
    "\n",
    "    1-Location of OUTPUT DIRECTORY for output files\n",
    "    2-Location of INPUT FILES (directory containing fastq files)\n",
    "    3-Location of BLASTN EXECUTABLE\n",
    "    4-Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
    "    5-Prefix common to BLASTN sequence database files\n",
    "    6-Optional guide RNA sequence(s) to identify in output alignments\n",
    "    7-Optional sub-sequence(s) to identify in output alignments\n",
    "\n",
    "    \"\"\")\n",
    "            input_list = []\n",
    "            stopword = \"\"\n",
    "            while True:\n",
    "                input_str = input()\n",
    "                if input_str.strip() == stopword:\n",
    "                    break\n",
    "                else:\n",
    "                    input_list.append(input_str)\n",
    "            output_directory = input_list[0].strip()\n",
    "            fastq_directory = input_list[1].strip()\n",
    "            blastn_path = input_list[2].strip()\n",
    "            db_path = input_list[3].strip()\n",
    "            db_prefix = input_list[4].strip()\n",
    "            guideRNA_seq = [i.strip() for i in input_list[5].split(',')]\n",
    "            extant_seq = [i.strip() for i in input_list[6].split(',')]\n",
    "        elif user_input2 == 'Yes' and user_input3 == 'No':\n",
    "            print(r\"\"\"\n",
    "----------------------------------\n",
    "User-specified input (list format)\n",
    "----------------------------------\n",
    "    \n",
    "Please paste individual input values directly at the interpreter prompts, specifying the following 6 values\n",
    "in the specified order.\n",
    "\n",
    "Press 'Enter' twice to complete.\n",
    "    \n",
    "    1-Location of OUTPUT DIRECTORY for output files\n",
    "    2-Location of INPUT FILES (directory containing fastq files)\n",
    "    3-Location of BLASTN EXECUTABLE\n",
    "    4-Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
    "    5-Prefix common to BLASTN sequence database files\n",
    "    6-Optional guide RNA sequence(s) to identify in output alignments\n",
    "    \n",
    "    \"\"\")\n",
    "            input_list = []\n",
    "            stopword = \"\"\n",
    "            while True:\n",
    "                input_str = input()\n",
    "                if input_str.strip() == stopword:\n",
    "                    break\n",
    "                else:\n",
    "                    input_list.append(input_str)\n",
    "            output_directory = input_list[0].strip()\n",
    "            fastq_directory = input_list[1].strip()\n",
    "            blastn_path = input_list[2].strip()\n",
    "            db_path = input_list[3].strip()\n",
    "            db_prefix = input_list[4].strip()\n",
    "            guideRNA_seq = [i.strip() for i in input_list[5].split(',')]\n",
    "        elif user_input2 == 'No' and user_input3 == 'Yes':\n",
    "            print(r\"\"\"\n",
    "----------------------------------\n",
    "User-specified input (list format)\n",
    "----------------------------------\n",
    "    \n",
    "Please paste individual input values directly at the command line prompts, specifying the following 6 values\n",
    "in the specified order.\n",
    "\n",
    "Press 'Enter' twice to complete.\n",
    "    \n",
    "    1-Location of OUTPUT DIRECTORY for output files\n",
    "    2-Location of INPUT FILES (directory containing fastq files)\n",
    "    3-Location of BLASTN EXECUTABLE\n",
    "    4-Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
    "    5-Prefix common to BLASTN sequence database files\n",
    "    6-Optional sub-sequence(s) to identify in output alignments\n",
    "    \n",
    "    \"\"\")  \n",
    "            input_list = []\n",
    "            stopword = \"\"\n",
    "            while True:\n",
    "                input_str = input()\n",
    "                if input_str.strip() == stopword:\n",
    "                    break\n",
    "                else:\n",
    "                    input_list.append(input_str)\n",
    "            output_directory = input_list[0].strip()\n",
    "            fastq_directory = input_list[1].strip()\n",
    "            blastn_path = input_list[2].strip()\n",
    "            db_path = input_list[3].strip()\n",
    "            db_prefix = input_list[4].strip()\n",
    "            extant_seq = [i.strip() for i in input_list[5].split(',')]\n",
    "    elif test_seq == 'No':\n",
    "        print(r\"\"\"\n",
    "----------------------------------\n",
    "User-specified input (list format)\n",
    "----------------------------------\n",
    "    \n",
    "Please paste individual input values directly at the command line prompts, specifying the following 5 values\n",
    "in the specified order.\n",
    "\n",
    "Press 'Enter' twice to complete.\n",
    "    \n",
    "    1-Location of OUTPUT DIRECTORY for output files\n",
    "    2-Location of INPUT FILES (directory containing fastq files)\n",
    "    3-Location of BLASTN EXECUTABLE\n",
    "    4-Location of BLASTN ALIGNMENT DATABASE DIRECTORY\n",
    "    5-Prefix common to BLASTN sequence database files\n",
    "    \n",
    "    \"\"\")  \n",
    "        input_list = []\n",
    "        stopword = \"\"\n",
    "        while True:\n",
    "            input_str = input()\n",
    "            if input_str.strip() == stopword:\n",
    "                break\n",
    "            else:\n",
    "                input_list.append(input_str)\n",
    "        output_directory = input_list[0].strip()\n",
    "        fastq_directory = input_list[1].strip()\n",
    "        blastn_path = input_list[2].strip()\n",
    "        db_path = input_list[3].strip()\n",
    "        db_prefix = input_list[4].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Convert directory and executable strings to operating system-appropriate paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Wait to create the directories and files until after input has been reviewed and accepted.\n",
    "# Convert fastq_directory input to operating system-appropriate filepath.\n",
    "output_directory = Path(str(output_directory))\n",
    "# Convert fastq_directory input to operating system-appropriate filepath.\n",
    "fastq_directory = Path(str(fastq_directory))\n",
    "# Convert blastn_path input to operating system-appropriate filepath.\n",
    "blastn_path = Path(str(blastn_path))\n",
    "# Convert db_path input to operating system-appropriate filepath.\n",
    "db_path = Path(str(db_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Collect fastq files from directory; sort alphanumerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "myFastqFilenames = [file for file in glob.glob(str(fastq_directory)+'/*') if Path(file).suffix == \".fastq\"]\n",
    "\n",
    "#Sort fastq file names\n",
    "myFastqFilenames = sorted(myFastqFilenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Print fastq file names, to double-check file inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "for file in myFastqFilenames:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Collect overview of fastq file contents:  \n",
    "<ul>\n",
    "  <li>Illumina runID</li>   \n",
    "  <li>read count in each fastq file</li>    \n",
    "  <li>file size</li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Collect Illumina run IDs from fastq files, consolidate to unique run IDs\n",
    "runIDlist = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    with open(sourcefile, \"r\") as f:\n",
    "        runID = \":\".join(f.readline().split(\":\",-2)[:2])\n",
    "    if not runID in runIDlist:\n",
    "        runIDlist.append(runID) \n",
    "\n",
    "# Collect total read counts for fastq files\n",
    "readcount = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    with open(sourcefile, \"r\") as f:\n",
    "        readcount.append(int(len((f).readlines())/4))\n",
    "        \n",
    "# Collect file sizes for fastq files\n",
    "filesize = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    filesize.append(round((os.path.getsize(sourcefile)/1048576),5))\n",
    "\n",
    "# fastq_overview prepares summation of fastq file names, their sizes, and read counts, to be reported in script_metrics.txt    \n",
    "fastq_overview = list(zip(myFastqFilenames, filesize, readcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Double-check whether user-specified entries look good. If a variable is inaccurately assigned, prompt user to restart kernel to begin again.\n",
    "\n",
    "Retrieve and/or calculate the following properties across the fastq files to be processed (these values will be reported in script_metrics.txt):  \n",
    "<ul>\n",
    "  <li>Illumina sequencing run ID(s)</li>\n",
    "  <li>Total number of fastq files</li>\n",
    "  <li>Total number of sequencing reads</li>\n",
    "  <li>Size distribution of fastq files</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "---------------------------------------------------------------\n",
    "Preparation for output:\n",
    "Please double-check that your inputs were recorded as expected.\n",
    "---------------------------------------------------------------\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "Your OUTPUT DIRECTORY was recorded as:\n",
    "\"\"\")\n",
    "print(str(output_directory))\n",
    "\n",
    "print(\"\"\"\n",
    "Your directory containing fastq INPUT FILES was recorded as:\n",
    "\"\"\")\n",
    "print(str(fastq_directory))\n",
    "\n",
    "print(\"\"\"\n",
    "    The following data were collected:  \"\"\")\n",
    "print(\"    Illumina sequencing run ID(s): \")\n",
    "for i in runIDlist:\n",
    "    print('        '+i)\n",
    "\n",
    "print(\"    # of fastq files to process: {0}\".format(len(myFastqFilenames)))\n",
    "\n",
    "print(\"    size distribution of fastq files to process: \\n      total... \"+str(round((sum(file for file in filesize))))+' MB \\n      range... max: '+str(round((max(file for file in filesize)),2))+' MB; min: '+str(round((min(file for file in filesize)),5))+' MB; median: '+str(round((numpy.median([file for file in filesize])),3))+' MB; mean +/- stdev: '+str(round((numpy.mean([file for file in filesize])),3))+' +/- '+str(round((numpy.std([file for file in filesize])),3))+' MB')\n",
    "\n",
    "print(\"    read distribution within fastq files to process: \\n      total... \"+locale.format_string(\"%d\", sum(readcount), grouping=True)+' reads \\n      range... max: '+str((max(file for file in readcount)))+' reads; min: '+str((min(file for file in readcount)))+' reads; median: '+str((numpy.median([file for file in readcount])))+' reads; mean +/- stdev: '+str(round((numpy.mean([file for file in readcount]))))+' +/- '+str(round((numpy.std([file for file in readcount]))))+' reads')\n",
    "\n",
    "print(\"\"\"\n",
    "Your BLASTN EXECUTABLE location was recorded as:\n",
    "\"\"\")\n",
    "print(str(blastn_path))\n",
    "\n",
    "print(\"\"\"\n",
    "Your BLASTN ALIGNMENT DATABASE DIRECTORY was recorded as:\n",
    "\"\"\")\n",
    "print(str(db_path))\n",
    "\n",
    "print(\"\"\"\n",
    "Your PREFIX common to BLASTN ALIGNMENT DATABASE FILES was recorded as:\n",
    "\"\"\")\n",
    "print(db_prefix)\n",
    "\n",
    "if test_seq == 'Yes':\n",
    "    print(\"\"\"\n",
    "Your DNA sub-sequence(s) were recorded as:\n",
    "\"\"\")\n",
    "    try:\n",
    "        guideRNA_seq\n",
    "    except NameError:\n",
    "        pass\n",
    "    else:\n",
    "        print('guide RNA sequence(s): '+str(guideRNA_seq))\n",
    "    try:\n",
    "        extant_seq\n",
    "    except NameError:\n",
    "        pass\n",
    "    else:\n",
    "        print('sub-sequence(s) to query for presence: '+str(extant_seq))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "check = input(\"\"\"\n",
    "Is this list accurately recorded? Type 'Y' or 'N': \n",
    "\"\"\")\n",
    "\n",
    "if check == 'Y':\n",
    "    pass\n",
    "elif check == 'N':\n",
    "    print(\"\"\"\n",
    "If you have corrections to make, please return to the appropriate cell to reset variables.\n",
    "To continue in the script, move to the next cell.\n",
    "To restart the script, click on the menu 'Kernel -> Restart'.  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Include or bypass frequency plot generation (optional file output, allele_evidence.pdf)**\n",
    "\n",
    "*ImputedGenotypes.py can produce a pdf containing frequency plots as evidence for allele contributions to imputed genotype(s). Frequency plot generation is time-intensive (for example, ~2-3 minutes per sample, depending on hardware parameters e.g., available RAM).* \n",
    "\n",
    "Indicate whether the script should create frequency plots (pdf) as **allele_evidence.pdf**, or whether this code block should be skipped at this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frequency_plot_check = input(\"\"\"\n",
    "ImputedGenotypes.py is ready to process fastq files. Before script operations begin, please indicate whether visual\n",
    "plots of allele frequencies should be rendered and delivered in an output file, allele_evidence.pdf.\n",
    "\n",
    "Note that production of allele_evidence.pdf can require hours of processing time, although the output timing of\n",
    "key text files with allele definitions and genotype imputations (e.g., allele_definitions.txt, imputed_genotypes.txt,\n",
    "allele_definitions.csv, population_summary.txt) will not be affected.\n",
    "\n",
    "To PROCEED with script operations that INCLUDE allele_evidence.pdf, type 'Y';\n",
    "\n",
    "To BYPASS script operations that generate allele_evidence.pdf, type 'N': \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### III. Generate output directory and files, ready for script output  \n",
    "Script generates a single directory, populated with 8 files ready to accept script output.  \n",
    "Files are automatically named as in **'Output notes'** above, with current date appended to filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on script operation duration\n",
    "startTime = datetime.now()\n",
    "startTimestr = str(startTime).split(' ')[1].split('.')[0]\n",
    "\n",
    "# Log time duration of user input\n",
    "userinputDuration = str(startTime - initialTime).split(':')[0]+' hr|'+str(startTime - initialTime).split(':')[1]+' min|'+str(startTime - initialTime).split(':')[2].split('.')[0]+' sec|'+str(startTime - initialTime).split(':')[2].split('.')[1]+' microsec'\n",
    "\n",
    "# Generate the directory and its files (to accept content later in script)\n",
    "path = str(output_directory)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "output_path = Path(output_directory)\n",
    "\n",
    "# Create output files\n",
    "if frequency_plot_check == 'Y':\n",
    "    filename_list = ['fasta.fa', 'blastn_alignments.txt', 'allele_definitions.txt', 'allele_evidence.pdf', 'imputed_genotypes.txt', 'population_summary.txt', 'allele_definitions.csv', 'script_metrics.txt']\n",
    "elif frequency_plot_check == 'N':\n",
    "    filename_list = ['fasta.fa', 'blastn_alignments.txt', 'allele_definitions.txt', 'imputed_genotypes.txt', 'population_summary.txt', 'allele_definitions.csv', 'script_metrics.txt']\n",
    "\n",
    "# Define current date as prefix to all filenames\n",
    "processdate = datetime.today().strftime(\"%m%d%Y\")\n",
    "\n",
    "for filename in filename_list:\n",
    "    with open(os.path.join(path, processdate+'_'+filename), 'wb') as file:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The file **script_metrics.txt** records script operation metadata (summarizes script input and performance); peform initial log of system information, user-defined variables and fastq file properties to script_metrics.txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Collect RAM info for local operating system\n",
    "mem = virtual_memory()\n",
    "ramem = mem.total/1073741824\n",
    "\n",
    "# Use print redirection to write to target file, in append mode (begin script_metrics.txt)\n",
    "filename = Path(str(output_path)+'/'+processdate+'_script_metrics.txt')\n",
    "with open(filename, 'a') as f:\n",
    "    print(\"\"\"ImputedGenotypes.py: Script Metrics\\nDate: \"\"\" + (datetime.today().strftime(\"%m/%d/%Y\")) +\n",
    "\"\"\"\\n\\nOperating system information:\n",
    "    name: \"\"\" + socket.gethostname() +\n",
    "'\\n    platform: ' + platform.platform() +\n",
    "'\\n    RAM (GB): ' + str(ramem) +\n",
    "'\\n    physical CPU/effective CPU: ' + str(psutil.cpu_count(logical=False)) +'/'+ str(psutil.cpu_count()) +\n",
    "'\\n    executable: ' + psutil.Process().exe() +\n",
    "\"\"\"\\n\\nUser-entered variables:\n",
    "    output_directory: \"\"\"+ str(output_directory) +\n",
    "\"\\n    fastq_directory: \"+ str(fastq_directory) +\n",
    "\"\\n    blastn_path: \"+ str(blastn_path) +\n",
    "\"\\n    db_path: \"+ str(db_path) +\n",
    "\"\\n    db_prefix: \"+ db_prefix, file = f)\n",
    "    try:\n",
    "        guideRNA_seq\n",
    "    except NameError:\n",
    "        print('    guideRNA_seq: not defined', file = f)\n",
    "    else:\n",
    "        print(\"    guideRNA_seq: \"+ str(guideRNA_seq).strip('[]').replace(\"'\",\"\"), file = f)\n",
    "    try:\n",
    "        extant_seq\n",
    "    except NameError:\n",
    "        print('    extant_seq: not defined', file = f)\n",
    "    else:\n",
    "        print(\"    extant_seq: \"+ str(extant_seq).strip('[]').replace(\"'\",\"\"), file = f)\n",
    "    print(\"\"\"\\nfastq file information:\n",
    "    Illumina sequencing run ID(s): \"\"\"+ str(runIDlist).strip('[]').replace(\"'\",\"\") +\n",
    "\"\\n    Number of fastq files processed: \"+ str(len(myFastqFilenames)) +\n",
    "\"\"\"\\n    Size distribution of fastq files processed: \n",
    "        total... \"\"\" +str(round((sum(file for file in filesize))))+' MB \\n        range... max: '+str(round((max(file for file in filesize)),2))+' MB; min: '+str(round((min(file for file in filesize)),5))+' MB; median: '+str(round((numpy.median([file for file in filesize])),3))+' MB; mean +/- stdev: '+str(round((numpy.mean([file for file in filesize])),3))+' +/- '+str(round((numpy.std([file for file in filesize])),3))+' MB'\n",
    "\"\\n    Read distribution within fastq files to process: \\n        total... \"+locale.format_string(\"%d\", sum(readcount), grouping=True)+' reads \\n        range... max: '+str((max(file for file in readcount)))+' reads; min: '+str((min(file for file in readcount)))+' reads; median: '+str((numpy.median([file for file in readcount])))+' reads; mean +/- stdev: '+str(round((numpy.mean([file for file in readcount]))))+' +/- '+str(round((numpy.std([file for file in readcount]))))+' reads', file = f)\n",
    "    print(\"\\nfastq files processed (name, size (MB), reads): \", file = f)\n",
    "    for i in (sorted(fastq_overview)):\n",
    "        print(\"    \" + str(i).strip(\"()\").replace(\"'\",\"\"), file = f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Identify candidate alleles: fasta file, BLASTN alignment, and assignment of alleles to samples  \n",
    "Deep sequencing of amplicons can yield hundreds to thousands of reads per sample; read frequencies can be used to gauge relative read abundance and, ultimately, to infer probable genotype (sequence ID(s) of the source template(s)).\n",
    "<img src=\"ImputedGenotypes_img/fasta_thumbnail-01.png\" align=\"left\" width=\"750\">  \n",
    "\n",
    "*Operations:*  \n",
    "**Count reads.** This script parses sample-specific fastq files for unique read types, counts the abundance of these read types, and reports the top 10 most abundant read types (in each of read1 and read2) in the form of fasta entries. For each sample, **each of the 10 ranked sequences is reported with its frequency metrics** in a corresponding fasta definition line (defline).  \n",
    "\n",
    "The output of this step is a fasta file (.fa) that will be created in the user-specified OUTPUT DIRECTORY.  \n",
    "\n",
    "**Align reads to reference.** This fasta file is then presented to **BLASTN** (with the reference sequence database specified during user input) for alignments.\n",
    "\n",
    "**Define candidate alleles.** The script then parses the alignments to organize alignment data for the 'top 10' reads assigned to each sample, in a single dictionary called **'alignmentoutput_dict'**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on read count operation duration\n",
    "startTime_readcount = datetime.now()\n",
    "\n",
    "# For each fastq file (sourcefile) in fastq_directory, count top 10 most abundant read types and direct read sequence + annotation defline (sample name + frequency metrics) to fasta.fa (future alignment input)\n",
    "query_input = Path(str(output_path)+'/'+processdate+'_fasta.fa')\n",
    "\n",
    "for sourcefile in myFastqFilenames:\n",
    "    fastaname = re.split('_', os.path.basename(sourcefile))\n",
    "    # read all lines of fastq file into memory\n",
    "    with open(sourcefile, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    read_lines = lines[1::4]\n",
    "    # remove \\n character from each string item in list:\n",
    "    read_lines = map(str.strip, read_lines)\n",
    "    # create dictionary (counter) relating unique read sequence to its # of occurrences\n",
    "    counter=Counter(read_lines)\n",
    "    # assign top 10 reads by count in fastq file (sourcefile) to modified_read_list_top10\n",
    "    modified_read_list_top10 = []\n",
    "    for i in counter.most_common(10):\n",
    "        # read frequency relative to other reads that occur at >1% raw frequency\n",
    "        filtered1 = sum([x for x in counter.values() if x/(sum(counter.values())) > 0.01])\n",
    "        # read frequency relative to other reads that occur at >01% raw frequency\n",
    "        filtered10 = sum([x for x in counter.values() if x/(sum(counter.values())) > 0.1])\n",
    "        # read raw frequency\n",
    "        raw_freq = round((100*i[1]/sum(counter.values())),2)\n",
    "        modified_read_list_top10.append([i[0], '['+str(i[1])+'/'+str(sum(counter.values()))+']', raw_freq, int(stats.percentileofscore([i for i in counter.values()], i[1], 'rank')), round((100*i[1]/sum([i[1] for i in counter.most_common(10)])),2), round((100*i[1]/filtered1),2) if filtered1 > 0 and raw_freq >= 1 else 'None', round((100*i[1]/filtered10),2) if filtered10 > 0 and raw_freq >= 10 else 'None'])\n",
    "    # direct output in fasta format (with defline encoding sample name + frequency metrics) to fasta.fa\n",
    "    with open(str(query_input), 'a+') as file:\n",
    "        for i in modified_read_list_top10:\n",
    "            file.write('>'+fastaname[0]+'_'+fastaname[3]+'_'+str(i[1])+'_%totalreads:'+str(i[2])+'_percentile:'+str(i[3])+'_%top10reads:'+str(i[4])+'_%readsfilteredfor1%:'+str(i[5])+'_%readsfilteredfor10%:'+str(i[6])+'\\n'+i[0]+'\\n')\n",
    "\n",
    "# Log read count time duration\n",
    "readcountDuration = str(datetime.now()- startTime_readcount).split(':')[0]+' hr|'+str(datetime.now() - startTime_readcount).split(':')[1]+' min|'+str(datetime.now() - startTime_readcount).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_readcount).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process alignments to reference sequence database, using **BLASTN** (NCBI).  \n",
    "<img src=\"ImputedGenotypes_img/BLASTN_thumbnail-01.png\" align=\"left\" width=\"100\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on blastn alignments duration\n",
    "startTime_alignments = datetime.now()\n",
    "\n",
    "# Process alignments relative to reference sequence database, using blastn\n",
    "# Reference database\n",
    "db_input = db_path / db_prefix\n",
    "\n",
    "# Alignment output\n",
    "blast_directory = processdate+'_blastn_alignments.txt'\n",
    "query_output = output_directory / blast_directory\n",
    "\n",
    "# Alignment command\n",
    "cmd_align = str(blastn_path)+' -query '+str(query_input)+' -db '+str(db_input)+' -out '+str(query_output)+' -gapopen 1 -gapextend 1 -outfmt \"5\"'\n",
    "\n",
    "os.system(cmd_align)\n",
    "\n",
    "# Log alignment time duration\n",
    "alignmentsDuration = str(datetime.now()- startTime_alignments).split(':')[0]+' hr|'+str(datetime.now() - startTime_alignments).split(':')[1]+' min|'+str(datetime.now() - startTime_alignments).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_alignments).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Define alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on genotypes imputation duration\n",
    "startTime_imputation = datetime.now()\n",
    "\n",
    "# Import blastn alignments output as a list of strings (each string corresponds to a query alignment)\n",
    "alignments_list = []\n",
    "with open(str(query_output), 'r') as file:\n",
    "    reader = file.read()\n",
    "    for i,part in enumerate(reader.split('<Iteration_iter-num>')):\n",
    "        alignments_list.append(part)\n",
    "# Remove blastn header line from alignments_list\n",
    "alignments_list = alignments_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Convert alignments_list to list of lists (i.e., each query alignment string is encapsulateed into its own sublist within alignments_list2)\n",
    "alignments_list2 = [alignments_list[i:i+1] for i in range(0, len(alignments_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Subset sample IDs and/or associated reads for which *(1) no alignment* was found in reference database, or *(2) multiple hits* were identified in reference database. These are ultimately removed from further analysis, but the identities of samples and/or associated reads that were filtered by these criteria are ultimately reported in 'population_summary.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Identify & subset queries for which no alignments were found in reference database ('no hits found')\n",
    "no_hits_list = []\n",
    "for i in alignments_list2:\n",
    "    if re.search('No hits found', str(i)):\n",
    "        no_hits_list.append(str(i).split('<Iteration_query-def>')[1].split('</Iteration_query-def>')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Further subset 'No hits found' queries for R1 vs. R2\n",
    "no_hits_R1_read_list = []\n",
    "no_hits_R2_read_list = []\n",
    "for i in no_hits_list:\n",
    "    if i.split('_')[1] == 'R1':\n",
    "        no_hits_R1_read_list.append(i.split('_')[0]+' '+i.split('_')[2]+' '+i.split('_')[3].split(':')[1]+'%')\n",
    "    elif i.split('_')[1] == 'R2':\n",
    "        no_hits_R2_read_list.append(i.split('_')[0]+' '+i.split('_')[2]+' '+i.split('_')[3].split(':')[1]+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Record sample names having reads with no alignment hits\n",
    "no_hits_samplename_list = []\n",
    "for i in no_hits_list:\n",
    "    samplename = i.split('_')[0]\n",
    "    if samplename not in no_hits_samplename_list:\n",
    "        no_hits_samplename_list.append(samplename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Within each sublist of alignments_list2, split each line into an individual string, remove beginning and trailing whitespace, and recapture specified subset of alignment information in alignments_list3\n",
    "alignments_list3 = []\n",
    "for i in alignments_list2:\n",
    "    if str(i).split('<Iteration_query-def>')[1].split('</Iteration_query-def>')[0] not in no_hits_list:\n",
    "        alignments_list3.append([y.strip() for x in i for y in x.split('\\n') if y.strip().startswith(('<Iteration_query-ID>', '<Iteration_query-def>', '<Hit_num>', '<Hit_id>', '<Hit_def>', '<Hsp_hit-from>', '<Hsp_hit-to>', '<Hsp_qseq>', '<Hsp_hseq>', '<Hsp_midline>'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Identify & subset reads with >1 alignment to sequences in reference database\n",
    "multiple_alignments_list = []\n",
    "for i in alignments_list3:\n",
    "    if len(re.findall('<Hit_num>', str(i))) > 1:\n",
    "        multiple_alignments_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Identify read IDs with >1 alignment to sequences in reference database\n",
    "multiple_alignments_readID_list = []\n",
    "for i in multiple_alignments_list:\n",
    "    multiple_alignments_readID_list.append(i[1].split('>')[1].split('<')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Record sample names having reads with >1 alignment to sequences in reference database\n",
    "multiple_alignments_samplename_list = []\n",
    "for i in multiple_alignments_readID_list:\n",
    "    samplename = i.split('_')[0]\n",
    "    if samplename not in multiple_alignments_samplename_list:\n",
    "        multiple_alignments_samplename_list.append(samplename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare dictionary linking sample names to their reads having >1 alignment to sequences in reference database\n",
    "multiple_alignments_dict = {}\n",
    "for i in multiple_alignments_samplename_list:\n",
    "    multiple_alignments_dict [\"{0}\".format(i)] = tuple(x for x in multiple_alignments_list if bool(re.search(i, x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Finalize list containing candidate alleles with single alignment hit in reference database.  \n",
    "Prepare **'alignmentoutput_dict'**, a dictionary that aggregates all sample-associated alleles as sublists within a single list (value) assigned to appropriate sample name ID (key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare alignment_list4 for reads with exclusively 1 alignment hit in reference database\n",
    "alignments_list4 = []\n",
    "for i in alignments_list3:\n",
    "    if i not in multiple_alignments_list:\n",
    "        alignments_list4.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Among lists containing alignment data in alignments_list4, determine which queries (reads) correspond to the same sample; where querydef = i[1].split(\">\")[1].split(\"_[\")[0], reads belonging to the same sample share identical querydef\n",
    "# Fasta deflines encode frequency metrics for reads, based on defline format:\n",
    "# sampleID_[reads/total reads]_percentile_% read abundance_% top 10 reads_% reads filtered for 1%_% reads filtered for 10%\n",
    "querydef_list = []\n",
    "for i in alignments_list3:\n",
    "    querydef = i[1].split(\">\")[1].split(\"_\")[0]\n",
    "    querydef_list.append(querydef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# collapse querydef_list content into list of UNIQUE sample IDs\n",
    "querydef_uniq_list = []\n",
    "for i in querydef_list:\n",
    "    if i in querydef_uniq_list:\n",
    "        pass\n",
    "    else:\n",
    "        querydef_uniq_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare dictionary relating sample IDs to their associated reads ('alleles')\n",
    "alignmentoutput_dict = {}\n",
    "for i in querydef_uniq_list:\n",
    "    alignmentoutput_dict[\"{0}\".format(i)] = tuple(x for x in alignments_list4 if bool(re.search(i, x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Identify sample IDs for which no valid candidate alleles were identified. These samples are not further analyzed, but their identities are reported in 'population_summary.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Identify & subset sample ID's that do not have output alleles (empty tuple values in dictionary)\n",
    "empty_sampleIDs_list = []\n",
    "for i in alignmentoutput_dict:\n",
    "    if bool(alignmentoutput_dict.get(i) == ()):\n",
    "        empty_sampleIDs_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Make a copy of alignmentoutput_dict, removing dictionary keys with empty tuple values\n",
    "alignmentoutput_dict2 = { k : v for k,v in alignmentoutput_dict.items() if v}\n",
    "# Alignmentoutput_dict2 is the key input dictionary for genotype imputations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### V. Impute genotypes \n",
    "Data for sample-specific alleles were assembled in **alignmentoutput_dict**, a dictionary that collected alignment data for each sample's top 10 reads, with each read's frequency metrics maintained in the allele name (defline). The contents of this dictionary are now further parsed to assemble a second dictionary--**imputedgenotypes_dict**--in which analytics for each read are collected in sample-specific values: \n",
    "  - **allele type** is defined as 'wild-type' or 'mutant'\n",
    "  - if mutant, **allele specification** is further defined as 'deletion', 'insertion', 'substitution', 'indel', etc.\n",
    "  - if guide RNA or DNA test sequence(s) were specified during user input, the script searches for these user-specified sequence(s) in the read alignment (in both 'query' and 'hit') and records the starting position of the sequence match within the read string, for later positional mapping relative to the alignment\n",
    "  - finally, **genotype is imputed** for each sample based on the allele type(s) and specification(s) for reads that occur at >10% abundance (adjusted for all reads that occur at >10% raw frequency)\n",
    "\n",
    "--------\n",
    "**imputedgenotypes_dict**, the key data structure in which allele and genotype data are collected for individual samples, operates on the following organizational logic:  \n",
    "  - each sample ID is a unique dictionary key\n",
    "  - each sample value is a list, with data for all associated alleles individualized within sublists\n",
    "  - for each allele, four subdictionaries organize data for that allele within its sublist\n",
    "    - subdictionary 1 (with keys 'allele_name', 'chr+build', 'locus_ID', 'coordinates', 'alignment') organizes alignment data\n",
    "      (including frequency metrics within the 'allele_name' string value)\n",
    "    - subdictionary 2 (with keys 'allele_type', 'allele_specs') organizes allele definitions\n",
    "    - subdictionary 3 (with keys for each guide and/or its reverse) organizes positional mapping information to locate a guide sequence relative to the sequence alignment\n",
    "    - subdictionary 4 (with keys for each test sequence and/or its reverse) organizes positional mapping information to locate a test sequence relative to the sequence alignment  \n",
    "    \n",
    "*example*:  \n",
    "**imputedgenotypes_dict** = {'**sample ID1**': \\[[{'allele1_name':'.....', 'chr+build':'.....', 'locus_ID':'.....', 'coordinates':'.....', 'alignment':'query \\n midline \\n hit'}, {'allele_type':'mutant | wild-type', 'allele_specs':'deletion | insertion | substitution | indel, size'}, {'guide1':'sequence position', 'guide2':'sequence position}, {'test sequence1':'sequence position', 'test sequence2':'sequence position'}\\], \\[{'allele2_name':'.....', 'chr+build':'.....', 'locus_ID':'.....', 'coordinates':'.....', 'alignment':'query \\n midline \\n hit'}, {'allele_type':'mutant | wild-type', 'allele_specs':'deletion | insertion | substitution | indel, size'}, {'guide1':'sequence position', 'guide2':'sequence position}, {'test sequence1':'sequence position', 'test sequence2':'sequence position'}\\]], '**sample ID2**': \\[[{...},{...},{...},{...}\\],\\[{...},{...},{...},{...}\\],...], '**sample ID3**' : \\[[{...},{...},{...},{...}\\],\\[{...},{...},{...},{...}\\],...], . . . }  \n",
    "\n",
    "--------\n",
    "The output of these analytics is reported in **'allele_definitions.txt'** and **'imputed_genotypes.txt'**.  \n",
    "These files overlap in content, except that samples are reported in alphanumeric order based on sample ID name in **'allele_definitions.txt'** whereas samples are reported in ranked order of imputed genotype class (*e.g., homozygous deletions first*) in **'imputed_genotypes.txt'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define nt complement dictionary, for use in generating DNA sequence complements\n",
    "nt_dict = {'A':'T', 'T':'A', 'G':'C', 'C':'G', 'N':'N', '-':'-'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare dictionary relating sample IDs to their associated 'alleles', allele interpretations/definitions, and imputed genotype\n",
    "imputedgenotypes_dict = {}\n",
    "for i in alignmentoutput_dict2:\n",
    "    imputedgenotypes_dict[\"{0}\".format(i)] = []\n",
    "    imputed_genotype = []\n",
    "    allele_data = ['allele_name', 'chr+build', 'locusID', 'coordinates', 'alignment']\n",
    "    allele_descriptions = ['allele_type', 'allele_specs']\n",
    "    guideRNA_match = ''\n",
    "    extant_match = ''\n",
    "    for x in range(0,len(alignmentoutput_dict2.get(i))):\n",
    "        imputedgenotypes_dict[i].extend([[]])\n",
    "        allele_data_x = []\n",
    "        allele_data_x.append(alignmentoutput_dict2.get(i)[x][1].split(\">\")[1].split(\"<\")[0].replace('_', ' '))\n",
    "        allele_data_x.append(alignmentoutput_dict2.get(i)[x][4].split(\">\")[1].split(\"<\")[0])\n",
    "        allele_data_x.append(alignmentoutput_dict2.get(i)[x][3].split(\">\")[1].split(\"<\")[0])\n",
    "        allele_data_x.append(alignmentoutput_dict2.get(i)[x][5].split(\">\")[1].split(\"<\")[0]+'-'+alignmentoutput_dict2.get(i)[x][6].split(\">\")[1].split(\"<\")[0])\n",
    "        allele_data_x.append('\\n'+'    query  '+alignmentoutput_dict2.get(i)[x][7].split(\">\")[1].split(\"<\")[0]+'\\n'+'           '+alignmentoutput_dict2.get(i)[x][9].split(\">\")[1].split(\"<\")[0]+'\\n'+'reference  '+alignmentoutput_dict2.get(i)[x][8].split(\">\")[1].split(\"<\")[0])\n",
    "        imputedgenotypes_dict[i][x].append(((dict(zip(allele_data, allele_data_x)))))\n",
    "        allele_descriptions_x = []\n",
    "        if bool(re.search(' ', alignmentoutput_dict2.get(i)[x][9])):\n",
    "            allele_descriptions_x.append('mutant')\n",
    "            if bool(re.search('-', alignmentoutput_dict2.get(i)[x][7])) and not bool(re.search('-', alignmentoutput_dict2.get(i)[x][8])):\n",
    "                allele_descriptions_x.append('likely deletion, '+str(alignmentoutput_dict2.get(i)[x][7].count('-'))+' bp')\n",
    "                imputedgenotypes_dict[i][x].append(((dict(zip(allele_descriptions, allele_descriptions_x)))))\n",
    "                # imputed genotype is based on alleles with frequency adjusted as relative to reads that occurred at >10% raw frequency\n",
    "                if imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1].strip()) > 10:\n",
    "                    imputed_genotype.append(imputedgenotypes_dict.get(i)[x][1].get('allele_specs'))\n",
    "            elif bool(re.search('-', alignmentoutput_dict2.get(i)[x][8])) and not bool(re.search('-', alignmentoutput_dict2.get(i)[x][7])):\n",
    "                allele_descriptions_x.append('likely insertion, '+str(alignmentoutput_dict2.get(i)[x][8].count('-'))+' bp')\n",
    "                imputedgenotypes_dict[i][x].append(((dict(zip(allele_descriptions, allele_descriptions_x)))))\n",
    "                if imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1]) > 10:\n",
    "                    imputed_genotype.append(imputedgenotypes_dict.get(i)[x][1].get('allele_specs'))\n",
    "            elif bool(re.search('-', alignmentoutput_dict2.get(i)[x][7])) and bool(re.search('-', alignmentoutput_dict2.get(i)[x][8])):\n",
    "                allele_descriptions_x.append('likely complex indel')\n",
    "                imputedgenotypes_dict[i][x].append(((dict(zip(allele_descriptions, allele_descriptions_x)))))\n",
    "                if imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1]) > 10:\n",
    "                    imputed_genotype.append(imputedgenotypes_dict.get(i)[x][1].get('allele_specs'))\n",
    "            else:\n",
    "                allele_descriptions_x.append('likely substitution')\n",
    "                imputedgenotypes_dict[i][x].append(((dict(zip(allele_descriptions, allele_descriptions_x)))))\n",
    "                if imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                    pass\n",
    "                elif float(imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1]) > 10:\n",
    "                    imputed_genotype.append(imputedgenotypes_dict.get(i)[x][1].get('allele_specs'))\n",
    "        else:\n",
    "            allele_descriptions_x.append('wild-type')\n",
    "            imputedgenotypes_dict[i][x].append(((dict(zip(allele_descriptions, allele_descriptions_x)))))\n",
    "            if imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] == 'None':\n",
    "                pass\n",
    "            elif float(imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1]) > 10:\n",
    "                imputed_genotype.append('wild-type')\n",
    "        # find guide RNA sequence in reference sequence, and record location so that guide can be printed at appropriate position above reference sequence\n",
    "        try:\n",
    "            guideRNA_seq\n",
    "        except NameError:\n",
    "            imputedgenotypes_dict[i][x].extend([{}])\n",
    "        else:\n",
    "            guideRNA_seq_orientation_list = []\n",
    "            guide_positions_list = []\n",
    "            for guide in guideRNA_seq:\n",
    "                guideRNA_match = re.search(guide, alignmentoutput_dict2.get(i)[x][8].replace('-', '')) or re.search(guide, alignmentoutput_dict2.get(i)[x][7].replace('-', ''))\n",
    "                if not guideRNA_match:\n",
    "                    guide_revcomp = ''.join(reversed(''.join(nt_dict.get(nt) for nt in guide)))\n",
    "                    guide_rev = ''.join(reversed(guide))\n",
    "                    guideRNA_revcomp_match = re.search(guide_revcomp, alignmentoutput_dict2.get(i)[x][8].replace('-', '')) or re.search(guide_revcomp, alignmentoutput_dict2.get(i)[x][7].replace('-', ''))\n",
    "                    if not guideRNA_revcomp_match:\n",
    "                        guideRNA_seq_orientation_list.append('guide')\n",
    "                        guide_positions_list.append('None')\n",
    "                    else:\n",
    "                        guideRNA_seq_orientation_list.append(guide_rev)\n",
    "                        guide_positions_list.append(guideRNA_revcomp_match.start())\n",
    "                else:\n",
    "                    guideRNA_seq_orientation_list.append(guide)\n",
    "                    guide_positions_list.append(guideRNA_match.start())\n",
    "            imputedgenotypes_dict[i][x].append(((dict(zip(guideRNA_seq_orientation_list, guide_positions_list)))))\n",
    "        try:\n",
    "            extant_seq\n",
    "        except NameError:\n",
    "            imputedgenotypes_dict[i][x].extend([{}])\n",
    "        else:\n",
    "            extant_seq_orientation_list = []\n",
    "            seq_positions_list = []\n",
    "            for seq in extant_seq:\n",
    "                extant_match = re.search(seq, alignmentoutput_dict2.get(i)[x][8].replace('-', '')) or re.search(seq, alignmentoutput_dict2.get(i)[x][7].replace('-', ''))\n",
    "                if not extant_match:\n",
    "                    seq_revcomp = ''.join(reversed(''.join(nt_dict.get(nt) for nt in seq)))\n",
    "                    seq_rev = ''.join(reversed(seq))\n",
    "                    seq_revcomp_match = re.search(seq_revcomp, alignmentoutput_dict2.get(i)[x][8].replace('-', '')) or re.search(seq_revcomp, alignmentoutput_dict2.get(i)[x][7].replace('-', ''))\n",
    "                    if not seq_revcomp_match:\n",
    "                        extant_seq_orientation_list.append(seq)\n",
    "                        seq_positions_list.append('None')\n",
    "                    else:\n",
    "                        extant_seq_orientation_list.append(seq_rev)     \n",
    "                        seq_positions_list.append(seq_revcomp_match.start())\n",
    "                else:\n",
    "                    extant_seq_orientation_list.append(seq)\n",
    "                    seq_positions_list.append(extant_match.start())\n",
    "            imputedgenotypes_dict[i][x].append(((dict(zip(extant_seq_orientation_list, seq_positions_list))))) \n",
    "    # impute genotype based on allele(s) recorded as occurring at >10% frequency in imputed_genotypes list; deliver to index[0] position of imputedgenotypes_dict value for sampleID key\n",
    "    # homozygous states\n",
    "    if len(set(imputed_genotype)) == 1:\n",
    "        if bool('wild-type' in imputed_genotype):\n",
    "            imputedgenotypes_dict[i].insert(0, '|homozygous| wild-type (wt/wt)')\n",
    "        for n in set(imputed_genotype):\n",
    "            if bool(re.search('deletion', n)):\n",
    "                imputedgenotypes_dict[i].insert(0, '|homozygous| deletion (delta/delta)')\n",
    "            if bool(re.search('insertion', n)):\n",
    "                imputedgenotypes_dict[i].insert(0, '|homozygous| insertion (++/++)')\n",
    "            if bool(re.search('indel', n)):\n",
    "                imputedgenotypes_dict[i].insert(0, '|homozygous| indel (indel/indel')\n",
    "            if bool(re.search('substitution', n)):\n",
    "                imputedgenotypes_dict[i].insert(0, '|homozygous| substitution (sub/sub)')\n",
    "    #heterozygous states\n",
    "    elif len(set(imputed_genotype)) == 2:\n",
    "    # with wild-type allele\n",
    "        if bool('wild-type' in imputed_genotype):\n",
    "            for n in set(imputed_genotype):\n",
    "                if re.search('deletion', n):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| deletion + wild-type (delta/wt)')\n",
    "                elif re.search('insertion', n):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| insertion + wild-type (++/wt)')\n",
    "                elif re.search('indel', n):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| indel + wild-type  (indel/wt)')\n",
    "                elif re.search('substitution', n):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| substitution + wild-type (sub/wt)')\n",
    "    #heterozygous states (no wild-type allele)\n",
    "        elif not bool('wild-type' in imputed_genotype):\n",
    "            genotype_impute_summary = []\n",
    "            for n in set(imputed_genotype):\n",
    "                if re.search('wild-type', n):\n",
    "                    genotype_impute_summary.append('wild-type')\n",
    "                elif re.search('deletion', n):\n",
    "                    genotype_impute_summary.append('deletion')\n",
    "                elif re.search('insertion', n):\n",
    "                    genotype_impute_summary.append('insertion')\n",
    "                elif re.search('indel', n):\n",
    "                    genotype_impute_summary.append('indel')\n",
    "                elif re.search('substitution', n):\n",
    "                    genotype_impute_summary.append('substitution')\n",
    "            if len(set(genotype_impute_summary)) == 1:\n",
    "                if 'deletion' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| deletion1 + deletion2 (del1/del2)')\n",
    "                elif 'insertion' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| insertion1 + insertion2 (++1/++2)')\n",
    "                elif 'indel' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| indel1 + indel2 (indel1/indel2)')\n",
    "                elif 'substitution' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| substitution1 + substitution2 (sub1/sub2)')\n",
    "            else:\n",
    "                if 'deletion' in set(genotype_impute_summary) and 'insertion' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| deletion + insertion (del/++)')\n",
    "                elif 'deletion' in set(genotype_impute_summary) and 'indel' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| deletion + indel (del/indel)')\n",
    "                elif 'deletion' in set(genotype_impute_summary) and 'substitution' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| deletion + substitution (del/sub)')\n",
    "                elif 'insertion' in set(genotype_impute_summary) and 'indel' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| insertion + indel (++/indel)')\n",
    "                elif 'insertion' in set(genotype_impute_summary) and 'substitution' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| insertion + indel (++/sub)')                    \n",
    "                elif 'indel' in set(genotype_impute_summary) and 'substitution' in set(genotype_impute_summary):\n",
    "                    imputedgenotypes_dict[i].insert(0, '|heterozygous| indel + substitution (indel/sub)')\n",
    "    #multizygous states\n",
    "    elif len(set(imputed_genotype)) > 2:\n",
    "        imputed_genotype_str = '|multizygous|'\n",
    "        genotype_impute_summary = []\n",
    "        for n in set(imputed_genotype):\n",
    "            if re.search('wild-type', n):\n",
    "                genotype_impute_summary.append('wild-type')\n",
    "            elif re.search('deletion', n):\n",
    "                genotype_impute_summary.append('deletion')\n",
    "            elif re.search('insertion', n):\n",
    "                genotype_impute_summary.append('insertion')\n",
    "            elif re.search('indel', n):\n",
    "                genotype_impute_summary.append('indel')\n",
    "            elif re.search('substitution', n):\n",
    "                genotype_impute_summary.append('substitution')\n",
    "        if 'wild-type' in genotype_impute_summary:\n",
    "            imputed_genotype_str = imputed_genotype_str+' wild-type'\n",
    "            if 'deletion' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + deletion ('+str(genotype_impute_summary.count('deletion'))+')'\n",
    "            if 'insertion' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + insertion ('+str(genotype_impute_summary.count('insertion'))+')'\n",
    "            if 'indel' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + indel ('+str(genotype_impute_summary.count('indel'))+')'\n",
    "            if 'substitution' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + substitution ('+str(genotype_impute_summary.count('substitution'))+')'\n",
    "        elif 'deletion' in genotype_impute_summary:\n",
    "            imputed_genotype_str = imputed_genotype_str+' deletion ('+str(genotype_impute_summary.count('deletion'))+')'\n",
    "            if 'insertion' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + insertion ('+str(genotype_impute_summary.count('insertion'))+')'\n",
    "            if 'indel' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + indel ('+str(genotype_impute_summary.count('indel'))+')'\n",
    "            if 'substitution' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + substitution ('+str(genotype_impute_summary.count('substitution'))+')'\n",
    "        elif 'insertion' in genotype_impute_summary:\n",
    "            imputed_genotype_str = imputed_genotype_str+' insertion ('+str(genotype_impute_summary.count('insertion'))+')'\n",
    "            if 'indel' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + indel ('+str(genotype_impute_summary.count('indel'))+')'\n",
    "            if 'substitution' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + substitution ('+str(genotype_impute_summary.count('substitution'))+')'\n",
    "        elif 'indel' in genotype_impute_summary:\n",
    "            imputed_genotype_str = imputed_genotype_str+' indel ('+str(genotype_impute_summary.count('indel'))+')'\n",
    "            if 'substitution' in genotype_impute_summary:\n",
    "                imputed_genotype_str = imputed_genotype_str+' + substitution ('+str(genotype_impute_summary.count('substitution'))+')'\n",
    "        elif 'substitution' in genotype_impute_summary:\n",
    "            imputed_genotype_str = imputed_genotype_str+' + substitution ('+str(genotype_impute_summary.count('substitution'))+')'   \n",
    "        imputedgenotypes_dict[i].insert(0, imputed_genotype_str)\n",
    "    elif not imputed_genotype:\n",
    "        imputedgenotypes_dict[i].insert(0, '|unclear or multi-allelic| insufficient representation of any allele (i.e., no allele exceeds >10% of total reads when adjusted for 10% read threshold)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Create list containing reversed guideRNA_seq & extant_seq sequences, for use with R2 sequences\n",
    "try:\n",
    "    guideRNA_seq\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    guideRNA_seq_rev = [''.join(reversed(i)) for i in guideRNA_seq]\n",
    "    \n",
    "try:\n",
    "    extant_seq\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    extant_seq_rev = [''.join(reversed(i)) for i in extant_seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Report alleles and imputed genotypes to output file, **'allele_definitions.txt'**. Print location of guide RNA and/or test sequence matches relative to sequence alignments (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Print summaries of sample-specific allele definitions to output files; first to allele_definitions.txt, preserving sample order\n",
    "allele_definitions_output = Path(str(output_path)+'/'+processdate+'_allele_definitions.txt')\n",
    "\n",
    "with open(str(allele_definitions_output), 'a+') as file:\n",
    "    file.write('ImputedGenotypes.py: Allele Definitions\\nDate: ' + (datetime.today().strftime(\"%m/%d/%Y\")) + '\\n\\n')\n",
    "    for i in querydef_uniq_list:\n",
    "        if i in imputedgenotypes_dict:\n",
    "            file.write((len(i)*'=')+'\\n'+i+'\\n'+(len(i)*'=')+'\\n')\n",
    "            file.write('Imputed Genotype: '+imputedgenotypes_dict.get(i)[0]+'\\n')\n",
    "            # display alleles and their descriptions\n",
    "            read_checklist = []\n",
    "            read_abundance_checklist = []\n",
    "            for n in range(1, len(imputedgenotypes_dict.get(i))):\n",
    "                if imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[1] == 'R1':\n",
    "                    if 'R1' not in read_checklist:\n",
    "                        read_checklist.append('R1')\n",
    "                        file.write('\\n'+3*' '+'*'+8*'~'+'*\\n'+3*' '+'| READ 1 |\\n'+3*' '+'*'+8*'~'+'*\\n\\n')\n",
    "                    else:\n",
    "                        pass\n",
    "                    if float(imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[3].split(':')[1]) < 10:\n",
    "                        if 'R1dregs' not in read_abundance_checklist:\n",
    "                            read_abundance_checklist.append('R1dregs')\n",
    "                            file.write(3*' '+'*'+56*'~'+'*\\n'+3*' '+'|  >>>>> remaining alleles occur at frequency <10% <<<<< |\\n'+3*' '+'*'+56*'~'+'*\\n\\n')\n",
    "                        else:\n",
    "                            pass    \n",
    "                elif imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[1] == 'R2':\n",
    "                    if 'R2' not in read_checklist:\n",
    "                        read_checklist.append('R2')\n",
    "                        if 'R1' not in read_checklist:\n",
    "                            file.write('\\n'+3*' '+'*'+8*'~'+'*\\n'+3*' '+'| READ 2 |\\n'+3*' '+'*'+8*'~'+'*\\n\\n')\n",
    "                        else:\n",
    "                            file.write(3*' '+'*'+8*'~'+'*\\n'+3*' '+'| READ 2 |\\n'+3*' '+'*'+8*'~'+'*\\n\\n')\n",
    "                    else:\n",
    "                        pass\n",
    "                    if float(imputedgenotypes_dict.get(i)[n][0].get('allele_name').split(' ')[3].split(':')[1]) < 10:\n",
    "                        if 'R2dregs' not in read_abundance_checklist:\n",
    "                            read_abundance_checklist.append('R2dregs')\n",
    "                            file.write(3*' '+'*'+56*'~'+'*\\n'+3*' '+'|  >>>>> remaining alleles occur at frequency <10% <<<<< |\\n'+3*' '+'*'+56*'~'+'*\\n\\n')\n",
    "                        else:\n",
    "                            pass\n",
    "                if imputedgenotypes_dict.get(i)[n][1].get('allele_type') == 'wild-type':\n",
    "                    file.write(3*' '+'Allele: '+imputedgenotypes_dict.get(i)[n][0].get('allele_name')+' | '+imputedgenotypes_dict.get(i)[n][1].get('allele_type')+'\\n    Locus: '+imputedgenotypes_dict.get(i)[n][0].get('chr+build')+', '+imputedgenotypes_dict.get(i)[n][0].get('locusID')+' '+imputedgenotypes_dict.get(i)[n][0].get('coordinates')+'\\n')\n",
    "                else:\n",
    "                    file.write(3*' '+'Allele: '+imputedgenotypes_dict.get(i)[n][0].get('allele_name')+' | '+imputedgenotypes_dict.get(i)[n][1].get('allele_type')+', '+imputedgenotypes_dict.get(i)[n][1].get('allele_specs')+'\\n    Locus: '+imputedgenotypes_dict.get(i)[n][0].get('chr+build')+', '+imputedgenotypes_dict.get(i)[n][0].get('locusID')+' '+imputedgenotypes_dict.get(i)[n][0].get('coordinates')+'\\n')           \n",
    "                for guide in imputedgenotypes_dict.get(i)[n][2]:\n",
    "                    if imputedgenotypes_dict.get(i)[n][2].get(guide) != 'None':\n",
    "                        if guide in guideRNA_seq:\n",
    "                            file.write('\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))-2)*' '+\"5'-\"+guide+\"-3' (guide sequence)\"+'\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))+len(guide)-3)*' '+'v')\n",
    "                        elif guide in guideRNA_seq_rev:\n",
    "                            file.write('\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))-2)*' '+\"3'-\"+guide+\"-5' (guide sequence)\"+'\\n'+(int(imputedgenotypes_dict.get(i)[n][2].get(guide))+4)*' '+'v')\n",
    "                file.write(imputedgenotypes_dict.get(i)[n][0].get('alignment'))\n",
    "                for seq in imputedgenotypes_dict.get(i)[n][3]:\n",
    "                    if imputedgenotypes_dict.get(i)[n][3].get(seq) != 'None':\n",
    "                        file.write('\\n')\n",
    "                        if seq in extant_seq:\n",
    "                            file.write((1+int(imputedgenotypes_dict.get(i)[n][3].get(seq)))*' '+len(seq)*'^'+'\\n'+(int(imputedgenotypes_dict.get(i)[n][3].get(seq))-2)*' '+\"5'-\"+seq+\"-3' (test sequence)\\n\")\n",
    "                        elif seq in extant_seq_rev:\n",
    "                            file.write((1+int(imputedgenotypes_dict.get(i)[n][3].get(seq)))*' '+len(seq)*'^'+'\\n'+(int(imputedgenotypes_dict.get(i)[n][3].get(seq))-2)*' '+\"3'-\"+seq+\"-5' (test sequence)\\n\")\n",
    "                    elif imputedgenotypes_dict.get(i)[n][3].get(seq) == 'None':\n",
    "                        file.write('\\n')\n",
    "                file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Report alleles and imputed genotypes to output file, **'imputed_genotypes.txt'**. Print location of guide RNA and/or test sequence matches relative to sequence alignments (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Next print to imputed_genotypes.txt, using imputed genotype criteria as basis for reporting order\n",
    "# First prepare lists that bin sampleIDs based on imputed genotype\n",
    "# homo genotypes\n",
    "imputedgenotypes_homowildtype = []\n",
    "imputedgenotypes_homodeletion = []\n",
    "imputedgenotypes_homoinsertion = []\n",
    "imputedgenotypes_homoindel = []\n",
    "imputedgenotypes_homosubstitution = []\n",
    "# biallelic mutant genotypes\n",
    "imputedgenotypes_biallelic_deletion = []\n",
    "imputedgenotypes_biallelic_insertion = []\n",
    "imputedgenotypes_biallelic_indel = []\n",
    "imputedgenotypes_biallelic_substitution = []\n",
    "imputedgenotypes_biallelic_other = []\n",
    "# hetero genotypes (containing wt allele)\n",
    "imputedgenotypes_heterodeletion = []\n",
    "imputedgenotypes_heteroinsertion = []\n",
    "imputedgenotypes_heteroindel = []\n",
    "imputedgenotypes_heterosubstitution = []\n",
    "# multizygous\n",
    "imputedgenotypes_multizygous = []\n",
    "# unclear\n",
    "imputedgenotypes_unclear = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Add sampleIDs to appropriate lists, based on genotype class imputed for each sample\n",
    "for i in imputedgenotypes_dict:\n",
    "    if imputedgenotypes_dict.get(i)[0] in ('|homozygous| wild-type (wt/wt)'):\n",
    "        imputedgenotypes_homowildtype.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|homozygous| deletion (delta/delta)'):\n",
    "        imputedgenotypes_homodeletion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|homozygous| insertion (++/++)'):\n",
    "        imputedgenotypes_homoinsertion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|homozygous| indel (indel/indel)'):\n",
    "        imputedgenotypes_homoindel.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|homozygous| substitution (sub/sub)'):\n",
    "        imputedgenotypes_homosubstitution.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| deletion1 + deletion2 (del1/del2)'):\n",
    "        imputedgenotypes_biallelic_deletion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| insertion1 + insertion2 (++1/++2)'):\n",
    "        imputedgenotypes_biallelic_insertion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| indel1 + indel2 (indel1/indel2)'):\n",
    "        imputedgenotypes_biallelic_indel.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| substitution1 + substitution2 (sub1/sub2)'):\n",
    "        imputedgenotypes_biallelic_substitution.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| deletion + insertion (del/++)', '|heterozygous| deletion + indel (del/indel)', '|heterozygous| deletion + substitution (del/sub)', '|heterozygous| insertion + indel (++/indel)', '|heterozygous| insertion + indel (++/sub)', '|heterozygous| indel + substitution (indel/sub)'):\n",
    "        imputedgenotypes_biallelic_other.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| deletion + wild-type  (delta/wt)'):\n",
    "        imputedgenotypes_heterodeletion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| insertion + wild-type (++/wt)'):\n",
    "        imputedgenotypes_heteroinsertion.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| indel + wild-type (indel/wt)'):\n",
    "        imputedgenotypes_heteroindel.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|heterozygous| substitution + wild-type (sub/wt)'):\n",
    "        imputedgenotypes_heterosubstitution.append(i)\n",
    "    elif re.search('multizygous', imputedgenotypes_dict.get(i)[0]):\n",
    "        imputedgenotypes_multizygous.append(i)\n",
    "    elif imputedgenotypes_dict.get(i)[0] in ('|unclear or multi-allelic| insufficient representation of any allele (i.e., no allele exceeds >10% of total reads when adjusted for 10% read threshold)'):\n",
    "        imputedgenotypes_unclear.append(i)\n",
    "    elif re.search('', imputedgenotypes_dict.get(i)[0]):\n",
    "        imputedgenotypes_unclear.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Alphanumerically sort the imputedgenotypes lists in place\n",
    "imputedgenotypes_homowildtype.sort()\n",
    "imputedgenotypes_homodeletion.sort()\n",
    "imputedgenotypes_homoinsertion.sort()\n",
    "imputedgenotypes_homoindel.sort()\n",
    "imputedgenotypes_homosubstitution.sort()\n",
    "imputedgenotypes_biallelic_deletion.sort()\n",
    "imputedgenotypes_biallelic_insertion.sort()\n",
    "imputedgenotypes_biallelic_indel.sort()\n",
    "imputedgenotypes_biallelic_substitution.sort()\n",
    "imputedgenotypes_biallelic_other.sort()\n",
    "imputedgenotypes_heterodeletion.sort()\n",
    "imputedgenotypes_heteroinsertion.sort()\n",
    "imputedgenotypes_heteroindel.sort()\n",
    "imputedgenotypes_heterosubstitution.sort()\n",
    "imputedgenotypes_multizygous.sort()\n",
    "imputedgenotypes_unclear.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Print to imputed_genotypes.txt\n",
    "imputed_genotypes_output = Path(str(output_path)+'/'+processdate+'_imputed_genotypes.txt')\n",
    "# samples are reported in this file based on the following priority:\n",
    "    # imputedgenotypes_homodeletion\n",
    "    # imputedgenotypes_homoinsertion\n",
    "    # iputedgenotypes_homoindel\n",
    "    # imputedgenotypes_homosubstitution\n",
    "    # imputedgenotypes_biallelic_deletion\n",
    "    # imputedgenotypes_biallelic_insertion\n",
    "    # imputedgenotypes_biallelic_indel\n",
    "    # imputedgenotypes_biallelic_substitution\n",
    "    # imputedgenotypes_biallelic_other\n",
    "    # imputedgenotypes_heterodeletion\n",
    "    # imputedgenotypes_heteroinsertion\n",
    "    # imputedgenotypes_heteroindel\n",
    "    # imputedgenotypes_heterosubstitution\n",
    "    # imputedgenotypes_multizygous\n",
    "    # imputedgenotypes_homowildtype\n",
    "    # imputedgenotypes_unclear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Call upon allele_output function to report alleles and imputed genotypes based on imputed genotype class\n",
    "with open(str(imputed_genotypes_output), 'a+') as file:\n",
    "    file.write('ImputedGenotypes.py: Imputed Genotypes\\nDate: ' + (datetime.today().strftime(\"%m/%d/%Y\")) + '\\n\\n')\n",
    "    if len(imputedgenotypes_homodeletion) > 0:\n",
    "        file.write('\\n\\nHOMOZYGOUS DELETION\\n...................\\n\\n')\n",
    "        allele_output(imputedgenotypes_homodeletion)\n",
    "    if len(imputedgenotypes_homoinsertion) > 0:\n",
    "        file.write('\\n\\nHOMOZYGOUS INSERTION\\n....................\\n\\n')\n",
    "        allele_output(imputedgenotypes_homoinsertion)\n",
    "    if len(imputedgenotypes_homoindel) > 0:\n",
    "        file.write('\\n\\nHOMOZYGOUS INDEL\\n................\\n\\n')\n",
    "        allele_output(imputedgenotypes_homoindel)\n",
    "    if len(imputedgenotypes_homosubstitution) > 0:\n",
    "        file.write('\\n\\nHOMOZYGOUS SUBSTITUTION\\n.......................\\n\\n')\n",
    "        allele_output(imputedgenotypes_homosubstitution)\n",
    "    if len(imputedgenotypes_biallelic_deletion) > 0:\n",
    "        file.write('\\n\\nBIALLELIC DELETION\\n..................\\n\\n')\n",
    "        allele_output(imputedgenotypes_biallelic_deletion)\n",
    "    if len(imputedgenotypes_biallelic_insertion) > 0:\n",
    "        file.write('\\n\\nBIALLELIC INSERTION\\n...................\\n\\n')\n",
    "        allele_output(imputedgenotypes_biallelic_insertion)\n",
    "    if len(imputedgenotypes_biallelic_indel) > 0:\n",
    "        file.write('\\n\\nBIALLELIC INDEL\\n...............\\n\\n')\n",
    "        allele_output(imputedgenotypes_biallelic_indel)\n",
    "    if len(imputedgenotypes_biallelic_substitution) > 0:\n",
    "        file.write('\\n\\nBIALLELIC SUBSTITUTION\\n......................\\n\\n')\n",
    "        allele_output(imputedgenotypes_biallelic_substitution)\n",
    "        file.write('\\n\\nBIALLELIC MUTANT (VARIOUS)\\n..........................\\n\\n')\n",
    "    if len(imputedgenotypes_heterodeletion) > 0:\n",
    "        file.write('\\n\\nHETEROZYGOUS DELETION\\n.....................\\n\\n')\n",
    "        allele_output(imputedgenotypes_heterodeletion)\n",
    "    if len(imputedgenotypes_heteroinsertion) > 0:\n",
    "        file.write('\\n\\nHETEROZYGOUS INSERTION\\n......................\\n\\n')\n",
    "        allele_output(imputedgenotypes_heteroinsertion)\n",
    "    if len(imputedgenotypes_heteroindel) > 0:\n",
    "        file.write('\\n\\nHETEROZYGOUS INDEL\\n..................\\n\\n')\n",
    "        allele_output(imputedgenotypes_heteroindel)\n",
    "    if len(imputedgenotypes_heterosubstitution) > 0:\n",
    "        file.write('\\n\\nHETEROZYGOUS SUBSTITUTION\\n.........................\\n\\n')\n",
    "        allele_output(imputedgenotypes_heterosubstitution)\n",
    "    if len(imputedgenotypes_multizygous) > 0:\n",
    "        file.write('\\n\\nMULTIZYGOUS (>2 ALLELES)\\n..................\\n\\n')\n",
    "        allele_output(imputedgenotypes_multizygous)\n",
    "    if len(imputedgenotypes_homowildtype) > 0:\n",
    "        file.write('\\n\\nHOMOZYGOUS WILD-TYPE\\n....................\\n\\n')\n",
    "        allele_output(imputedgenotypes_homowildtype)\n",
    "    if len(imputedgenotypes_unclear) > 0:\n",
    "        file.write('\\n\\nGENOTYPE UNCLEAR (e.g., UNUSUAL ALLELE FREQUENCIES)\\n..................................................\\n\\n')\n",
    "        allele_output(imputedgenotypes_unclear)\n",
    "        \n",
    "# Log allele definition & genotype imputation time duration\n",
    "imputationDuration = str(datetime.now()- startTime_imputation).split(':')[0]+' hr|'+str(datetime.now() - startTime_imputation).split(':')[1]+' min|'+str(datetime.now() - startTime_imputation).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_imputation).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### VI. Process accessory files  \n",
    "#### *Transfer allele data to .csv spreadsheet, complete population summary*  \n",
    "**Data availability:** The raw data underlying allele definitions and imputed genotypes are housed in a session-specific dictionary, **imputedgenotypes_dict**. These data are made available to a user in spreadsheet format, by transferring dictionary content to a pandas dataframe and then to a comma-separated output file, **allele_definitions.csv**.\n",
    "\n",
    "**Population summary:** ImputedGenotypes.py focuses on sample-specific designation of alleles and imputed genotypes, but also reports aggregate population-level statistics in **population_summary.txt**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Allele_definitions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on accessory file processing duration (allele_definitions.csv, population_summary.txt)\n",
    "startTime_fileprocessing = datetime.now()\n",
    "\n",
    "# Import data into pandas dataframe\n",
    "imputedgenotypes_dataframe = pd.DataFrame(\n",
    "    {\n",
    "        \"allele\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[0]+'_'+str(x) for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"read\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"sample\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[0] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"reads\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[2].split('/')[0].strip('[') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"totalreads\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[2].split('/')[1].strip(']') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"%totalreads\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[3].split(':')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"%top10reads\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[5].split(':')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"%readsfilteredfor>1%\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[6].split(':')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"%readsfilteredfor>10%\": [imputedgenotypes_dict.get(i)[x][0].get('allele_name').split(' ')[7].split(':')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],  \n",
    "        \"chr\": [imputedgenotypes_dict.get(i)[x][0].get('chr+build').split(',')[0] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"locusID\": [imputedgenotypes_dict.get(i)[x][0].get('locusID') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"coordinates\": [imputedgenotypes_dict.get(i)[x][0].get('coordinates') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"alignment_query\": [imputedgenotypes_dict.get(i)[x][0].get('alignment').split('\\n')[1] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"alignment_midline\": [imputedgenotypes_dict.get(i)[x][0].get('alignment').split('\\n')[2] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"alignment_hit\": [imputedgenotypes_dict.get(i)[x][0].get('alignment').split('\\n')[3] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"allele_type\": [imputedgenotypes_dict.get(i)[x][1].get('allele_type') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"allele_specs\": [imputedgenotypes_dict.get(i)[x][1].get('allele_specs') for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))],\n",
    "        \"imputed_genotype\": [imputedgenotypes_dict.get(i)[0] for i in imputedgenotypes_dict for x in range(1,len(imputedgenotypes_dict.get(i)))]\n",
    "     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare output file containing allele data in comma-separated, tabular format (allele_definitions.csv)\n",
    "allele_definitions_csv_output = Path(str(output_path)+'/'+processdate+'_allele_definitions.csv')\n",
    "\n",
    "imputedgenotypes_dataframe.to_csv(path_or_buf=allele_definitions_csv_output, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Population_summary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Prepare population summary and print to population_summary.txt\n",
    "population_summary_output = Path(str(output_path)+'/'+processdate+'_population_summary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Create list containing contents of pandas dataframe, summarizing sample-specific allele definitions and imputed genotype properties\n",
    "imputedgenotypes_dataframe['sample'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: total sample #\n",
    "total_samples = []\n",
    "total_sample_count = 0\n",
    "for sourcefile in myFastqFilenames:\n",
    "    fastaname = re.split('_', os.path.basename(sourcefile))\n",
    "    if fastaname[0] not in total_samples:\n",
    "        total_samples.append(fastaname[0])\n",
    "        total_sample_count = total_sample_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics\n",
    "sample_checklist = []\n",
    "genotype_checklist = []\n",
    "for i in imputedgenotypes_dataframe['sample'].tolist():\n",
    "    if i not in sample_checklist:\n",
    "        sample_checklist.append(i)\n",
    "        genotype_checklist.append(set(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['imputed_genotype']))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: Genotype counts\n",
    "diploid = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) or re.search('heterozygous', str(i)):\n",
    "        diploid = diploid+1\n",
    "        \n",
    "multiploid = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('multizygous', str(i)):\n",
    "        multiploid = multiploid+1\n",
    "\n",
    "unclear = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('unclear', str(i)):\n",
    "        unclear = unclear+1\n",
    "        \n",
    "homo_wt = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and re.search('wild-type', str(i)):\n",
    "        homo_wt = homo_wt+1\n",
    "        \n",
    "homo_mutant = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and not re.search('wild-type', str(i)):\n",
    "        homo_mutant = homo_mutant+1\n",
    "        \n",
    "homo_deletion = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and re.search('deletion', str(i)):\n",
    "        homo_deletion = homo_deletion+1\n",
    "        \n",
    "homo_insertion = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and re.search('insertion', str(i)):\n",
    "        homo_insertion = homo_insertion+1\n",
    "        \n",
    "homo_substitution = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and re.search('substitution', str(i)):\n",
    "        homo_substitution = homo_substitution+1\n",
    "        \n",
    "homo_indel = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('homozygous', str(i)) and re.search('indel', str(i)):\n",
    "        homo_indel = homo_indel+1\n",
    "        \n",
    "hetero_wt = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('wild-type', str(i)):\n",
    "        hetero_wt  = hetero_wt+1\n",
    "        \n",
    "hetero_wt_deletion = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('wild-type', str(i)) and re.search('deletion', str(i)):\n",
    "        hetero_wt_deletion  = hetero_wt_deletion+1\n",
    "        \n",
    "hetero_wt_insertion = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('wild-type', str(i)) and re.search('insertion', str(i)):\n",
    "        hetero_wt_insertion = hetero_wt_insertion+1\n",
    "        \n",
    "hetero_wt_substitution = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('wild-type', str(i)) and re.search('substitution', str(i)):\n",
    "        hetero_wt_substitution = hetero_wt_substitution+1\n",
    "        \n",
    "hetero_wt_indel = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('wild-type', str(i)) and re.search('indel', str(i)):\n",
    "        hetero_wt_indel = hetero_wt_indel+1\n",
    "        \n",
    "hetero_mutant_mutant = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and not re.search('wild-type', str(i)):\n",
    "        hetero_mutant_mutant = hetero_mutant_mutant+1\n",
    "        \n",
    "hetero_deletion_insertion = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('deletion', str(i)) and re.search('insertion', str(i)):\n",
    "        hetero_deletion_insertion = hetero_deletion_insertion+1\n",
    "        \n",
    "hetero_deletion_substitution = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('deletion', str(i)) and re.search('substitution', str(i)):\n",
    "        hetero_deletion_substitution = hetero_deletion_substitution+1\n",
    "\n",
    "hetero_insertion_substitution = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('insertion', str(i)) and re.search('substitution', str(i)):\n",
    "        hetero_insertion_substitution = hetero_insertion_substitution+1\n",
    "        \n",
    "hetero_deletion_indel = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('deletion', str(i)) and re.search('indel', str(i)):\n",
    "        hetero_deletion_indel = hetero_deletion_indel+1\n",
    "        \n",
    "hetero_insertion_indel = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('insertion', str(i)) and re.search('indel', str(i)):\n",
    "        hetero_insertion_indel = hetero_insertion_indel+1\n",
    "        \n",
    "hetero_substitution_indel = 0\n",
    "for i in genotype_checklist:\n",
    "    if re.search('heterozygous', str(i)) and re.search('substitution', str(i)) and re.search('indel', str(i)):\n",
    "        hetero_substitution_indel = hetero_substitution_indel+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: Allele counts\n",
    "sample_checklist = []\n",
    "allele_type_checklist = []\n",
    "for i in imputedgenotypes_dataframe['sample'].tolist():\n",
    "    sample_alleles = []\n",
    "    if i not in sample_checklist:\n",
    "        sample_checklist.append(i)\n",
    "        R1_check = []\n",
    "        for x in range(0, len(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'])):\n",
    "            if imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'].iloc[x] == 'None':\n",
    "                pass\n",
    "            elif float(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'].iloc[x]) > 10:\n",
    "                if imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['read'].iloc[x] == 'R1':\n",
    "                    R1_check.append('R1/'+imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_type'].iloc[x])\n",
    "                    sample_alleles.append(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_type'].iloc[x])\n",
    "                elif imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['read'].iloc[x] == 'R2':\n",
    "                    if 'R1'+imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_type'].iloc[x] in R1_check:\n",
    "                        pass\n",
    "        if len(sample_alleles) != 0:\n",
    "            allele_type_checklist.append(sample_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: Compile counts of total defined alleles, wild-type alleles, and mutant alleles \n",
    "wt_alleles = 0\n",
    "mutant_alleles = 0\n",
    "\n",
    "for i in allele_type_checklist:\n",
    "    if len(i) == 1:\n",
    "        if re.search('wild-type', str(i)):\n",
    "            wt_alleles = wt_alleles+2\n",
    "        if re.search('mutant', str(i)):\n",
    "            mutant_alleles = mutant_alleles+2\n",
    "    elif len(i) == 2:\n",
    "        if re.search('wild-type', str(i)):\n",
    "            wt_alleles = wt_alleles+1\n",
    "        if re.search('mutant', str(i)):\n",
    "            mutant_alleles = mutant_alleles+1\n",
    "    elif len(i) == 3:\n",
    "        if re.search('wild-type', str(i)):\n",
    "            wt_alleles = wt_alleles+1\n",
    "        if re.findall('mutant', str(i)):\n",
    "            mutant_alleles = mutant_alleles+len(re.findall('mutant', str(i)))\n",
    "\n",
    "total_alleles = wt_alleles+mutant_alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics\n",
    "sample_checklist = []\n",
    "allele_specs_checklist = []\n",
    "for i in imputedgenotypes_dataframe['sample'].tolist():\n",
    "    sample_alleles = []\n",
    "    if i not in sample_checklist:\n",
    "        sample_checklist.append(i)\n",
    "        R1_check = []\n",
    "        for x in range(0, len(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'])):\n",
    "            if imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'].iloc[x] == 'None':\n",
    "                pass\n",
    "            elif imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_specs'].iloc[x] is None:\n",
    "                if 'wild-type' not in sample_alleles:\n",
    "                    sample_alleles.append('wild-type')\n",
    "            elif float(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['%readsfilteredfor>10%'].iloc[x]) > 10:\n",
    "                if imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['read'].iloc[x] == 'R1':\n",
    "                    if 'R1/'+imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_specs'].iloc[x] not in R1_check:\n",
    "                        R1_check.append('R1/'+imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_specs'].iloc[x])\n",
    "                        sample_alleles.append(imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_specs'].iloc[x])\n",
    "                elif imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['read'].iloc[x] == 'R2':\n",
    "                    if 'R1'+imputedgenotypes_dataframe[imputedgenotypes_dataframe['sample'] == i]['allele_specs'].iloc[x] in R1_check:\n",
    "                        pass\n",
    "        if len(sample_alleles) != 0:\n",
    "            allele_specs_checklist.append(sample_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: Compile counts of total deletion, insertion, substitution and indel alleles\n",
    "deletion_alleles = 0\n",
    "insertion_alleles = 0\n",
    "substitution_alleles = 0\n",
    "indel_alleles = 0\n",
    "\n",
    "for i in allele_specs_checklist:\n",
    "    if len(i) == 1:\n",
    "        if re.search('deletion', str(i)):\n",
    "            deletion_alleles = deletion_alleles+2\n",
    "        elif re.search('insertion', str(i)):\n",
    "            insertion_alleles = insertion_alleles+2\n",
    "        elif re.search('substitution', str(i)):\n",
    "            substitution_alleles = substitution_alleles+2\n",
    "        elif re.search('indel', str(i)):\n",
    "            indel_alleles = indel_alleles+2\n",
    "    elif len(i) == 2:\n",
    "        if re.search('deletion', str(i)):\n",
    "            deletion_alleles = deletion_alleles+1\n",
    "        if re.search('insertion', str(i)):\n",
    "            insertion_alleles = insertion_alleles+1\n",
    "        if re.search('substitution', str(i)):\n",
    "            substitution_alleles = substitution_alleles+1\n",
    "        if re.search('indel', str(i)):\n",
    "            indel_alleles = indel_alleles+1\n",
    "    elif len(i) == 3:\n",
    "        if re.findall('deletion', str(i)):\n",
    "            deletion_alleles = deletion_alleles+len(re.findall('deletion', str(i)))\n",
    "        if re.findall('insertion', str(i)):\n",
    "            insertion_alleles = insertion_alleles+len(re.findall('insertion', str(i)))\n",
    "        if re.findall('substitution', str(i)):\n",
    "            substitution_alleles = substitution_alleles+len(re.findall('substitution', str(i)))\n",
    "        if re.findall('indel', str(i)):\n",
    "            indel_alleles = indel_alleles+len(re.findall('indel', str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Population metrics: Compile list of sampleIDs for which there were no alignment hits for any of the top 10 reads\n",
    "no_hits_and_hits_samplename_list = []\n",
    "no_hits_for_any_top10_reads_samplename_list = []\n",
    "for i in no_hits_samplename_list:\n",
    "    if i in querydef_uniq_list:\n",
    "        no_hits_and_hits_samplename_list.append(i)\n",
    "    else:\n",
    "        no_hits_for_any_top10_reads_samplename_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare population_summary.txt file\n",
    "with open(str(population_summary_output), 'a+') as file:\n",
    "    file.write('ImputedGenotypes.py: Population Summary\\nDate: ' + (datetime.today().strftime(\"%m/%d/%Y\")) +\n",
    "\"\"\"\\n\\nI. Synopsis of Interpretations: Allele Definitions & Genotype Imputations\n",
    "\n",
    "    (A) Sample summary\n",
    "        (i) Number of samples processed: \"\"\" + str(total_sample_count) +\n",
    "'\\n        (ii) % samples called (genotype imputed): ' + str(len(sample_checklist)) + ' (' + str(round((100*(len(sample_checklist)/total_sample_count)),2))+'%)' +\n",
    "\"\"\"\\n\\n    (B) Genotypes summary\n",
    "        (i) % samples diploid (1-2 prominent alleles inferred): \"\"\" + str(diploid) + ' (' + str(round((100*(diploid/total_sample_count)),2))+'%)' +\n",
    "'\\n            (1) % homozygous wild-type (wt): ' + str(homo_wt) + ' (' + str(round((100*(homo_wt/total_sample_count)),2))+'%)' +\n",
    "'\\n            (2) % homozygous mutant: ' + str(homo_mutant) + ' (' + str(round((100*(homo_mutant/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % homozygous deletion: ' + str(homo_deletion) + ' (' + str(round((100*(homo_deletion/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % homozygous insertion: ' + str(homo_insertion) + ' (' + str(round((100*(homo_insertion/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % homozygous substitution: ' + str(homo_substitution) + ' (' + str(round((100*(homo_substitution/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % homozygous complex indel: ' + str(homo_indel) + ' (' + str(round((100*(homo_indel/total_sample_count)),2))+'%)' +\n",
    "'\\n            (3) % heterozygous (wt + mutant): ' + str(hetero_wt) + ' (' + str(round((100*(hetero_wt/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous deletion: ' + str(hetero_wt_deletion) + ' (' + str(round((100*(hetero_wt_deletion/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous insertion: ' + str(hetero_wt_insertion) + ' (' + str(round((100*(hetero_wt_insertion/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous substitution: ' + str(hetero_wt_substitution) + ' (' + str(round((100*(hetero_wt_substitution/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous complex indel: ' + str(hetero_wt_indel) + ' (' + str(round((100*(hetero_wt_indel/total_sample_count)),2))+'%)' +\n",
    "'\\n            (4) % heterozygous (mutant + mutant): ' + str(hetero_mutant_mutant) + ' (' + str(round((100*(hetero_mutant_mutant/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous deletion + insertion: ' + str(hetero_deletion_insertion) + ' (' + str(round((100*(hetero_deletion_insertion/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous deletion + substitution: ' + str(hetero_deletion_substitution) + ' (' + str(round((100*(hetero_deletion_substitution/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous insertion + substitution: ' + str(hetero_insertion_substitution) + ' (' + str(round((100*(hetero_insertion_substitution/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous deletion + complex indel: ' + str(hetero_deletion_indel) + ' (' + str(round((100*(hetero_deletion_indel/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous insertion + complex indel: ' + str(hetero_insertion_indel) + ' (' + str(round((100*(hetero_insertion_indel/total_sample_count)),2))+'%)' +\n",
    "'\\n                -> % heterozygous substitution + complex indel: ' + str(hetero_substitution_indel) + ' (' + str(round((100*(hetero_substitution_indel/total_sample_count)),2))+'%)' +\n",
    "'\\n        (ii) % samples multiploid (>2 prominent alleles inferred): ' + str(multiploid) + ' (' + str(round((100*(multiploid/total_sample_count)),2))+'%)' +\n",
    "\"\"\"\\n\\n    (B) Alleles summary\n",
    "        (i) % wild-type alleles: \"\"\" + str(wt_alleles) + ' (' + str(round((100*(wt_alleles/total_alleles)),2)) + '% of total alleles)' +\n",
    "'\\n        (ii) % mutant alleles: ' + str(mutant_alleles) + ' (' + str(round((100*(mutant_alleles/total_alleles)),2)) + '% of total alleles)' +\n",
    "'\\n            (1) % deletion alleles: ' + str(deletion_alleles) + ' (' + str(round((100*(deletion_alleles/total_alleles)),2)) + '% of total alleles)' +\n",
    "'\\n            (2) % insertion alleles: ' + str(insertion_alleles) + ' (' + str(round((100*(insertion_alleles/total_alleles)),2)) + '% of total alleles)' +\n",
    "'\\n            (3) % substitution alleles: ' + str(substitution_alleles) + ' (' + str(round((100*(substitution_alleles/total_alleles)),2)) + '% of total alleles)' +\n",
    "'\\n            (4) % complex indel alleles: ' + str(indel_alleles) + ' (' + str(round((100*(indel_alleles/total_alleles)),2)) + '% of total alleles)')\n",
    "    file.write(\"\"\"\\n\\nII. Synopsis of Reads Lost to Analysis\n",
    "    'Top 10' reads among samples with (A) no hits, or (B) multiple hits, in reference database\n",
    "\n",
    "    (A) Samples with reads among the 'top 10 most abundant reads', that did not map to the reference genome\n",
    "        (i) For the following sample IDs (\"\"\"+str(len(no_hits_for_any_top10_reads_samplename_list))+\"\"\"), NO reads among the \"top 10 most abundant reads\" could be mapped to the reference genome:\\n\"\"\")\n",
    "    for i in no_hits_for_any_top10_reads_samplename_list:\n",
    "        file.write('             '+i)\n",
    "    file.write('')\n",
    "    \n",
    "    file.write('\\n        (ii) For the following sample IDs ('+str(len(no_hits_samplename_list))+'), the indicated reads among the \"top 10 most abundant reads\" did not map to the reference genome:')\n",
    "# Print this output to population summary\n",
    "    for i in no_hits_samplename_list:\n",
    "        R1_check = []\n",
    "        R2_check = []\n",
    "        file.write('\\n             '+i+':')\n",
    "        for x in no_hits_R1_read_list:\n",
    "            if i == x.split(' ')[0]:\n",
    "                if 'R1' not in R1_check:\n",
    "                    R1_check.append('R1')\n",
    "                    file.write('\\n               R1')\n",
    "                file.write('\\n               '+x)\n",
    "        for x in no_hits_R2_read_list:\n",
    "            if i == x.split(' ')[0]:\n",
    "                if 'R2' not in R2_check:\n",
    "                    R2_check.append('R2')\n",
    "                    file.write('\\n               R2')\n",
    "                file.write('\\n               '+x)\n",
    "        file.write('')\n",
    "        \n",
    "    file.write('\\n\\n    (B) Samples with reads among the \"top 10 most abundant reads\", that mapped to multiple loci in the reference genome' +\n",
    "'\\n        (i) For the following sample IDs ('+str(len(multiple_alignments_samplename_list))+'), the indicated reads among the \"top 10 most abundant reads\" mapped to more than one locus in the reference genome:')\n",
    "    if len(multiple_alignments_samplename_list) == 0:\n",
    "        file.write('\\n               None')\n",
    "    else:\n",
    "        file.write('\\n             Sample IDs:')\n",
    "        for i in multiple_alignments_samplename_list:\n",
    "            file.write('\\n               '+i.strip()) \n",
    "        file.write('\\n\\n             Details:')\n",
    "        for i in multiple_alignments_dict:\n",
    "            file.write('\\n               '+i+'\\n               '+len(i)*'=')\n",
    "            R1_check = []\n",
    "            R2_check = []\n",
    "            for x in multiple_alignments_dict.get(i):\n",
    "                hit_list = []\n",
    "                hit_spec_list = []\n",
    "                for y in x:\n",
    "                    if re.search('Hit_num', y):\n",
    "                        hit_list.append(y)\n",
    "                if x[1].split('>')[1].split('_')[1] == 'R1':\n",
    "                    if 'R1' not in R1_check:\n",
    "                        R1_check.append('R1')\n",
    "                        file.write('\\n               R1')\n",
    "                elif x[1].split('>')[1].split('_')[1] == 'R2':\n",
    "                    if 'R2' not in R2_check:\n",
    "                        R2_check.append('R2')\n",
    "                        file.write('\\n               R2') \n",
    "                if len(hit_list) == 2:\n",
    "                    hit_spec_list.append('Hit '+x[2].split('>')[1].split('<')[0]+': '+x[4].split('>')[1].split('<')[0]+': '+x[3].split('>')[1].split('<')[0]+x[5].split('>')[1].split('<')[0]+'-'+x[6].split('>')[1].split('<')[0])\n",
    "                    hit_spec_list.append(x[7].split('>')[1].split('<')[0]+'\\n               '+x[9].split('>')[1].split('<')[0]+'\\n               '+x[8].split('>')[1].split('<')[0])\n",
    "                    if bool(int(x[10].split('>')[1].split('<')[0]) > 2):\n",
    "                        hit_spec_list.append('\\n               Hit 2: consult BLASTN file output (likely >1 high-scoring segment pair for this alignment)')\n",
    "                    else:\n",
    "                        hit_spec_list.append('\\n               Hit '+x[10].split('>')[1].split('<')[0]+': '+x[12].split('>')[1].split('<')[0]+': '+x[11].split('>')[1].split('<')[0]+x[13].split('>')[1].split('<')[0]+'-'+x[14].split('>')[1].split('<')[0])\n",
    "                        hit_spec_list.append(x[15].split('>')[1].split('<')[0]+'\\n               '+x[17].split('>')[1].split('<')[0]+'\\n               '+x[16].split('>')[1].split('<')[0])\n",
    "                    file.write('\\n               '+' '.join(x[1].split('>')[1].split('_')[:4])+' ... '+str(len(hit_list))+' hits\\n               '+((len((' '.join(x[1].split('>')[1].split('_')[:4])))+len(str(len(hit_list)))+10)*'-'))\n",
    "                    for w in hit_spec_list:\n",
    "                        file.write('\\n               '+str(w))\n",
    "                    file.write(''+'\\n')\n",
    "                else:    \n",
    "                    file.write('\\n               '+' '.join(x[1].split('>')[1].split('_')[:4])+' ... '+str(len(hit_list))+' hits\\n               '+((len((' '.join(x[1].split('>')[1].split('_')[:4])))+len(str(len(hit_list)))+10)*'-'))\n",
    "                    file.write(''+'\\n')\n",
    "                \n",
    "# Log file processing time duration                \n",
    "fileprocessingDuration = str(datetime.now()- startTime_fileprocessing).split(':')[0]+' hr|'+str(datetime.now() - startTime_fileprocessing).split(':')[1]+' min|'+str(datetime.now() - startTime_fileprocessing).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_fileprocessing).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Compile visualization of evidence supporting imputed genotypes (optional)\n",
    "This script imputed genotypes based on allele definitions (*e.g.* wild-type or mutant relative alignment reference) and the relative frequencies of defined alleles. **If you chose to include frequency plots as a file output (at script outset), supporting evidence for imputed genotypes will now be reported in the form of plots that visualize read frequency metrics for each sample**. For the top 10 ranked reads (ten 'allele ranks'), frequency is plotted at four levels:\n",
    " - raw frequency (# reads/total reads)\n",
    " - frequency adjusted for top 10 most abundant reads (# reads/total reads among top 10 reads)\n",
    " - frequency adjusted for reads that occur at >1% raw frequency (# reads/total reads among reads that occur at >1% raw frequency)\n",
    " - frequency adjusted for reads that occur at >10% raw frequency (# reads/total reads among reads that occur at >10% raw frequency).  \n",
    " \n",
    "In many cases, relative abundance of a robust candidate allele increases as low-frequency reads (attributable to PCR artefacts) are filtered out.\n",
    "\n",
    "Frequency plots are recorded in a PDF output file, **allele_evidence.pdf**. If you chose not to include frequency plots as a file output at script onset, allele_evidence.pdf will not appear in the final file output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if frequency_plot_check == 'Y':\n",
    "    frequency_plots()\n",
    "elif frequency_plot_check == 'N':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Log script processing time duration \n",
    "processingDuration = str(datetime.now()- startTime).split(':')[0]+' hr|'+str(datetime.now() - startTime).split(':')[1]+' min|'+str(datetime.now() - startTime).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime).split(':')[2].split('.')[1]+' microsec'\n",
    "\n",
    "# Log script end time\n",
    "endTime = datetime.now()\n",
    "endTimestr = str(endTime).split(' ')[1].split('.')[0]     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### VIII. Prepare final report of file size metrics and time durations to **script_metrics.txt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Assess output file set created by script\n",
    "file_set = [file for file in os.listdir(output_directory) if Path(file).suffix in ('.pdf','.txt','.fa')]\n",
    "\n",
    "# Log further script operation metrics to script_metrics.txt\n",
    "filename = Path(str(output_path)+ '/'+processdate+'_script_metrics.txt')\n",
    "\n",
    "if frequency_plot_check == 'Y':\n",
    "    with open(filename, 'a') as f:\n",
    "        print(\"\"\"\\nFile output information:\n",
    "    Output directory: \"\"\" + str(output_directory) +\n",
    "'\\n    Total file #: ' + str(len(file_set)) +\n",
    "'\\n    Total file output sizes: ', file = f)\n",
    "        for file in file_set:\n",
    "            print('        '+file+': '+path_size(str(output_directory)+'/'+file), file = f)\n",
    "        print(\"\"\"\\nScript operation times:\n",
    "    start time: \"\"\"+startTimestr+\n",
    "    '\\n    fasta processing time: '+readcountDuration+\n",
    "    '\\n    alignments processing time: '+alignmentsDuration+\n",
    "    '\\n    imputation processing time: '+imputationDuration+\n",
    "    '\\n    frequency plots compilation time: '+frequencyplotsDuration+\n",
    "    '\\n    accessory file processing time: '+fileprocessingDuration+\n",
    "    '\\n    total processing time: '+processingDuration+\n",
    "    '\\n    end time: ' + endTimestr, file = f)\n",
    "    f.close()\n",
    "elif frequency_plot_check == 'N':\n",
    "    with open(filename, 'a') as f:\n",
    "        print(\"\"\"\\nFile output information:\n",
    "    Output directory: \"\"\" + str(output_directory) +\n",
    "'\\n    Total file #: ' + str(len(file_set)) +\n",
    "'\\n    Total file output sizes: ', file = f)\n",
    "        for file in file_set:\n",
    "            print('        '+file+': '+path_size(str(output_directory)+'/'+file), file = f)\n",
    "        print(\"\"\"\\nScript operation times:\n",
    "    start time: \"\"\"+startTimestr+\n",
    "    '\\n    fasta processing time: '+readcountDuration+\n",
    "    '\\n    alignments processing time: '+alignmentsDuration+\n",
    "    '\\n    imputation processing time: '+imputationDuration+\n",
    "    '\\n    accessory file processing time: '+fileprocessingDuration+\n",
    "    '\\n    total processing time: '+processingDuration+\n",
    "    '\\n    end time: ' + endTimestr, file = f)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "# End of script operations\n",
    "print(\"\"\"\n",
    "Script has completed.  Please find output files at \"\"\"+str(output_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "############################################################################# end"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
